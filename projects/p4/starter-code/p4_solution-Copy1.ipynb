{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "focus": false,
    "id": "cc166dbc-d723-4076-8dd8-a290d911dc9b"
   },
   "source": [
    "# Project 4: Web Scraping Indeed.com & Predicting Salaries"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Introduction/Problem Statement.\n",
    "As a job seeker, it is important for me to be able to know whether a job I'm applying to will be a well-paid or not. Unfortunately, most job postings are not up-front about their salary "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false,
    "focus": false,
    "id": "911505d6-159f-4146-967d-a8482fe27e3d"
   },
   "outputs": [],
   "source": [
    "URL = 'http://www.indeed.com/q-data-scientist-l-Atlanta,-GA-jobs.html'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true,
    "focus": false,
    "id": "78446809-fa02-48df-b60f-cbeda175a498"
   },
   "outputs": [],
   "source": [
    "import requests\n",
    "import bs4\n",
    "from bs4 import BeautifulSoup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false,
    "focus": false,
    "id": "c8846f3e-42a5-4714-9784-fb5d6a28524b"
   },
   "outputs": [],
   "source": [
    "# read site in soup\n",
    "r = requests.get(URL)\n",
    "soup = BeautifulSoup(r.content, \"lxml\")\n",
    "\n",
    "# Append to the full set of results\n",
    "results = soup.findAll('div', { \"class\" : \"result\" })"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "focus": false,
    "id": "963bb376-7746-43ce-98ec-ea4162f7ead6"
   },
   "source": [
    "Let's look at one result more closely. A single `result` looks like\n",
    "\n",
    "```\n",
    "<div class=\" row result\" data-jk=\"2480d203f7e97210\" data-tn-component=\"organicJob\" id=\"p_2480d203f7e97210\" itemscope=\"\" itemtype=\"http://schema.org/JobPosting\">\n",
    "<h2 class=\"jobtitle\" id=\"jl_2480d203f7e97210\">\n",
    "<a class=\"turnstileLink\" data-tn-element=\"jobTitle\" onmousedown=\"return rclk(this,jobmap[0],1);\" rel=\"nofollow\" target=\"_blank\" title=\"AVP/Quantitative Analyst\">AVP/Quantitative Analyst</a>\n",
    "</h2>\n",
    "<span class=\"company\" itemprop=\"hiringOrganization\" itemtype=\"http://schema.org/Organization\">\n",
    "<span itemprop=\"name\">\n",
    "<a href=\"/cmp/Alliancebernstein?from=SERP&amp;campaignid=serp-linkcompanyname&amp;fromjk=2480d203f7e97210&amp;jcid=b374f2a780e04789\" target=\"_blank\">\n",
    "    AllianceBernstein</a></span>\n",
    "</span>\n",
    "<tr>\n",
    "<td class=\"snip\">\n",
    "<nobr>$117,500 - $127,500 a year</nobr>\n",
    "<div>\n",
    "<span class=\"summary\" itemprop=\"description\">\n",
    "C onduct quantitative and statistical research as well as portfolio management for various investment portfolios. Collaborate with Quantitative Analysts and</span>\n",
    "</div>\n",
    "</div>\n",
    "</td>\n",
    "</tr>\n",
    "</table>\n",
    "</div>\n",
    "```\n",
    "\n",
    "While this has some of the more verbose elements removed, we can see that there is some structure to the above:\n",
    "- The salary is available in a `nobr` element inside of a `td` element with `class='snip`.\n",
    "- The title of a job is in a link with class set to `jobtitle` and a `data-tn-element=\"jobTitle`.  \n",
    "- The location is set in a `span` with `class='location'`. \n",
    "- The company is set in a `span` with `class='company'`. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "focus": false,
    "id": "27b6ffb9-b42f-4298-b07a-10e3bab030cd"
   },
   "source": [
    "### Write 4 functions to extract each item: location, company, job, and salary.\n",
    "\n",
    "example: \n",
    "```python\n",
    "def extract_location_from_result(result):\n",
    "    return result.find ...\n",
    "```\n",
    "\n",
    "- Make sure these functions are robust and can handle cases where the data/field may not be available\n",
    "- Test the functions on the results above"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "u'Data Scientist\\n\\n\\n\\n\\n        Cox Automotive\\n\\n - \\n46 reviews\\n - Atlanta, GA\\n\\n\\nInterprets problems and develops solutions to business problems using data analysis, data mining, optimization tools, and machine learning techniques and...\\n\\n\\n30+ days ago window[\\'sj_result_4dd0428a36b610d7\\'] = {\"showSource\": false, \"source\": \"Cox Automotive\", \"loggedIn\": false, \"showMyJobsLinks\": true,\"undoAction\": \"unsave\",\"relativeJobAge\": \"30+ days ago\",\"jobKey\": \"4dd0428a36b610d7\", \"myIndeedAvailable\": true, \"tellAFriendEnabled\": false, \"showMoreActionsLink\": false, \"resultNumber\": 11, \"jobStateChangedToSaved\": false, \"searchState\": \"q=data scientist&amp;l=Atlanta%2C+GA\", \"basicPermaLink\": \"http://www.indeed.com\", \"saveJobFailed\": false, \"removeJobFailed\": false, \"requestPending\": false, \"notesEnabled\": false, \"currentPage\" : \"serp\", \"sponsored\" : true,\"reportJobButtonEnabled\": false, \"showMyJobsHired\": false, \"showSaveForSponsored\": false};\\n\\n\\n\\n\\nSponsored'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def extract_text(el):\n",
    "    if el:\n",
    "        return el.text.strip()\n",
    "    else:\n",
    "        return ''\n",
    "extract_text(results[1])\n",
    "\n",
    "# company\n",
    "def get_company_from_result(result):\n",
    "    return extract_text(result.find('span', {'class' : 'company'}))\n",
    "print get_company_from_result(results[1]) #test\n",
    "\n",
    "# location\n",
    "def get_location_from_result(result):\n",
    "    return extract_text(result.find('span', {'class':'location'}))\n",
    "print get_location_from_result(results[1]) #test\n",
    "\n",
    "# summary\n",
    "def get_summary_from_result(result):\n",
    "    return extract_text(result.find('span', {'class':'summary'}))\n",
    "print get_summary_from_result(results[1]) #test\n",
    "\n",
    "# title\n",
    "def get_title_from_result(result):\n",
    "    return extract_text(result.find('a', {'data-tn-element' : 'jobTitle'}))\n",
    "print get_title_from_result(results[2]) #test\n",
    "\n",
    "# get salary if exists\n",
    "def get_salary_from_result(result):\n",
    "    salary_table = result.find('td', {'class' : 'snip'})\n",
    "    if salary_table:\n",
    "        snip = salary_table.find('nobr')\n",
    "        if snip:\n",
    "            return snip.text.strip()   \n",
    "    return None\n",
    "print get_salary_from_result(results[0]) #test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3.7"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# adding some other variables as well\n",
    "# when posted may be associated with salary (maybe jobs that pay better get snatched up more quickly)\n",
    "def get_date_posted(result):\n",
    "    return extract_text(result.find('span', {'class':'date'}))\n",
    "print get_date_posted(results[1])\n",
    "\n",
    "# whether sponsored may be associated with salary (sponsored jobs may indicate a company with more money, or more desperate?)\n",
    "def get_is_sponsored(result):\n",
    "    is_sponsored = extract_text(result.find('span', {'class':'sdn'}))\n",
    "    if is_sponsored:\n",
    "        return is_sponsored\n",
    "    return None\n",
    "print get_is_sponsored(results[1])\n",
    "\n",
    "# number of reviews may be associated with salary\n",
    "def get_number_reviews(result):\n",
    "    x = extract_text(result.find('span', {'class': 'slNoUnderline'}))\n",
    "    if x:\n",
    "        return x\n",
    "    return None\n",
    "print get_number_reviews(results[0])\n",
    "\n",
    "# get star rating\n",
    "import re\n",
    "\n",
    "def get_star_rating(result):\n",
    "    find_rating = result.find('span',{'class':'rating'})\n",
    "    if find_rating:\n",
    "        search_in = str(find_rating)\n",
    "        return 5*float(re.findall('width: (.*)px', search_in)[0])/60\n",
    "    return None\n",
    "get_star_rating(results[8])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'http://www.indeed.com/rc/clk?jk=b950c132b2440486&fccid=105ecfd0283f415f'"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# I may want to look into a job in more detail, so I'll include the link\n",
    "def get_link(result):\n",
    "    find_rating = result.find('a',{'class' : 'jobtitle turnstileLink'}, href=True)\n",
    "    if find_rating:\n",
    "        search_in = str(find_rating)\n",
    "        return 'http://www.indeed.com'+ find_rating.attrs['href']\n",
    "    find_rating = result.find('a',{'rel' : 'nofollow'})\n",
    "    if find_rating:\n",
    "        search_in = str(find_rating)\n",
    "        return 'http://www.indeed.com'+ find_rating.attrs['href']\n",
    "    return None\n",
    "get_link(results[8])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "focus": false,
    "id": "dc1d32a3-b13c-4919-8723-ce50dbc7660f"
   },
   "source": [
    "Now, to scale up our scraping, we need to accumulate more results. We can do this by examining the URL above.\n",
    "\n",
    "- \"http://www.indeed.com/jobs?q=data+scientist+%2420%2C000&l=New+York&start=10\"\n",
    "\n",
    "There are two query parameters here we can alter to collect more results: the `l=New+York` and the `start=10`. The first controls the location of the results (so we can try different city). The second controls where in the results to start and gives 10 results (so we can keep incrementing this by 10 to move further within the list)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "focus": false,
    "id": "27584c3f-f552-40a2-842a-0681b1fd6265"
   },
   "source": [
    "#### Complete the following code to collect results from multiple cities and start points. \n",
    "- Enter your city below to add it to the search\n",
    "- Remember to convert your salary to U.S. Dollars to match the other cities if the currency is different"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cities = ['Atlanta, GA', 'Washington, DC', 'New York, NY', 'New Orleans, LA', 'Boston, MA', \n",
    "         'Austin, TX', 'Seattle, WA', 'San Francisco, CA', 'Detroit, MI', 'Minneapolis, MN',]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false,
    "focus": false,
    "id": "b02e2931-4d5a-4e1e-9504-c6ccaaf84bed"
   },
   "outputs": [],
   "source": [
    "# create template URL and max number of results (pages) to pull\n",
    "url_template = \"http://www.indeed.com/jobs?q=data+scientist&l={}&start={}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "//anaconda/envs/py27/lib/python2.7/site-packages/bs4/__init__.py:181: UserWarning: No parser was explicitly specified, so I'm using the best available HTML parser for this system (\"lxml\"). This usually isn't a problem, but if you run this code on another system, or in a different virtual environment, it may use a different parser and behave differently.\n",
      "\n",
      "The code that caused this warning is on line 174 of the file //anaconda/envs/py27/lib/python2.7/runpy.py. To get rid of this warning, change code that looks like this:\n",
      "\n",
      " BeautifulSoup([your markup])\n",
      "\n",
      "to this:\n",
      "\n",
      " BeautifulSoup([your markup], \"lxml\")\n",
      "\n",
      "  markup_type=markup_type))\n"
     ]
    }
   ],
   "source": [
    "# for loop to pull data with bs4\n",
    "results = []\n",
    "starts = [] #I want to keep track of what page something appears on\n",
    "city_state = [] #I want to keep track of what city I searched in, since not all results are in the city.\n",
    "for city in cities:\n",
    "    city = city.replace(' ', '+')\n",
    "    for start in range(0,2000,10):\n",
    "        r = requests.get(url_template.format(city, start))\n",
    "        # Grab the results from the request (as above)\n",
    "        soup = BeautifulSoup(r.content)\n",
    "        # Append to the full set of results\n",
    "        results += soup.findAll('div', { \"class\" : \"result\" })\n",
    "        starts.extend([start]*len(soup.findAll('div', { \"class\" : \"result\" })))\n",
    "        city_state.extend([city]*len(soup.findAll('div', { \"class\" : \"result\" })))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "29898\n",
      "29898\n",
      "29898\n"
     ]
    }
   ],
   "source": [
    "#checking that lengths match so I can ensure the data is corrent when I add it to my dataframe.\n",
    "print len(results)\n",
    "print len(starts)\n",
    "print len(city_state)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "focus": false,
    "id": "10eb5902-4727-4947-a167-2531aa12a427"
   },
   "source": [
    "#### Use the functions you wrote above to parse out the 4 fields - location, title, company and salary. Create a dataframe from the results with those 4 columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false,
    "focus": false,
    "id": "d601ff2f-fbdf-4c4f-8bbe-10c4a3132cc8"
   },
   "outputs": [],
   "source": [
    "# combine data into dictionaries company location summary title salary\n",
    "rows = []\n",
    "for i, result in enumerate(results):\n",
    "    if result:\n",
    "        row = {'company': get_company_from_result(result),\n",
    "              'location': get_location_from_result(result),\n",
    "              'summary': get_summary_from_result(result),\n",
    "              'title': get_title_from_result(result),\n",
    "              'salary': get_salary_from_result(result),\n",
    "              'date_posted': get_date_posted(result),\n",
    "              'sponsored': get_is_sponsored(result),\n",
    "              'star_rating': get_star_rating(result),\n",
    "              'search_city':city_state[i],\n",
    "              'start': starts[i],\n",
    "              'website': get_link(result), \n",
    "              'number_reviews': get_number_reviews(result)}\n",
    "        rows.append(row)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(29898, 12)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# create dataframe\n",
    "import pandas as pd\n",
    "ds_jobs = pd.DataFrame(rows)\n",
    "ds_jobs.info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>company</th>\n",
       "      <th>date_posted</th>\n",
       "      <th>location</th>\n",
       "      <th>number_reviews</th>\n",
       "      <th>salary</th>\n",
       "      <th>search_city</th>\n",
       "      <th>sponsored</th>\n",
       "      <th>star_rating</th>\n",
       "      <th>start</th>\n",
       "      <th>summary</th>\n",
       "      <th>title</th>\n",
       "      <th>website</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Cotiviti</td>\n",
       "      <td>30+ days ago</td>\n",
       "      <td>Atlanta, GA</td>\n",
       "      <td>30 reviews</td>\n",
       "      <td>None</td>\n",
       "      <td>Atlanta,+GA</td>\n",
       "      <td>Sponsored</td>\n",
       "      <td>3.35</td>\n",
       "      <td>0</td>\n",
       "      <td>This is a pioneering data scientist who will participate in expanding the new analytics backbone. Cotiviti is looking for an industry leading Data Scientist to...</td>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>http://www.indeed.com/pagead/clk?mo=r&amp;ad=-6NYlbfkN0AbexXlh6WlNaC12RNLKcRQH8fywLm61v9KQllly0vTVrm9U0Iy0AOsYwOq9YOpDX03iprvWHw_SY6xCXG90mwLvOd8fb5BdJ-fu_-2tfp_KoWry1hPm7FaVRyBGPoeYEaNltu7W5i0j-OYtPh1ozEJ4oN7u_zLF7PnEIYwsSJTUyra1nlPHHQpGEq7KH9P1UhJyt0gLdmaXr7oC9iG41hrLTLQM6Dy4jOfZIDOXaBdIjV_m-vrLzXNwMCEHNxAuNUsOUWu9fNUIO6h2dpkDtS46fwUq5bUGThLBpg1h_JsmngU4OOpPDCmzhyOIZujq7kpNxhKt2UxH0Sm5knOVKSmYxJ1lNKEnygA8DCD6U_1zkkTxJJ5LBcAr9lpizyc6MVLmeSSISBIrGKE9SvJv_WjfNXpznu3719huu8jLhA-4dpvovDIXnXZf5ddKRiNMGDJ_o8d2rLvrnNdM6ksJXYj&amp;p=1&amp;sk=&amp;fvj=0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Cox Automotive</td>\n",
       "      <td>30+ days ago</td>\n",
       "      <td>Atlanta, GA</td>\n",
       "      <td>46 reviews</td>\n",
       "      <td>None</td>\n",
       "      <td>Atlanta,+GA</td>\n",
       "      <td>Sponsored</td>\n",
       "      <td>3.40</td>\n",
       "      <td>0</td>\n",
       "      <td>Interprets problems and develops solutions to business problems using data analysis, data mining, optimization tools, and machine learning techniques and...</td>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>http://www.indeed.com/pagead/clk?mo=r&amp;ad=-6NYlbfkN0Aqmv_5JD5v6gg1ICRL12VY6BolF0XAUkQtat1DEGOKAas7v4hqpX3lzUM4h7L4VGsyuyDvf1POStkSJgHsuP2fB8YliLIijj53wvHBII5P9eQQwhBoT2Vrz0Dv0LOR9cmhA2uclIYN001l_R0jB6OflQ3KEmNIKzoNezeQCnu5X1bPju79uAEHbaTS6LdJvB-hJTy0PZPPeNKSkMyWxp3Wc2N8qN2FIq69xIhd7NBdjwnWuSZEDZvdGAtcdwsplmc_6i_owekmLU0Zj9rRIQYMM4CCSqkchPU_LsOfeRYl0NSHhXylFvCq02OyIvg1KznvqQ7PPXo_fB0sk1_bs3_otngXRLhv8vkj1BFB91Yk951kq_RGaTq5Z94UiOx8vqbM6V4495DCvkTFhmxPx8jUsGpZ6kQVHUXPRdq4CZxNPdlpgypTkUKGSHiuF2jTN7edfKfbZELHMxMILPWKq1PX7Etfm45MtiI=&amp;p=2&amp;sk=&amp;fvj=0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Honeywell</td>\n",
       "      <td>30+ days ago</td>\n",
       "      <td>Atlanta, GA</td>\n",
       "      <td>3,557 reviews</td>\n",
       "      <td>None</td>\n",
       "      <td>Atlanta,+GA</td>\n",
       "      <td>Sponsored</td>\n",
       "      <td>3.70</td>\n",
       "      <td>0</td>\n",
       "      <td>Support and mentor data scientists. Minimum of 5 years of experience in a combination of data science, machine learning, predictive analytics, statistical...</td>\n",
       "      <td>Principal Data Scientist - Atlanta, GA</td>\n",
       "      <td>http://www.indeed.com/pagead/clk?mo=r&amp;ad=-6NYlbfkN0BT1oD7gxL4d4q7k2XK_xqJz55UkLlcqeX4XFuXt5iz9snYfsSUT3YCjhoIHnNQ-5Dn3WpSwV_to5gRmnY1dWxevmGFzqLqqlIFz_9Edyh1_IXncaR6MCLo7f5ouI8dmb8uuCR-Gmx3D0JDk0Mr6-bDRl6_oL__-yabT9kowHDUPeBtZkMJognwbgSn7JKNdyR8xVuWFFOTK19pmuU2dd5avUCBVFtU2sKLt8sbDK9kZmatBTvLWw9mSk9saicemGkngM_SN-JaPwW2wHCjEO5hK98T035f01nOI9o3ia3L5wR1VUQJgkEqq37uz9VQlxlzLpE9e-1UkEpSSuVpab7uYAzIunguUW-Veb9PE7QBNJkn1V2aLOTbuEYDgbiHxkQQy5UqMb6a7SV1IxkpbHkbfInjk9I-rbwVtqZduH3r8D_W_d1EbYFUhzGETCT-VTLBqqwyAv_rFadY2vmiP5R3t_H5qjb5foJI0iHryGOAf4taEETWvPjj5-ovMDCSWJlDwEvyiMmFjw==&amp;p=3&amp;sk=&amp;fvj=0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Vision3 Solutions, Inc</td>\n",
       "      <td>1 day ago</td>\n",
       "      <td>Atlanta, GA</td>\n",
       "      <td>None</td>\n",
       "      <td>$90 an hour</td>\n",
       "      <td>Atlanta,+GA</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>Data Scientist- Big Data*. May write code to automate reports and templates and consolidate data into reports and knowledge. 12 Months Contract*....</td>\n",
       "      <td>Data Scientist- Big Data</td>\n",
       "      <td>http://www.indeed.com/company/Vision3-Solutions,-Inc/jobs/Data-Scientist-1a8c086f5f6f1294?r=1&amp;fccid=37d33d67f3fba52b</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>FraudScope</td>\n",
       "      <td>2 days ago</td>\n",
       "      <td>Atlanta, GA</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>Atlanta,+GA</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>Experience with healthcare-related data and familiarity with current methods applied to healthcare data is preferred....</td>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>http://www.indeed.com/company/FraudScope/jobs/Data-Scientist-d72c337465398caf?r=1&amp;fccid=e87f46501099545c</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  company   date_posted     location number_reviews  \\\n",
       "0                Cotiviti  30+ days ago  Atlanta, GA     30 reviews   \n",
       "1          Cox Automotive  30+ days ago  Atlanta, GA     46 reviews   \n",
       "2               Honeywell  30+ days ago  Atlanta, GA  3,557 reviews   \n",
       "3  Vision3 Solutions, Inc     1 day ago  Atlanta, GA           None   \n",
       "4              FraudScope    2 days ago  Atlanta, GA           None   \n",
       "\n",
       "        salary  search_city  sponsored  star_rating  start  \\\n",
       "0         None  Atlanta,+GA  Sponsored         3.35      0   \n",
       "1         None  Atlanta,+GA  Sponsored         3.40      0   \n",
       "2         None  Atlanta,+GA  Sponsored         3.70      0   \n",
       "3  $90 an hour  Atlanta,+GA       None          NaN      0   \n",
       "4         None  Atlanta,+GA       None          NaN      0   \n",
       "\n",
       "                                                                                                                                                              summary  \\\n",
       "0  This is a pioneering data scientist who will participate in expanding the new analytics backbone. Cotiviti is looking for an industry leading Data Scientist to...   \n",
       "1        Interprets problems and develops solutions to business problems using data analysis, data mining, optimization tools, and machine learning techniques and...   \n",
       "2       Support and mentor data scientists. Minimum of 5 years of experience in a combination of data science, machine learning, predictive analytics, statistical...   \n",
       "3                Data Scientist- Big Data*. May write code to automate reports and templates and consolidate data into reports and knowledge. 12 Months Contract*....   \n",
       "4                                            Experience with healthcare-related data and familiarity with current methods applied to healthcare data is preferred....   \n",
       "\n",
       "                                    title  \\\n",
       "0                          Data Scientist   \n",
       "1                          Data Scientist   \n",
       "2  Principal Data Scientist - Atlanta, GA   \n",
       "3                Data Scientist- Big Data   \n",
       "4                          Data Scientist   \n",
       "\n",
       "                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                           website  \n",
       "0                                                          http://www.indeed.com/pagead/clk?mo=r&ad=-6NYlbfkN0AbexXlh6WlNaC12RNLKcRQH8fywLm61v9KQllly0vTVrm9U0Iy0AOsYwOq9YOpDX03iprvWHw_SY6xCXG90mwLvOd8fb5BdJ-fu_-2tfp_KoWry1hPm7FaVRyBGPoeYEaNltu7W5i0j-OYtPh1ozEJ4oN7u_zLF7PnEIYwsSJTUyra1nlPHHQpGEq7KH9P1UhJyt0gLdmaXr7oC9iG41hrLTLQM6Dy4jOfZIDOXaBdIjV_m-vrLzXNwMCEHNxAuNUsOUWu9fNUIO6h2dpkDtS46fwUq5bUGThLBpg1h_JsmngU4OOpPDCmzhyOIZujq7kpNxhKt2UxH0Sm5knOVKSmYxJ1lNKEnygA8DCD6U_1zkkTxJJ5LBcAr9lpizyc6MVLmeSSISBIrGKE9SvJv_WjfNXpznu3719huu8jLhA-4dpvovDIXnXZf5ddKRiNMGDJ_o8d2rLvrnNdM6ksJXYj&p=1&sk=&fvj=0  \n",
       "1                                              http://www.indeed.com/pagead/clk?mo=r&ad=-6NYlbfkN0Aqmv_5JD5v6gg1ICRL12VY6BolF0XAUkQtat1DEGOKAas7v4hqpX3lzUM4h7L4VGsyuyDvf1POStkSJgHsuP2fB8YliLIijj53wvHBII5P9eQQwhBoT2Vrz0Dv0LOR9cmhA2uclIYN001l_R0jB6OflQ3KEmNIKzoNezeQCnu5X1bPju79uAEHbaTS6LdJvB-hJTy0PZPPeNKSkMyWxp3Wc2N8qN2FIq69xIhd7NBdjwnWuSZEDZvdGAtcdwsplmc_6i_owekmLU0Zj9rRIQYMM4CCSqkchPU_LsOfeRYl0NSHhXylFvCq02OyIvg1KznvqQ7PPXo_fB0sk1_bs3_otngXRLhv8vkj1BFB91Yk951kq_RGaTq5Z94UiOx8vqbM6V4495DCvkTFhmxPx8jUsGpZ6kQVHUXPRdq4CZxNPdlpgypTkUKGSHiuF2jTN7edfKfbZELHMxMILPWKq1PX7Etfm45MtiI=&p=2&sk=&fvj=0  \n",
       "2  http://www.indeed.com/pagead/clk?mo=r&ad=-6NYlbfkN0BT1oD7gxL4d4q7k2XK_xqJz55UkLlcqeX4XFuXt5iz9snYfsSUT3YCjhoIHnNQ-5Dn3WpSwV_to5gRmnY1dWxevmGFzqLqqlIFz_9Edyh1_IXncaR6MCLo7f5ouI8dmb8uuCR-Gmx3D0JDk0Mr6-bDRl6_oL__-yabT9kowHDUPeBtZkMJognwbgSn7JKNdyR8xVuWFFOTK19pmuU2dd5avUCBVFtU2sKLt8sbDK9kZmatBTvLWw9mSk9saicemGkngM_SN-JaPwW2wHCjEO5hK98T035f01nOI9o3ia3L5wR1VUQJgkEqq37uz9VQlxlzLpE9e-1UkEpSSuVpab7uYAzIunguUW-Veb9PE7QBNJkn1V2aLOTbuEYDgbiHxkQQy5UqMb6a7SV1IxkpbHkbfInjk9I-rbwVtqZduH3r8D_W_d1EbYFUhzGETCT-VTLBqqwyAv_rFadY2vmiP5R3t_H5qjb5foJI0iHryGOAf4taEETWvPjj5-ovMDCSWJlDwEvyiMmFjw==&p=3&sk=&fvj=0  \n",
       "3                                                                                                                                                                                                                                                                                                                                                                                                                                                                                             http://www.indeed.com/company/Vision3-Solutions,-Inc/jobs/Data-Scientist-1a8c086f5f6f1294?r=1&fccid=37d33d67f3fba52b  \n",
       "4                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                         http://www.indeed.com/company/FraudScope/jobs/Data-Scientist-d72c337465398caf?r=1&fccid=e87f46501099545c  "
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.options.display.max_colwidth = 1000\n",
    "ds_jobs.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "before drop Sponsored                               11466\n",
      "Sponsored by Amazon.com                  2075\n",
      "Sponsored by The Home Depot               328\n",
      "Urgently Hiring                           226\n",
      "Sponsored by Target Corporation           200\n",
      "Sponsored by WorkableHR Sponsored         199\n",
      "Ad: Urgently Hiring                       174\n",
      "Sponsored by Cox Communications Inc.      154\n",
      "Name: sponsored, dtype: int64\n",
      "\n",
      "drop size (5535, 12)\n",
      "\n",
      "after drop Sponsored                               71\n",
      "Sponsored by Amazon.com                 21\n",
      "Ad: Urgently Hiring                      2\n",
      "Sponsored by The Home Depot              2\n",
      "Urgently Hiring                          2\n",
      "Sponsored by WorkableHR Sponsored        1\n",
      "Sponsored by Target Corporation          1\n",
      "Sponsored by Cox Communications Inc.     1\n",
      "Name: sponsored, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# looking at sponsored posts to see if they account for the majority of my duplicates\n",
    "print 'before drop', ds_jobs.sponsored.value_counts()\n",
    "print '\\ndrop size', ds_jobs.drop_duplicates([x for x in ds_jobs.columns if x != 'start' and x != 'website']).shape\n",
    "print '\\nafter drop', ds_jobs.drop_duplicates([x for x in ds_jobs.columns if x != 'start' and x != 'website']).sponsored.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# making a copy so I can refer to original if needed without having to re-run\n",
    "ds_jobs_clean = ds_jobs.copy()\n",
    "\n",
    "# drop duplicates (not considering 'start' column because I want to eliminate things that appeared more than once)\n",
    "# (also not considering website because the sponsored ads sometimes have different links each time they appear)\n",
    "ds_jobs_clean.drop_duplicates([x for x in ds_jobs.columns if x != 'start' and x != 'website'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 264,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index([u'company', u'date_posted', u'location', u'number_reviews', u'salary',\n",
       "       u'search_city', u'sponsored', u'star_rating', u'start', u'summary',\n",
       "       u'title', u'website', u'how_paid', u'annual_salary', u'is_sponsored',\n",
       "       u'time_since_posted', u'in_city', u'page'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 264,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ds_jobs_clean.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "focus": false,
    "id": "faac26dc-392a-4f90-a397-144a070702cb"
   },
   "source": [
    "Lastly, we need to clean up salary data. \n",
    "\n",
    "1. Only a small number of the scraped results have salary information - only these will be used for modeling.\n",
    "1. Some of the salaries are not yearly but hourly or weekly, these will not be useful to us for now\n",
    "1. Some of the entries may be duplicated\n",
    "1. The salaries are given as text and usually with ranges.\n",
    "\n",
    "#### Find the entries with annual salary entries, by filtering the entries without salaries or salaries that are not yearly (filter those that refer to hour or week). Also, remove duplicate entries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "$120,000 a year               8\n",
       "$150,000 - $200,000 a year    6\n",
       "$150,000 a year               6\n",
       "$130,000 a year               6\n",
       "$110,000 a year               5\n",
       "$140,000 - $160,000 a year    5\n",
       "$100,000 a year               4\n",
       "$100,000 - $125,000 a year    4\n",
       "$120,000 - $150,000 a year    4\n",
       "$160,000 a year               4\n",
       "$140,000 a year               4\n",
       "$200,000 a year               4\n",
       "$80,000 a year                3\n",
       "$180,000 a year               3\n",
       "$80,000 - $100,000 a year     3\n",
       "$100,000 - $120,000 a year    3\n",
       "$70,286 - $88,213 a year      3\n",
       "$5,400 - $6,500 a month       3\n",
       "$90,000 a year                2\n",
       "$59,708 - $72,246 a year      2\n",
       "$110,000 - $180,000 a year    2\n",
       "$90,000 - $120,000 a year     2\n",
       "$90,000 - $140,000 a year     2\n",
       "$110,000 - $140,000 a year    2\n",
       "$15 - $20 an hour             2\n",
       "$4,319 - $6,183 a month       2\n",
       "$50,000 - $65,000 a year      2\n",
       "$98,202 - $125,346 a year     2\n",
       "$125,000 a year               2\n",
       "$80,000 - $160,000 a year     2\n",
       "$70,000 - $85,000 a year      2\n",
       "$75,000 - $120,000 a year     2\n",
       "$55,000 a year                2\n",
       "$3,564 - $4,792 a month       2\n",
       "$60,000 - $70,000 a year      2\n",
       "$85 an hour                   2\n",
       "$120,000 - $160,000 a year    2\n",
       "$125,000 - $175,000 a year    2\n",
       "$150,000 - $170,000 a year    2\n",
       "$60 an hour                   2\n",
       "$20 - $25 an hour             2\n",
       "$5,168 - $7,393 a month       2\n",
       "$2,417 - $3,192 a month       2\n",
       "$70,000 - $90,000 a year      2\n",
       "$88,305 - $146,570 a year     2\n",
       "$45,000 a year                2\n",
       "$120,000 - $130,000 a year    2\n",
       "$6,250 - $10,833 a month      2\n",
       "$75,000 - $90,000 a year      2\n",
       "$4,495 - $6,433 a month       2\n",
       "$88,305 - $114,802 a year     2\n",
       "$90,000 - $110,000 a year     2\n",
       "$3,077 - $4,113 a month       2\n",
       "$68,239 - $85,644 a year      2\n",
       "$57 an hour                   2\n",
       "$140,000 - $180,000 a year    2\n",
       "$35,000 - $50,000 a year      1\n",
       "$92,145 - $141,555 a year     1\n",
       "$80,000 - $130,000 a year     1\n",
       "$100,000 - $115,000 a year    1\n",
       "$68,239 a year                1\n",
       "$85,000 - $110,000 a year     1\n",
       "$135,000 - $200,000 a year    1\n",
       "$4,313 - $5,657 a month       1\n",
       "$11.25 an hour                1\n",
       "$84,302 - $109,592 a year     1\n",
       "$2,420 - $2,667 a month       1\n",
       "$115,000 a year               1\n",
       "$65,000 a year                1\n",
       "$65,572 - $84,611 a year      1\n",
       "$60,000 a year                1\n",
       "$3,175 - $4,540 a month       1\n",
       "$32,000 - $34,000 a year      1\n",
       "$9.75 - $14.15 an hour        1\n",
       "$65,000 - $75,000 a year      1\n",
       "$95,000 a year                1\n",
       "$110,000 - $130,000 a year    1\n",
       "$150,000 - $165,000 a year    1\n",
       "$100,000 - $150,000 a year    1\n",
       "$25,000 a year                1\n",
       "$25.77 - $39.22 an hour       1\n",
       "$180,000 - $230,000 a year    1\n",
       "$150,000 - $190,000 a year    1\n",
       "$65,232 - $92,625 a year      1\n",
       "$200,000 - $300,000 a year    1\n",
       "$90 an hour                   1\n",
       "$80,000 - $120,000 a year     1\n",
       "$190,000 - $200,000 a year    1\n",
       "$50 an hour                   1\n",
       "$77,315 a year                1\n",
       "$125,000 - $200,000 a year    1\n",
       "$170,000 a year               1\n",
       "$42,000 a year                1\n",
       "$199,000 a year               1\n",
       "$115,000 - $130,000 a year    1\n",
       "$2,805 - $3,727 a month       1\n",
       "$41,057 - $61,669 a year      1\n",
       "$165,000 - $195,000 a year    1\n",
       "$18 an hour                   1\n",
       "$54,792 - $77,430 a year      1\n",
       "                             ..\n",
       "$69,900 a year                1\n",
       "$90,000 - $180,000 a year     1\n",
       "$160,000 - $180,000 a year    1\n",
       "$35,000 a year                1\n",
       "$80 an hour                   1\n",
       "$29 an hour                   1\n",
       "$135,000 a year               1\n",
       "$45,000 - $55,000 a year      1\n",
       "$51,706 a year                1\n",
       "$4,599 - $6,066 a month       1\n",
       "$200,000 - $250,000 a year    1\n",
       "$100,000 - $130,000 a year    1\n",
       "$109,900 - $126,100 a year    1\n",
       "$75,000 - $110,000 a year     1\n",
       "$130,000 - $160,000 a year    1\n",
       "$70,000 a year                1\n",
       "$145,000 a year               1\n",
       "$3,007 - $4,008 a month       1\n",
       "$37,680 - $49,308 a year      1\n",
       "$886 a week                   1\n",
       "$50,000 a year                1\n",
       "$70,286 a year                1\n",
       "$76,082 - $97,340 a year      1\n",
       "$77,394 - $119,947 a year     1\n",
       "$55,263 - $93,815 a year      1\n",
       "$105,000 - $120,000 a year    1\n",
       "$36,381 - $48,462 a year      1\n",
       "$110,000 - $120,000 a year    1\n",
       "$13 - $18 an hour             1\n",
       "$92,145 - $119,794 a year     1\n",
       "$47,860 - $67,712 a year      1\n",
       "$28 an hour                   1\n",
       "$125 an hour                  1\n",
       "$50,000 - $60,000 a year      1\n",
       "$68,239 - $80,000 a year      1\n",
       "$80,000 - $90,000 a year      1\n",
       "$135,000 - $165,000 a year    1\n",
       "$5,583 a month                1\n",
       "$15 - $17 an hour             1\n",
       "$70,000 - $145,000 a year     1\n",
       "$175,000 - $215,000 a year    1\n",
       "$63,863 a year                1\n",
       "$40 - $50 an hour             1\n",
       "$24,000 a year                1\n",
       "$42.73 - $51.94 an hour       1\n",
       "$53,051 - $105,000 a year     1\n",
       "$21.80 an hour                1\n",
       "$150,000 - $205,000 a year    1\n",
       "$150,000 - $180,000 a year    1\n",
       "$185,000 a year               1\n",
       "$40,000 a year                1\n",
       "$145,000 - $175,000 a year    1\n",
       "$68,239 - $78,475 a year      1\n",
       "$90,000 - $130,000 a year     1\n",
       "$18.66 - $26.99 an hour       1\n",
       "$1,250 a week                 1\n",
       "$1,088 a week                 1\n",
       "$130,000 - $170,000 a year    1\n",
       "$5,833 a month                1\n",
       "$32,000 a year                1\n",
       "$180,000 - $220,000 a year    1\n",
       "$160 an hour                  1\n",
       "$100,000 - $110,000 a year    1\n",
       "$78,549 - $104,614 a year     1\n",
       "$5,259 - $8,624 a month       1\n",
       "$61,491 - $79,275 a year      1\n",
       "$135,000 - $180,000 a year    1\n",
       "$51,603 - $100,736 a year     1\n",
       "$788 a week                   1\n",
       "$26 an hour                   1\n",
       "$90,000 - $100,000 a year     1\n",
       "$150 an hour                  1\n",
       "$87,657 - $112,956 a year     1\n",
       "$45 an hour                   1\n",
       "$12 - $15 an hour             1\n",
       "$98,800 - $126,700 a year     1\n",
       "$125,000 - $150,000 a year    1\n",
       "$42 an hour                   1\n",
       "$48,060 - $63,036 a year      1\n",
       "$165,000 a year               1\n",
       "$5,541 a month                1\n",
       "$23.32 an hour                1\n",
       "$19 an hour                   1\n",
       "$30 an hour                   1\n",
       "$2,623 - $3,644 a month       1\n",
       "$46.20 - $56.15 an hour       1\n",
       "$170,000 - $190,000 a year    1\n",
       "$76,340 - $100,322 a year     1\n",
       "$12.50 - $18.50 an hour       1\n",
       "$44,590 - $119,145 a year     1\n",
       "$45 - $55 an hour             1\n",
       "$4,917 - $6,489 a month       1\n",
       "$85,500 a year                1\n",
       "$17.79 an hour                1\n",
       "$150,000 - $175,000 a year    1\n",
       "$20 an hour                   1\n",
       "$55 an hour                   1\n",
       "$200,000 - $230,000 a year    1\n",
       "$62,338 - $160,300 a year     1\n",
       "$38.47 - $48.28 an hour       1\n",
       "Name: salary, dtype: int64"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# investigating to see what kinds of variables I have here.\n",
    "pd.options.display.max_rows = 200\n",
    "ds_jobs_clean.salary.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n",
      "35000.0\n",
      "20000.0\n",
      "20000.0\n",
      "\n",
      "\n",
      "yearly\n",
      "hourly\n",
      "monthly\n",
      "weekly\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "import numpy as np\n",
    "def get_standardized_salary(salary_string):\n",
    "    if salary_string:\n",
    "        if re.findall('(.*) a year', salary_string):\n",
    "            matches = re.findall('([0-9]+,[0-9]+)', salary_string)\n",
    "            return np.mean([float(salary.replace(',', '')) for salary in matches ])\n",
    "        elif re.findall('(.*) a month', salary_string):\n",
    "            matches = re.findall('([0-9]+,[0-9]+|[0-9]+)', salary_string)\n",
    "            return np.mean([float(salary.replace(',', '')) for salary in matches ])*12\n",
    "        elif re.findall('(.*) a week', salary_string):\n",
    "            matches = re.findall('([0-9]+,[0-9]+|[0-9]+)', salary_string)\n",
    "            return np.mean([float(salary.replace(',', '')) for salary in matches ])*52\n",
    "        elif re.findall('(.*) a day', salary_string):\n",
    "            matches = re.findall('([0-9]+,[0-9]+|[0-9]+)', salary_string)\n",
    "            return np.mean([float(salary.replace(',', '')) for salary in matches ])*5*52\n",
    "        elif re.findall('(.*) an hour', salary_string):\n",
    "            matches = re.findall('([0-9]+\\.[0-9]+|[0-9]+)', salary_string)\n",
    "            return np.mean([float(salary.replace(',', '')) for salary in matches ])*8*5*52\n",
    "    else:\n",
    "        return None\n",
    "\n",
    "# How paid (monthly, yearly, etc.) may affect outcome so I want to keep track of that \n",
    "def get_how_paid(salary_string):\n",
    "    if salary_string:\n",
    "        if re.findall('(.*) a year', salary_string):\n",
    "            return 'yearly'\n",
    "        elif re.findall('(.*) a month', salary_string):\n",
    "            return 'monthly'\n",
    "        elif re.findall('(.*) a week', salary_string):\n",
    "            return 'weekly'\n",
    "        elif re.findall('(.*) a day', salary_string):\n",
    "            return 'daily'\n",
    "        elif re.findall('(.*) an hour', salary_string):\n",
    "            return 'hourly'\n",
    "        else:\n",
    "            return None\n",
    "# checking if it works on multiple types\n",
    "print get_standardized_salary(None) \n",
    "print get_standardized_salary('20,000 to 50,000 a year')\n",
    "print get_standardized_salary('$20,000 a year')\n",
    "print get_standardized_salary('$20,000 a year')\n",
    "print '\\n'\n",
    "print get_how_paid('125,000âˆ’150,000 a year')\n",
    "print get_how_paid('$17.79 an hour')\n",
    "print get_how_paid('2,000 - 2,889 a month')\n",
    "print get_how_paid('$2000 a week')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>salary</th>\n",
       "      <th>how_paid</th>\n",
       "      <th>annual_salary</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>6900</th>\n",
       "      <td>$199,000 a year</td>\n",
       "      <td>yearly</td>\n",
       "      <td>199000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12098</th>\n",
       "      <td>$75,000 - $110,000 a year</td>\n",
       "      <td>yearly</td>\n",
       "      <td>92500.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24054</th>\n",
       "      <td>$45,000 a year</td>\n",
       "      <td>yearly</td>\n",
       "      <td>45000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6759</th>\n",
       "      <td>$50,000 - $65,000 a year</td>\n",
       "      <td>yearly</td>\n",
       "      <td>57500.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3584</th>\n",
       "      <td>$150,000 a year</td>\n",
       "      <td>yearly</td>\n",
       "      <td>150000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7390</th>\n",
       "      <td>$200,000 - $230,000 a year</td>\n",
       "      <td>yearly</td>\n",
       "      <td>215000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21857</th>\n",
       "      <td>$15 - $20 an hour</td>\n",
       "      <td>hourly</td>\n",
       "      <td>36400.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19204</th>\n",
       "      <td>$4,319 - $6,183 a month</td>\n",
       "      <td>monthly</td>\n",
       "      <td>63012.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6925</th>\n",
       "      <td>$150,000 a year</td>\n",
       "      <td>yearly</td>\n",
       "      <td>150000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12158</th>\n",
       "      <td>$80,000 - $100,000 a year</td>\n",
       "      <td>yearly</td>\n",
       "      <td>90000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12190</th>\n",
       "      <td>$160,000 a year</td>\n",
       "      <td>yearly</td>\n",
       "      <td>160000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6981</th>\n",
       "      <td>$200,000 a year</td>\n",
       "      <td>yearly</td>\n",
       "      <td>200000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18647</th>\n",
       "      <td>$3,564 - $4,792 a month</td>\n",
       "      <td>monthly</td>\n",
       "      <td>50136.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6718</th>\n",
       "      <td>$70,286 - $88,213 a year</td>\n",
       "      <td>yearly</td>\n",
       "      <td>79249.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13114</th>\n",
       "      <td>$90,000 - $130,000 a year</td>\n",
       "      <td>yearly</td>\n",
       "      <td>110000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6596</th>\n",
       "      <td>$70,286 - $88,213 a year</td>\n",
       "      <td>yearly</td>\n",
       "      <td>79249.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12904</th>\n",
       "      <td>$75,000 - $120,000 a year</td>\n",
       "      <td>yearly</td>\n",
       "      <td>97500.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15084</th>\n",
       "      <td>$5,259 - $8,624 a month</td>\n",
       "      <td>monthly</td>\n",
       "      <td>83298.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22054</th>\n",
       "      <td>$25.77 - $39.22 an hour</td>\n",
       "      <td>hourly</td>\n",
       "      <td>67589.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24021</th>\n",
       "      <td>$77,315 a year</td>\n",
       "      <td>yearly</td>\n",
       "      <td>77315.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                           salary how_paid  annual_salary\n",
       "6900              $199,000 a year   yearly       199000.0\n",
       "12098   $75,000 - $110,000 a year   yearly        92500.0\n",
       "24054              $45,000 a year   yearly        45000.0\n",
       "6759     $50,000 - $65,000 a year   yearly        57500.0\n",
       "3584              $150,000 a year   yearly       150000.0\n",
       "7390   $200,000 - $230,000 a year   yearly       215000.0\n",
       "21857           $15 - $20 an hour   hourly        36400.0\n",
       "19204     $4,319 - $6,183 a month  monthly        63012.0\n",
       "6925              $150,000 a year   yearly       150000.0\n",
       "12158   $80,000 - $100,000 a year   yearly        90000.0\n",
       "12190             $160,000 a year   yearly       160000.0\n",
       "6981              $200,000 a year   yearly       200000.0\n",
       "18647     $3,564 - $4,792 a month  monthly        50136.0\n",
       "6718     $70,286 - $88,213 a year   yearly        79249.5\n",
       "13114   $90,000 - $130,000 a year   yearly       110000.0\n",
       "6596     $70,286 - $88,213 a year   yearly        79249.5\n",
       "12904   $75,000 - $120,000 a year   yearly        97500.0\n",
       "15084     $5,259 - $8,624 a month  monthly        83298.0\n",
       "22054     $25.77 - $39.22 an hour   hourly        67589.6\n",
       "24021              $77,315 a year   yearly        77315.0"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ds_jobs_clean['how_paid'] = ds_jobs_clean.salary.apply(get_how_paid)\n",
    "ds_jobs_clean['annual_salary'] = ds_jobs_clean.salary.apply(get_standardized_salary)\n",
    "ds_jobs_clean[['salary', 'how_paid', 'annual_salary']][ds_jobs_clean.salary.notnull()].sample(frac=1).head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "0\n"
     ]
    }
   ],
   "source": [
    "# checking that none of my salary info got missed\n",
    "print ds_jobs_clean[(ds_jobs_clean.salary.notnull()) & (ds_jobs_clean.annual_salary.isnull())].shape[0]\n",
    "print ds_jobs_clean[(ds_jobs_clean.salary.notnull()) & (ds_jobs_clean.how_paid.isnull())].shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>company</th>\n",
       "      <th>date_posted</th>\n",
       "      <th>location</th>\n",
       "      <th>number_reviews</th>\n",
       "      <th>salary</th>\n",
       "      <th>search_city</th>\n",
       "      <th>sponsored</th>\n",
       "      <th>star_rating</th>\n",
       "      <th>start</th>\n",
       "      <th>summary</th>\n",
       "      <th>title</th>\n",
       "      <th>website</th>\n",
       "      <th>how_paid</th>\n",
       "      <th>annual_salary</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Cotiviti</td>\n",
       "      <td>30+ days ago</td>\n",
       "      <td>Atlanta, GA</td>\n",
       "      <td>30.0</td>\n",
       "      <td>None</td>\n",
       "      <td>Atlanta, GA</td>\n",
       "      <td>Sponsored</td>\n",
       "      <td>3.35</td>\n",
       "      <td>0</td>\n",
       "      <td>This is a pioneering data scientist who will participate in expanding the new analytics backbone. Cotiviti is looking for an industry leading Data Scientist to...</td>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>http://www.indeed.com/pagead/clk?mo=r&amp;ad=-6NYlbfkN0AbexXlh6WlNaC12RNLKcRQH8fywLm61v9KQllly0vTVrm9U0Iy0AOsYwOq9YOpDX03iprvWHw_SY6xCXG90mwLvOd8fb5BdJ-fu_-2tfp_KoWry1hPm7FaVRyBGPoeYEaNltu7W5i0j-OYtPh1ozEJ4oN7u_zLF7PnEIYwsSJTUyra1nlPHHQpGEq7KH9P1UhJyt0gLdmaXr7oC9iG41hrLTLQM6Dy4jOfZIDOXaBdIjV_m-vrLzXNwMCEHNxAuNUsOUWu9fNUIO6h2dpkDtS46fwUq5bUGThLBpg1h_JsmngU4OOpPDCmzhyOIZujq7kpNxhKt2UxH0Sm5knOVKSmYxJ1lNKEnygA8DCD6U_1zkkTxJJ5LBcAr9lpizyc6MVLmeSSISBIrGKE9SvJv_WjfNXpznu3719huu8jLhA-4dpvovDIXnXZf5ddKRiNMGDJ_o8d2rLvrnNdM6ksJXYj&amp;p=1&amp;sk=&amp;fvj=0</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Cox Automotive</td>\n",
       "      <td>30+ days ago</td>\n",
       "      <td>Atlanta, GA</td>\n",
       "      <td>46.0</td>\n",
       "      <td>None</td>\n",
       "      <td>Atlanta, GA</td>\n",
       "      <td>Sponsored</td>\n",
       "      <td>3.40</td>\n",
       "      <td>0</td>\n",
       "      <td>Interprets problems and develops solutions to business problems using data analysis, data mining, optimization tools, and machine learning techniques and...</td>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>http://www.indeed.com/pagead/clk?mo=r&amp;ad=-6NYlbfkN0Aqmv_5JD5v6gg1ICRL12VY6BolF0XAUkQtat1DEGOKAas7v4hqpX3lzUM4h7L4VGsyuyDvf1POStkSJgHsuP2fB8YliLIijj53wvHBII5P9eQQwhBoT2Vrz0Dv0LOR9cmhA2uclIYN001l_R0jB6OflQ3KEmNIKzoNezeQCnu5X1bPju79uAEHbaTS6LdJvB-hJTy0PZPPeNKSkMyWxp3Wc2N8qN2FIq69xIhd7NBdjwnWuSZEDZvdGAtcdwsplmc_6i_owekmLU0Zj9rRIQYMM4CCSqkchPU_LsOfeRYl0NSHhXylFvCq02OyIvg1KznvqQ7PPXo_fB0sk1_bs3_otngXRLhv8vkj1BFB91Yk951kq_RGaTq5Z94UiOx8vqbM6V4495DCvkTFhmxPx8jUsGpZ6kQVHUXPRdq4CZxNPdlpgypTkUKGSHiuF2jTN7edfKfbZELHMxMILPWKq1PX7Etfm45MtiI=&amp;p=2&amp;sk=&amp;fvj=0</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Honeywell</td>\n",
       "      <td>30+ days ago</td>\n",
       "      <td>Atlanta, GA</td>\n",
       "      <td>3557.0</td>\n",
       "      <td>None</td>\n",
       "      <td>Atlanta, GA</td>\n",
       "      <td>Sponsored</td>\n",
       "      <td>3.70</td>\n",
       "      <td>0</td>\n",
       "      <td>Support and mentor data scientists. Minimum of 5 years of experience in a combination of data science, machine learning, predictive analytics, statistical...</td>\n",
       "      <td>Principal Data Scientist - Atlanta, GA</td>\n",
       "      <td>http://www.indeed.com/pagead/clk?mo=r&amp;ad=-6NYlbfkN0BT1oD7gxL4d4q7k2XK_xqJz55UkLlcqeX4XFuXt5iz9snYfsSUT3YCjhoIHnNQ-5Dn3WpSwV_to5gRmnY1dWxevmGFzqLqqlIFz_9Edyh1_IXncaR6MCLo7f5ouI8dmb8uuCR-Gmx3D0JDk0Mr6-bDRl6_oL__-yabT9kowHDUPeBtZkMJognwbgSn7JKNdyR8xVuWFFOTK19pmuU2dd5avUCBVFtU2sKLt8sbDK9kZmatBTvLWw9mSk9saicemGkngM_SN-JaPwW2wHCjEO5hK98T035f01nOI9o3ia3L5wR1VUQJgkEqq37uz9VQlxlzLpE9e-1UkEpSSuVpab7uYAzIunguUW-Veb9PE7QBNJkn1V2aLOTbuEYDgbiHxkQQy5UqMb6a7SV1IxkpbHkbfInjk9I-rbwVtqZduH3r8D_W_d1EbYFUhzGETCT-VTLBqqwyAv_rFadY2vmiP5R3t_H5qjb5foJI0iHryGOAf4taEETWvPjj5-ovMDCSWJlDwEvyiMmFjw==&amp;p=3&amp;sk=&amp;fvj=0</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Vision3 Solutions, Inc</td>\n",
       "      <td>1 day ago</td>\n",
       "      <td>Atlanta, GA</td>\n",
       "      <td>NaN</td>\n",
       "      <td>$90 an hour</td>\n",
       "      <td>Atlanta, GA</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>Data Scientist- Big Data*. May write code to automate reports and templates and consolidate data into reports and knowledge. 12 Months Contract*....</td>\n",
       "      <td>Data Scientist- Big Data</td>\n",
       "      <td>http://www.indeed.com/company/Vision3-Solutions,-Inc/jobs/Data-Scientist-1a8c086f5f6f1294?r=1&amp;fccid=37d33d67f3fba52b</td>\n",
       "      <td>hourly</td>\n",
       "      <td>187200.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>FraudScope</td>\n",
       "      <td>2 days ago</td>\n",
       "      <td>Atlanta, GA</td>\n",
       "      <td>NaN</td>\n",
       "      <td>None</td>\n",
       "      <td>Atlanta, GA</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>Experience with healthcare-related data and familiarity with current methods applied to healthcare data is preferred....</td>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>http://www.indeed.com/company/FraudScope/jobs/Data-Scientist-d72c337465398caf?r=1&amp;fccid=e87f46501099545c</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  company   date_posted     location  number_reviews  \\\n",
       "0                Cotiviti  30+ days ago  Atlanta, GA            30.0   \n",
       "1          Cox Automotive  30+ days ago  Atlanta, GA            46.0   \n",
       "2               Honeywell  30+ days ago  Atlanta, GA          3557.0   \n",
       "3  Vision3 Solutions, Inc     1 day ago  Atlanta, GA             NaN   \n",
       "4              FraudScope    2 days ago  Atlanta, GA             NaN   \n",
       "\n",
       "        salary  search_city  sponsored  star_rating  start  \\\n",
       "0         None  Atlanta, GA  Sponsored         3.35      0   \n",
       "1         None  Atlanta, GA  Sponsored         3.40      0   \n",
       "2         None  Atlanta, GA  Sponsored         3.70      0   \n",
       "3  $90 an hour  Atlanta, GA       None          NaN      0   \n",
       "4         None  Atlanta, GA       None          NaN      0   \n",
       "\n",
       "                                                                                                                                                              summary  \\\n",
       "0  This is a pioneering data scientist who will participate in expanding the new analytics backbone. Cotiviti is looking for an industry leading Data Scientist to...   \n",
       "1        Interprets problems and develops solutions to business problems using data analysis, data mining, optimization tools, and machine learning techniques and...   \n",
       "2       Support and mentor data scientists. Minimum of 5 years of experience in a combination of data science, machine learning, predictive analytics, statistical...   \n",
       "3                Data Scientist- Big Data*. May write code to automate reports and templates and consolidate data into reports and knowledge. 12 Months Contract*....   \n",
       "4                                            Experience with healthcare-related data and familiarity with current methods applied to healthcare data is preferred....   \n",
       "\n",
       "                                    title  \\\n",
       "0                          Data Scientist   \n",
       "1                          Data Scientist   \n",
       "2  Principal Data Scientist - Atlanta, GA   \n",
       "3                Data Scientist- Big Data   \n",
       "4                          Data Scientist   \n",
       "\n",
       "                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                           website  \\\n",
       "0                                                          http://www.indeed.com/pagead/clk?mo=r&ad=-6NYlbfkN0AbexXlh6WlNaC12RNLKcRQH8fywLm61v9KQllly0vTVrm9U0Iy0AOsYwOq9YOpDX03iprvWHw_SY6xCXG90mwLvOd8fb5BdJ-fu_-2tfp_KoWry1hPm7FaVRyBGPoeYEaNltu7W5i0j-OYtPh1ozEJ4oN7u_zLF7PnEIYwsSJTUyra1nlPHHQpGEq7KH9P1UhJyt0gLdmaXr7oC9iG41hrLTLQM6Dy4jOfZIDOXaBdIjV_m-vrLzXNwMCEHNxAuNUsOUWu9fNUIO6h2dpkDtS46fwUq5bUGThLBpg1h_JsmngU4OOpPDCmzhyOIZujq7kpNxhKt2UxH0Sm5knOVKSmYxJ1lNKEnygA8DCD6U_1zkkTxJJ5LBcAr9lpizyc6MVLmeSSISBIrGKE9SvJv_WjfNXpznu3719huu8jLhA-4dpvovDIXnXZf5ddKRiNMGDJ_o8d2rLvrnNdM6ksJXYj&p=1&sk=&fvj=0   \n",
       "1                                              http://www.indeed.com/pagead/clk?mo=r&ad=-6NYlbfkN0Aqmv_5JD5v6gg1ICRL12VY6BolF0XAUkQtat1DEGOKAas7v4hqpX3lzUM4h7L4VGsyuyDvf1POStkSJgHsuP2fB8YliLIijj53wvHBII5P9eQQwhBoT2Vrz0Dv0LOR9cmhA2uclIYN001l_R0jB6OflQ3KEmNIKzoNezeQCnu5X1bPju79uAEHbaTS6LdJvB-hJTy0PZPPeNKSkMyWxp3Wc2N8qN2FIq69xIhd7NBdjwnWuSZEDZvdGAtcdwsplmc_6i_owekmLU0Zj9rRIQYMM4CCSqkchPU_LsOfeRYl0NSHhXylFvCq02OyIvg1KznvqQ7PPXo_fB0sk1_bs3_otngXRLhv8vkj1BFB91Yk951kq_RGaTq5Z94UiOx8vqbM6V4495DCvkTFhmxPx8jUsGpZ6kQVHUXPRdq4CZxNPdlpgypTkUKGSHiuF2jTN7edfKfbZELHMxMILPWKq1PX7Etfm45MtiI=&p=2&sk=&fvj=0   \n",
       "2  http://www.indeed.com/pagead/clk?mo=r&ad=-6NYlbfkN0BT1oD7gxL4d4q7k2XK_xqJz55UkLlcqeX4XFuXt5iz9snYfsSUT3YCjhoIHnNQ-5Dn3WpSwV_to5gRmnY1dWxevmGFzqLqqlIFz_9Edyh1_IXncaR6MCLo7f5ouI8dmb8uuCR-Gmx3D0JDk0Mr6-bDRl6_oL__-yabT9kowHDUPeBtZkMJognwbgSn7JKNdyR8xVuWFFOTK19pmuU2dd5avUCBVFtU2sKLt8sbDK9kZmatBTvLWw9mSk9saicemGkngM_SN-JaPwW2wHCjEO5hK98T035f01nOI9o3ia3L5wR1VUQJgkEqq37uz9VQlxlzLpE9e-1UkEpSSuVpab7uYAzIunguUW-Veb9PE7QBNJkn1V2aLOTbuEYDgbiHxkQQy5UqMb6a7SV1IxkpbHkbfInjk9I-rbwVtqZduH3r8D_W_d1EbYFUhzGETCT-VTLBqqwyAv_rFadY2vmiP5R3t_H5qjb5foJI0iHryGOAf4taEETWvPjj5-ovMDCSWJlDwEvyiMmFjw==&p=3&sk=&fvj=0   \n",
       "3                                                                                                                                                                                                                                                                                                                                                                                                                                                                                             http://www.indeed.com/company/Vision3-Solutions,-Inc/jobs/Data-Scientist-1a8c086f5f6f1294?r=1&fccid=37d33d67f3fba52b   \n",
       "4                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                         http://www.indeed.com/company/FraudScope/jobs/Data-Scientist-d72c337465398caf?r=1&fccid=e87f46501099545c   \n",
       "\n",
       "  how_paid  annual_salary  \n",
       "0     None            NaN  \n",
       "1     None            NaN  \n",
       "2     None            NaN  \n",
       "3   hourly       187200.0  \n",
       "4     None            NaN  "
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# my cities have '+' in place of spaces because of how I had to input them into the URL, so I want to fix that\n",
    "ds_jobs_clean.search_city = ds_jobs_clean.search_city.str.replace('+' ,' ')\n",
    "\n",
    "# number of reviews has # and \"reviews\" so I want to clean that up and convert to numeric\n",
    "ds_jobs_clean.number_reviews = pd.to_numeric(ds_jobs_clean.number_reviews.str.replace(' reviews' ,'').str.replace(',' ,''))\n",
    "ds_jobs_clean.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sponsored</th>\n",
       "      <th>is_sponsored</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Sponsored</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Sponsored</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Sponsored</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>None</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>None</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>None</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>None</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>None</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>None</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>None</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>None</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>None</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>None</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Sponsored</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>Sponsored</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>None</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>None</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>None</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>None</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>None</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    sponsored  is_sponsored\n",
       "0   Sponsored             1\n",
       "1   Sponsored             1\n",
       "2   Sponsored             1\n",
       "3        None             0\n",
       "4        None             0\n",
       "5        None             0\n",
       "6        None             0\n",
       "7        None             0\n",
       "8        None             0\n",
       "9        None             0\n",
       "10       None             0\n",
       "11       None             0\n",
       "12       None             0\n",
       "13  Sponsored             1\n",
       "14  Sponsored             1\n",
       "18       None             0\n",
       "19       None             0\n",
       "20       None             0\n",
       "21       None             0\n",
       "22       None             0"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# sponsored has mutliple options, and I just want to have a dummy variable of whether something is sponsored or not\n",
    "ds_jobs_clean['is_sponsored'] = ds_jobs_clean.sponsored.apply(lambda x: 1 if x else 0)\n",
    "ds_jobs_clean[['sponsored', 'is_sponsored']].head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "30+ days ago      2490\n",
       "7 days ago         200\n",
       "8 days ago         181\n",
       "1 day ago          179\n",
       "2 days ago         155\n",
       "3 days ago         141\n",
       "9 days ago         133\n",
       "21 days ago        132\n",
       "22 days ago        127\n",
       "14 days ago        119\n",
       "30 days ago        118\n",
       "15 days ago        115\n",
       "10 days ago        113\n",
       "16 days ago        112\n",
       "23 days ago        109\n",
       "6 days ago         104\n",
       "28 days ago        103\n",
       "29 days ago         95\n",
       "13 days ago         93\n",
       "27 days ago         90\n",
       "17 days ago         83\n",
       "24 days ago         80\n",
       "20 days ago         75\n",
       "4 days ago          35\n",
       "11 days ago         31\n",
       "5 days ago          30\n",
       "26 days ago         25\n",
       "18 days ago         25\n",
       "25 days ago         25\n",
       "12 days ago         22\n",
       "19 days ago         18\n",
       "19 hours ago        15\n",
       "17 hours ago        15\n",
       "16 hours ago        14\n",
       "10 hours ago        13\n",
       "21 hours ago        11\n",
       "22 hours ago        10\n",
       "4 hours ago          9\n",
       "18 hours ago         9\n",
       "15 hours ago         8\n",
       "7 hours ago          8\n",
       "11 hours ago         8\n",
       "9 hours ago          8\n",
       "13 hours ago         7\n",
       "6 hours ago          6\n",
       "14 hours ago         6\n",
       "12 hours ago         5\n",
       "20 hours ago         5\n",
       "2 hours ago          5\n",
       "1 hour ago           4\n",
       "8 hours ago          4\n",
       "23 hours ago         3\n",
       "5 hours ago          1\n",
       "55 minutes ago       1\n",
       "3 hours ago          1\n",
       "52 minutes ago       1\n",
       "Name: date_posted, dtype: int64"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# investigating date_posted column to figure out how to best convert, what my categories should be\n",
    "ds_jobs_clean.date_posted.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "in the last day\n",
      "in the last day\n",
      "7-12 days ago\n",
      "1-6 days ago\n",
      "13-18 days ago\n",
      "25-30 days ago\n",
      "more than 30 days ago\n"
     ]
    }
   ],
   "source": [
    "def categorize_time_since_posted(time_since_posted_str):\n",
    "    categories = ['in the last day', '1-6 days ago', '7-12 days ago', '13-18 days ago', '19-24 days ago', '25-30 days ago', 'more than 30 days ago']\n",
    "    if re.findall('hour', time_since_posted_str) or re.findall('minutes', time_since_posted_str):\n",
    "        return categories[0]\n",
    "    elif re.findall('30\\+', time_since_posted_str):\n",
    "        return categories[-1]\n",
    "    else:\n",
    "        days_ago = int(re.findall('(.*) day', time_since_posted_str)[0])\n",
    "        if days_ago <= 6:\n",
    "            return categories[1]\n",
    "        elif days_ago <= 12:\n",
    "            return categories[2]\n",
    "        elif days_ago <= 18:\n",
    "            return categories[3]\n",
    "        elif days_ago <= 24:\n",
    "            return categories[4]\n",
    "        else:\n",
    "            return categories[5]\n",
    "# test a few\n",
    "print categorize_time_since_posted('39 minutes ago')\n",
    "print categorize_time_since_posted('17 hours ago')\n",
    "print categorize_time_since_posted('9 days ago')\n",
    "print categorize_time_since_posted('4 days ago')\n",
    "print categorize_time_since_posted('14 days ago')\n",
    "print categorize_time_since_posted('30 days ago')\n",
    "print categorize_time_since_posted('30+ days ago')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "more than 30 days ago    2490\n",
       "7-12 days ago             680\n",
       "1-6 days ago              644\n",
       "13-18 days ago            547\n",
       "19-24 days ago            541\n",
       "25-30 days ago            456\n",
       "in the last day           177\n",
       "Name: date_posted, dtype: int64"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# checking how many end up in each category - looks ok\n",
    "ds_jobs_clean.date_posted.apply(categorize_time_since_posted).value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#applying the function\n",
    "ds_jobs_clean['time_since_posted'] = ds_jobs_clean.date_posted.apply(categorize_time_since_posted)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# examine where location is not the same as the search city (since some have zip codes for example, must do a regex)\n",
    "# I want to use this information to determine whether a job is in the city or not (assuming jobs in the city would pay more)\n",
    "def in_city_proper(search_city, location):\n",
    "    if re.findall(search_city, location):\n",
    "        return 1\n",
    "    else:\n",
    "        return 0\n",
    "ds_jobs_clean['in_city'] = ds_jobs_clean.apply(lambda x: in_city_proper(x.search_city, x.location), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>search_city</th>\n",
       "      <th>location</th>\n",
       "      <th>in_city</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>11966</th>\n",
       "      <td>Boston, MA</td>\n",
       "      <td>Boston, MA</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6300</th>\n",
       "      <td>New York, NY</td>\n",
       "      <td>New York, NY</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4433</th>\n",
       "      <td>Washington, DC</td>\n",
       "      <td>Silver Spring, MD</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7165</th>\n",
       "      <td>New York, NY</td>\n",
       "      <td>Montvale, NJ</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26996</th>\n",
       "      <td>Minneapolis, MN</td>\n",
       "      <td>Minneapolis, MN</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12832</th>\n",
       "      <td>Boston, MA</td>\n",
       "      <td>Cambridge, MA</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12834</th>\n",
       "      <td>Boston, MA</td>\n",
       "      <td>Cambridge, MA 02142 (East Cambridge area)</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3518</th>\n",
       "      <td>Washington, DC</td>\n",
       "      <td>McLean, VA</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21082</th>\n",
       "      <td>San Francisco, CA</td>\n",
       "      <td>San Francisco, CA</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7281</th>\n",
       "      <td>New York, NY</td>\n",
       "      <td>Port Washington, NY</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12114</th>\n",
       "      <td>Boston, MA</td>\n",
       "      <td>Boston, MA</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19057</th>\n",
       "      <td>Seattle, WA</td>\n",
       "      <td>Seattle, WA</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15020</th>\n",
       "      <td>Austin, TX</td>\n",
       "      <td>Austin, TX 78701 (Downtown area)</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21130</th>\n",
       "      <td>San Francisco, CA</td>\n",
       "      <td>San Francisco, CA</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12602</th>\n",
       "      <td>Boston, MA</td>\n",
       "      <td>Boston, MA</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>414</th>\n",
       "      <td>Atlanta, GA</td>\n",
       "      <td>Marietta, GA 30067</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13265</th>\n",
       "      <td>Boston, MA</td>\n",
       "      <td>Cambridge, MA 02139 (Area IV area)</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6431</th>\n",
       "      <td>New York, NY</td>\n",
       "      <td>New York, NY 10029 (Yorkville area)</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12782</th>\n",
       "      <td>Boston, MA</td>\n",
       "      <td>Cambridge, MA 02139 (Area IV area)</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18385</th>\n",
       "      <td>Seattle, WA</td>\n",
       "      <td>Redmond, WA</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13131</th>\n",
       "      <td>Boston, MA</td>\n",
       "      <td>Andover, MA</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6585</th>\n",
       "      <td>New York, NY</td>\n",
       "      <td>New York, NY</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3325</th>\n",
       "      <td>Washington, DC</td>\n",
       "      <td>Arlington, VA 22209 (Radnor-Ft Myer Heights area)</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3924</th>\n",
       "      <td>Washington, DC</td>\n",
       "      <td>Rockville, MD 20852</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22223</th>\n",
       "      <td>San Francisco, CA</td>\n",
       "      <td>Redwood City, CA</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27204</th>\n",
       "      <td>Minneapolis, MN</td>\n",
       "      <td>Chaska, MN</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22357</th>\n",
       "      <td>San Francisco, CA</td>\n",
       "      <td>San Francisco, CA 94105 (Financial District area)</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7290</th>\n",
       "      <td>New York, NY</td>\n",
       "      <td>New York, NY</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6045</th>\n",
       "      <td>New York, NY</td>\n",
       "      <td>New York, NY 10010 (Gramercy area)</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3397</th>\n",
       "      <td>Washington, DC</td>\n",
       "      <td>Washington, DC</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18651</th>\n",
       "      <td>Seattle, WA</td>\n",
       "      <td>Everett, WA 98204 (Holly area)</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4476</th>\n",
       "      <td>Washington, DC</td>\n",
       "      <td>Chantilly, VA 20153</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21802</th>\n",
       "      <td>San Francisco, CA</td>\n",
       "      <td>San Francisco, CA</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6387</th>\n",
       "      <td>New York, NY</td>\n",
       "      <td>New York, NY</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21026</th>\n",
       "      <td>San Francisco, CA</td>\n",
       "      <td>San Francisco, CA</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15024</th>\n",
       "      <td>Austin, TX</td>\n",
       "      <td>Austin, TX 78746</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13144</th>\n",
       "      <td>Boston, MA</td>\n",
       "      <td>Cambridge, MA 02139 (Area IV area)</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18410</th>\n",
       "      <td>Seattle, WA</td>\n",
       "      <td>Seattle, WA</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18965</th>\n",
       "      <td>Seattle, WA</td>\n",
       "      <td>Seattle, WA</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12547</th>\n",
       "      <td>Boston, MA</td>\n",
       "      <td>Watertown, MA</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21278</th>\n",
       "      <td>San Francisco, CA</td>\n",
       "      <td>San Francisco, CA 94111 (Financial District area)</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22296</th>\n",
       "      <td>San Francisco, CA</td>\n",
       "      <td>San Francisco, CA 94105 (Financial District area)</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21050</th>\n",
       "      <td>San Francisco, CA</td>\n",
       "      <td>San Francisco, CA 94107 (South Of Market area)</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6160</th>\n",
       "      <td>New York, NY</td>\n",
       "      <td>New York, NY</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7042</th>\n",
       "      <td>New York, NY</td>\n",
       "      <td>Parsippany, NJ 07054</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3653</th>\n",
       "      <td>Washington, DC</td>\n",
       "      <td>Silver Spring, MD</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21905</th>\n",
       "      <td>San Francisco, CA</td>\n",
       "      <td>South San Francisco, CA 94080</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18679</th>\n",
       "      <td>Seattle, WA</td>\n",
       "      <td>Seattle, WA</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12842</th>\n",
       "      <td>Boston, MA</td>\n",
       "      <td>Boston, MA</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7358</th>\n",
       "      <td>New York, NY</td>\n",
       "      <td>New York, NY</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11991</th>\n",
       "      <td>Boston, MA</td>\n",
       "      <td>Boston, MA</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6459</th>\n",
       "      <td>New York, NY</td>\n",
       "      <td>New York, NY 10167 (Midtown area)</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3764</th>\n",
       "      <td>Washington, DC</td>\n",
       "      <td>Arlington, VA 22203 (Bluemont area)</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9040</th>\n",
       "      <td>New Orleans, LA</td>\n",
       "      <td>New Orleans, LA 70113 (Central City area)</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>Atlanta, GA</td>\n",
       "      <td>Alpharetta, GA</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12660</th>\n",
       "      <td>Boston, MA</td>\n",
       "      <td>Lexington, MA</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4207</th>\n",
       "      <td>Washington, DC</td>\n",
       "      <td>Falls Church, VA</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13432</th>\n",
       "      <td>Boston, MA</td>\n",
       "      <td>Cambridge, MA 02139 (Area IV area)</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3989</th>\n",
       "      <td>Washington, DC</td>\n",
       "      <td>Arlington, VA</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22100</th>\n",
       "      <td>San Francisco, CA</td>\n",
       "      <td>South San Francisco, CA</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21756</th>\n",
       "      <td>San Francisco, CA</td>\n",
       "      <td>South San Francisco, CA</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18670</th>\n",
       "      <td>Seattle, WA</td>\n",
       "      <td>Seattle, WA</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6372</th>\n",
       "      <td>New York, NY</td>\n",
       "      <td>New York, NY</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15018</th>\n",
       "      <td>Austin, TX</td>\n",
       "      <td>Austin, TX</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13263</th>\n",
       "      <td>Boston, MA</td>\n",
       "      <td>Dedham, MA 02026</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6685</th>\n",
       "      <td>New York, NY</td>\n",
       "      <td>New York, NY</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19252</th>\n",
       "      <td>Seattle, WA</td>\n",
       "      <td>Seattle, WA</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6765</th>\n",
       "      <td>New York, NY</td>\n",
       "      <td>New York, NY 10029 (Yorkville area)</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3621</th>\n",
       "      <td>Washington, DC</td>\n",
       "      <td>Rockville, MD</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18277</th>\n",
       "      <td>Seattle, WA</td>\n",
       "      <td>Seattle, WA 98102 (Capitol Hill area)</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>604</th>\n",
       "      <td>Atlanta, GA</td>\n",
       "      <td>Atlanta, GA</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4319</th>\n",
       "      <td>Washington, DC</td>\n",
       "      <td>Washington, DC</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>87</th>\n",
       "      <td>Atlanta, GA</td>\n",
       "      <td>Atlanta, GA</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21803</th>\n",
       "      <td>San Francisco, CA</td>\n",
       "      <td>San Francisco, CA</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9001</th>\n",
       "      <td>New Orleans, LA</td>\n",
       "      <td>New Orleans, LA</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4418</th>\n",
       "      <td>Washington, DC</td>\n",
       "      <td>Vienna, VA</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18905</th>\n",
       "      <td>Seattle, WA</td>\n",
       "      <td>Seattle, WA</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6741</th>\n",
       "      <td>New York, NY</td>\n",
       "      <td>New York, NY</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27055</th>\n",
       "      <td>Minneapolis, MN</td>\n",
       "      <td>Arden Hills, MN</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6306</th>\n",
       "      <td>New York, NY</td>\n",
       "      <td>New York, NY 10013 (Tribeca area)</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22056</th>\n",
       "      <td>San Francisco, CA</td>\n",
       "      <td>San Francisco, CA 94103 (South Of Market area)</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12487</th>\n",
       "      <td>Boston, MA</td>\n",
       "      <td>Cambridge, MA</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6895</th>\n",
       "      <td>New York, NY</td>\n",
       "      <td>New York, NY</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21865</th>\n",
       "      <td>San Francisco, CA</td>\n",
       "      <td>San Francisco, CA 94107 (South Of Market area)</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3431</th>\n",
       "      <td>Washington, DC</td>\n",
       "      <td>Washington, DC</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6580</th>\n",
       "      <td>New York, NY</td>\n",
       "      <td>New York, NY</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3951</th>\n",
       "      <td>Washington, DC</td>\n",
       "      <td>McLean, VA</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12923</th>\n",
       "      <td>Boston, MA</td>\n",
       "      <td>Andover, MA</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12724</th>\n",
       "      <td>Boston, MA</td>\n",
       "      <td>Cambridge, MA</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20933</th>\n",
       "      <td>San Francisco, CA</td>\n",
       "      <td>San Francisco, CA</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18020</th>\n",
       "      <td>Seattle, WA</td>\n",
       "      <td>Seattle, WA</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19022</th>\n",
       "      <td>Seattle, WA</td>\n",
       "      <td>Bellevue, WA</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6009</th>\n",
       "      <td>New York, NY</td>\n",
       "      <td>New York, NY 10022 (Midtown area)</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18101</th>\n",
       "      <td>Seattle, WA</td>\n",
       "      <td>Seattle, WA</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21863</th>\n",
       "      <td>San Francisco, CA</td>\n",
       "      <td>San Ramon, CA</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26934</th>\n",
       "      <td>Minneapolis, MN</td>\n",
       "      <td>Plymouth, MN</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21497</th>\n",
       "      <td>San Francisco, CA</td>\n",
       "      <td>San Francisco, CA</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21624</th>\n",
       "      <td>San Francisco, CA</td>\n",
       "      <td>San Bruno, CA 94066</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12707</th>\n",
       "      <td>Boston, MA</td>\n",
       "      <td>Cambridge, MA</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21273</th>\n",
       "      <td>San Francisco, CA</td>\n",
       "      <td>San Francisco, CA 94111 (Financial District area)</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12665</th>\n",
       "      <td>Boston, MA</td>\n",
       "      <td>Quincy, MA</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12720</th>\n",
       "      <td>Boston, MA</td>\n",
       "      <td>Boston, MA</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21185</th>\n",
       "      <td>San Francisco, CA</td>\n",
       "      <td>San Francisco, CA</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26951</th>\n",
       "      <td>Minneapolis, MN</td>\n",
       "      <td>Eden Prairie, MN 55347</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18393</th>\n",
       "      <td>Seattle, WA</td>\n",
       "      <td>Redmond, WA 98052</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6567</th>\n",
       "      <td>New York, NY</td>\n",
       "      <td>New York, NY</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>83</th>\n",
       "      <td>Atlanta, GA</td>\n",
       "      <td>Atlanta, GA</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6416</th>\n",
       "      <td>New York, NY</td>\n",
       "      <td>New York, NY</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18741</th>\n",
       "      <td>Seattle, WA</td>\n",
       "      <td>Seattle, WA 98103 (Green Lake - Wallingford area)</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22130</th>\n",
       "      <td>San Francisco, CA</td>\n",
       "      <td>San Francisco, CA</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21632</th>\n",
       "      <td>San Francisco, CA</td>\n",
       "      <td>San Francisco, CA</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53</th>\n",
       "      <td>Atlanta, GA</td>\n",
       "      <td>Atlanta, GA</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6615</th>\n",
       "      <td>New York, NY</td>\n",
       "      <td>New York, NY</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21099</th>\n",
       "      <td>San Francisco, CA</td>\n",
       "      <td>San Francisco, CA</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21861</th>\n",
       "      <td>San Francisco, CA</td>\n",
       "      <td>Foster City, CA</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18288</th>\n",
       "      <td>Seattle, WA</td>\n",
       "      <td>Redmond, WA 98052</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>186</th>\n",
       "      <td>Atlanta, GA</td>\n",
       "      <td>Atlanta, GA</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12279</th>\n",
       "      <td>Boston, MA</td>\n",
       "      <td>Boston, MA</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18261</th>\n",
       "      <td>Seattle, WA</td>\n",
       "      <td>Seattle, WA</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12848</th>\n",
       "      <td>Boston, MA</td>\n",
       "      <td>Boston, MA</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7451</th>\n",
       "      <td>New York, NY</td>\n",
       "      <td>New York, NY</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3475</th>\n",
       "      <td>Washington, DC</td>\n",
       "      <td>Reston, VA 20191</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4343</th>\n",
       "      <td>Washington, DC</td>\n",
       "      <td>Chantilly, VA 20151</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6561</th>\n",
       "      <td>New York, NY</td>\n",
       "      <td>New York, NY</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7089</th>\n",
       "      <td>New York, NY</td>\n",
       "      <td>New York, NY</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15048</th>\n",
       "      <td>Austin, TX</td>\n",
       "      <td>Austin, TX</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18289</th>\n",
       "      <td>Seattle, WA</td>\n",
       "      <td>Seattle, WA</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15107</th>\n",
       "      <td>Austin, TX</td>\n",
       "      <td>Austin, TX</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27100</th>\n",
       "      <td>Minneapolis, MN</td>\n",
       "      <td>Plymouth, MN</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6434</th>\n",
       "      <td>New York, NY</td>\n",
       "      <td>New York, NY 10011 (Chelsea area)</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12261</th>\n",
       "      <td>Boston, MA</td>\n",
       "      <td>Boston, MA</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3308</th>\n",
       "      <td>Washington, DC</td>\n",
       "      <td>College Park, MD</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3429</th>\n",
       "      <td>Washington, DC</td>\n",
       "      <td>Bethesda, MD 20813</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27008</th>\n",
       "      <td>Minneapolis, MN</td>\n",
       "      <td>Minneapolis, MN 55401 (North Loop area)</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21830</th>\n",
       "      <td>San Francisco, CA</td>\n",
       "      <td>Burlingame, CA 94010</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18234</th>\n",
       "      <td>Seattle, WA</td>\n",
       "      <td>Seattle, WA</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18790</th>\n",
       "      <td>Seattle, WA</td>\n",
       "      <td>Bothell, WA</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6014</th>\n",
       "      <td>New York, NY</td>\n",
       "      <td>New York, NY</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15075</th>\n",
       "      <td>Austin, TX</td>\n",
       "      <td>Austin, TX</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4005</th>\n",
       "      <td>Washington, DC</td>\n",
       "      <td>Springfield, VA</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15066</th>\n",
       "      <td>Austin, TX</td>\n",
       "      <td>Austin, TX</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12850</th>\n",
       "      <td>Boston, MA</td>\n",
       "      <td>Boston, MA</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12354</th>\n",
       "      <td>Boston, MA</td>\n",
       "      <td>Cambridge, MA</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3012</th>\n",
       "      <td>Washington, DC</td>\n",
       "      <td>Washington, DC 20001 (Shaw area)</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7435</th>\n",
       "      <td>New York, NY</td>\n",
       "      <td>Rockleigh, NJ</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6537</th>\n",
       "      <td>New York, NY</td>\n",
       "      <td>New York, NY</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22240</th>\n",
       "      <td>San Francisco, CA</td>\n",
       "      <td>San Francisco, CA</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>140</th>\n",
       "      <td>Atlanta, GA</td>\n",
       "      <td>Alpharetta, GA</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27124</th>\n",
       "      <td>Minneapolis, MN</td>\n",
       "      <td>Chaska, MN</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3158</th>\n",
       "      <td>Washington, DC</td>\n",
       "      <td>Washington, DC</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21159</th>\n",
       "      <td>San Francisco, CA</td>\n",
       "      <td>San Francisco, CA</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13087</th>\n",
       "      <td>Boston, MA</td>\n",
       "      <td>Cambridge, MA 02142 (East Cambridge area)</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6732</th>\n",
       "      <td>New York, NY</td>\n",
       "      <td>New York, NY</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12488</th>\n",
       "      <td>Boston, MA</td>\n",
       "      <td>Boston, MA 02210 (South Boston area)</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6606</th>\n",
       "      <td>New York, NY</td>\n",
       "      <td>New York, NY 10016 (Gramercy area)</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20977</th>\n",
       "      <td>San Francisco, CA</td>\n",
       "      <td>San Francisco, CA</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6517</th>\n",
       "      <td>New York, NY</td>\n",
       "      <td>Manhattan, NY</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20966</th>\n",
       "      <td>San Francisco, CA</td>\n",
       "      <td>San Francisco, CA</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23938</th>\n",
       "      <td>Detroit, MI</td>\n",
       "      <td>United States</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3660</th>\n",
       "      <td>Washington, DC</td>\n",
       "      <td>Washington, DC 20024 (South West area)</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7446</th>\n",
       "      <td>New York, NY</td>\n",
       "      <td>New York, NY</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6773</th>\n",
       "      <td>New York, NY</td>\n",
       "      <td>New York, NY 10005 (Financial District area)</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12740</th>\n",
       "      <td>Boston, MA</td>\n",
       "      <td>Cambridge, MA</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6149</th>\n",
       "      <td>New York, NY</td>\n",
       "      <td>New York, NY</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6119</th>\n",
       "      <td>New York, NY</td>\n",
       "      <td>New York, NY 10001 (Chelsea area)</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13231</th>\n",
       "      <td>Boston, MA</td>\n",
       "      <td>Cambridge, MA</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11965</th>\n",
       "      <td>Boston, MA</td>\n",
       "      <td>Framingham, MA 01701</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12802</th>\n",
       "      <td>Boston, MA</td>\n",
       "      <td>Cambridge, MA 02139 (Area IV area)</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24062</th>\n",
       "      <td>Detroit, MI</td>\n",
       "      <td>Rochester, MI</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24040</th>\n",
       "      <td>Detroit, MI</td>\n",
       "      <td>Farmington Hills, MI</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12097</th>\n",
       "      <td>Boston, MA</td>\n",
       "      <td>Boston, MA</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21708</th>\n",
       "      <td>San Francisco, CA</td>\n",
       "      <td>San Francisco, CA</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20974</th>\n",
       "      <td>San Francisco, CA</td>\n",
       "      <td>San Francisco, CA</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12924</th>\n",
       "      <td>Boston, MA</td>\n",
       "      <td>Cambridge, MA 02139 (Area IV area)</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21916</th>\n",
       "      <td>San Francisco, CA</td>\n",
       "      <td>Oakland, CA 94612 (Northgate area)</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27188</th>\n",
       "      <td>Minneapolis, MN</td>\n",
       "      <td>Minneapolis, MN</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20976</th>\n",
       "      <td>San Francisco, CA</td>\n",
       "      <td>San Francisco, CA 94103 (South Of Market area)</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18559</th>\n",
       "      <td>Seattle, WA</td>\n",
       "      <td>Redmond, WA</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12338</th>\n",
       "      <td>Boston, MA</td>\n",
       "      <td>Boston, MA</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21052</th>\n",
       "      <td>San Francisco, CA</td>\n",
       "      <td>South San Francisco, CA</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22145</th>\n",
       "      <td>San Francisco, CA</td>\n",
       "      <td>Millbrae, CA 94030</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18302</th>\n",
       "      <td>Seattle, WA</td>\n",
       "      <td>SeaTac, WA</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15127</th>\n",
       "      <td>Austin, TX</td>\n",
       "      <td>Austin, TX 78701 (Downtown area)</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18980</th>\n",
       "      <td>Seattle, WA</td>\n",
       "      <td>Seattle, WA</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18474</th>\n",
       "      <td>Seattle, WA</td>\n",
       "      <td>Tukwila, WA</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3787</th>\n",
       "      <td>Washington, DC</td>\n",
       "      <td>Rockville, MD</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18115</th>\n",
       "      <td>Seattle, WA</td>\n",
       "      <td>Seattle, WA 98109 (Westlake area)</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13325</th>\n",
       "      <td>Boston, MA</td>\n",
       "      <td>Cambridge, MA 02142 (East Cambridge area)</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22059</th>\n",
       "      <td>San Francisco, CA</td>\n",
       "      <td>Greenbrae, CA</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3098</th>\n",
       "      <td>Washington, DC</td>\n",
       "      <td>Springfield, VA</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12635</th>\n",
       "      <td>Boston, MA</td>\n",
       "      <td>Cambridge, MA 02139 (Area IV area)</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3086</th>\n",
       "      <td>Washington, DC</td>\n",
       "      <td>Washington, DC 20006 (Foggy Bottom area)</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13232</th>\n",
       "      <td>Boston, MA</td>\n",
       "      <td>Cambridge, MA</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18259</th>\n",
       "      <td>Seattle, WA</td>\n",
       "      <td>Seattle, WA</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12937</th>\n",
       "      <td>Boston, MA</td>\n",
       "      <td>Boston, MA 02111 (Central area)</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21167</th>\n",
       "      <td>San Francisco, CA</td>\n",
       "      <td>San Francisco, CA 94103 (South Of Market area)</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12544</th>\n",
       "      <td>Boston, MA</td>\n",
       "      <td>Cambridge, MA</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>383</th>\n",
       "      <td>Atlanta, GA</td>\n",
       "      <td>Atlanta, GA</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15047</th>\n",
       "      <td>Austin, TX</td>\n",
       "      <td>Austin, TX</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21754</th>\n",
       "      <td>San Francisco, CA</td>\n",
       "      <td>San Francisco, CA 94124 (Bayview area)</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5535 rows Ã— 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             search_city                                           location  \\\n",
       "11966         Boston, MA                                         Boston, MA   \n",
       "6300        New York, NY                                       New York, NY   \n",
       "4433      Washington, DC                                  Silver Spring, MD   \n",
       "7165        New York, NY                                       Montvale, NJ   \n",
       "26996    Minneapolis, MN                                    Minneapolis, MN   \n",
       "12832         Boston, MA                                      Cambridge, MA   \n",
       "12834         Boston, MA          Cambridge, MA 02142 (East Cambridge area)   \n",
       "3518      Washington, DC                                         McLean, VA   \n",
       "21082  San Francisco, CA                                  San Francisco, CA   \n",
       "7281        New York, NY                                Port Washington, NY   \n",
       "12114         Boston, MA                                         Boston, MA   \n",
       "19057        Seattle, WA                                        Seattle, WA   \n",
       "15020         Austin, TX                   Austin, TX 78701 (Downtown area)   \n",
       "21130  San Francisco, CA                                  San Francisco, CA   \n",
       "12602         Boston, MA                                         Boston, MA   \n",
       "414          Atlanta, GA                                 Marietta, GA 30067   \n",
       "13265         Boston, MA                 Cambridge, MA 02139 (Area IV area)   \n",
       "6431        New York, NY                New York, NY 10029 (Yorkville area)   \n",
       "12782         Boston, MA                 Cambridge, MA 02139 (Area IV area)   \n",
       "18385        Seattle, WA                                        Redmond, WA   \n",
       "13131         Boston, MA                                        Andover, MA   \n",
       "6585        New York, NY                                       New York, NY   \n",
       "3325      Washington, DC  Arlington, VA 22209 (Radnor-Ft Myer Heights area)   \n",
       "3924      Washington, DC                                Rockville, MD 20852   \n",
       "22223  San Francisco, CA                                   Redwood City, CA   \n",
       "27204    Minneapolis, MN                                         Chaska, MN   \n",
       "22357  San Francisco, CA  San Francisco, CA 94105 (Financial District area)   \n",
       "7290        New York, NY                                       New York, NY   \n",
       "6045        New York, NY                 New York, NY 10010 (Gramercy area)   \n",
       "3397      Washington, DC                                     Washington, DC   \n",
       "18651        Seattle, WA                     Everett, WA 98204 (Holly area)   \n",
       "4476      Washington, DC                                Chantilly, VA 20153   \n",
       "21802  San Francisco, CA                                  San Francisco, CA   \n",
       "6387        New York, NY                                       New York, NY   \n",
       "21026  San Francisco, CA                                  San Francisco, CA   \n",
       "15024         Austin, TX                                   Austin, TX 78746   \n",
       "13144         Boston, MA                 Cambridge, MA 02139 (Area IV area)   \n",
       "18410        Seattle, WA                                        Seattle, WA   \n",
       "18965        Seattle, WA                                        Seattle, WA   \n",
       "12547         Boston, MA                                      Watertown, MA   \n",
       "21278  San Francisco, CA  San Francisco, CA 94111 (Financial District area)   \n",
       "22296  San Francisco, CA  San Francisco, CA 94105 (Financial District area)   \n",
       "21050  San Francisco, CA     San Francisco, CA 94107 (South Of Market area)   \n",
       "6160        New York, NY                                       New York, NY   \n",
       "7042        New York, NY                               Parsippany, NJ 07054   \n",
       "3653      Washington, DC                                  Silver Spring, MD   \n",
       "21905  San Francisco, CA                      South San Francisco, CA 94080   \n",
       "18679        Seattle, WA                                        Seattle, WA   \n",
       "12842         Boston, MA                                         Boston, MA   \n",
       "7358        New York, NY                                       New York, NY   \n",
       "11991         Boston, MA                                         Boston, MA   \n",
       "6459        New York, NY                  New York, NY 10167 (Midtown area)   \n",
       "3764      Washington, DC                Arlington, VA 22203 (Bluemont area)   \n",
       "9040     New Orleans, LA          New Orleans, LA 70113 (Central City area)   \n",
       "42           Atlanta, GA                                     Alpharetta, GA   \n",
       "12660         Boston, MA                                      Lexington, MA   \n",
       "4207      Washington, DC                                   Falls Church, VA   \n",
       "13432         Boston, MA                 Cambridge, MA 02139 (Area IV area)   \n",
       "3989      Washington, DC                                      Arlington, VA   \n",
       "22100  San Francisco, CA                            South San Francisco, CA   \n",
       "21756  San Francisco, CA                            South San Francisco, CA   \n",
       "18670        Seattle, WA                                        Seattle, WA   \n",
       "6372        New York, NY                                       New York, NY   \n",
       "15018         Austin, TX                                         Austin, TX   \n",
       "13263         Boston, MA                                   Dedham, MA 02026   \n",
       "6685        New York, NY                                       New York, NY   \n",
       "19252        Seattle, WA                                        Seattle, WA   \n",
       "6765        New York, NY                New York, NY 10029 (Yorkville area)   \n",
       "3621      Washington, DC                                      Rockville, MD   \n",
       "18277        Seattle, WA              Seattle, WA 98102 (Capitol Hill area)   \n",
       "604          Atlanta, GA                                        Atlanta, GA   \n",
       "4319      Washington, DC                                     Washington, DC   \n",
       "87           Atlanta, GA                                        Atlanta, GA   \n",
       "21803  San Francisco, CA                                  San Francisco, CA   \n",
       "9001     New Orleans, LA                                    New Orleans, LA   \n",
       "4418      Washington, DC                                         Vienna, VA   \n",
       "18905        Seattle, WA                                        Seattle, WA   \n",
       "6741        New York, NY                                       New York, NY   \n",
       "27055    Minneapolis, MN                                    Arden Hills, MN   \n",
       "6306        New York, NY                  New York, NY 10013 (Tribeca area)   \n",
       "22056  San Francisco, CA     San Francisco, CA 94103 (South Of Market area)   \n",
       "12487         Boston, MA                                      Cambridge, MA   \n",
       "6895        New York, NY                                       New York, NY   \n",
       "21865  San Francisco, CA     San Francisco, CA 94107 (South Of Market area)   \n",
       "3431      Washington, DC                                     Washington, DC   \n",
       "6580        New York, NY                                       New York, NY   \n",
       "3951      Washington, DC                                         McLean, VA   \n",
       "12923         Boston, MA                                        Andover, MA   \n",
       "12724         Boston, MA                                      Cambridge, MA   \n",
       "20933  San Francisco, CA                                  San Francisco, CA   \n",
       "18020        Seattle, WA                                        Seattle, WA   \n",
       "19022        Seattle, WA                                       Bellevue, WA   \n",
       "6009        New York, NY                  New York, NY 10022 (Midtown area)   \n",
       "18101        Seattle, WA                                        Seattle, WA   \n",
       "21863  San Francisco, CA                                      San Ramon, CA   \n",
       "26934    Minneapolis, MN                                       Plymouth, MN   \n",
       "21497  San Francisco, CA                                  San Francisco, CA   \n",
       "21624  San Francisco, CA                                San Bruno, CA 94066   \n",
       "12707         Boston, MA                                      Cambridge, MA   \n",
       "21273  San Francisco, CA  San Francisco, CA 94111 (Financial District area)   \n",
       "...                  ...                                                ...   \n",
       "12665         Boston, MA                                         Quincy, MA   \n",
       "12720         Boston, MA                                         Boston, MA   \n",
       "21185  San Francisco, CA                                  San Francisco, CA   \n",
       "26951    Minneapolis, MN                             Eden Prairie, MN 55347   \n",
       "18393        Seattle, WA                                  Redmond, WA 98052   \n",
       "6567        New York, NY                                       New York, NY   \n",
       "83           Atlanta, GA                                        Atlanta, GA   \n",
       "6416        New York, NY                                       New York, NY   \n",
       "18741        Seattle, WA  Seattle, WA 98103 (Green Lake - Wallingford area)   \n",
       "22130  San Francisco, CA                                  San Francisco, CA   \n",
       "21632  San Francisco, CA                                  San Francisco, CA   \n",
       "53           Atlanta, GA                                        Atlanta, GA   \n",
       "6615        New York, NY                                       New York, NY   \n",
       "21099  San Francisco, CA                                  San Francisco, CA   \n",
       "21861  San Francisco, CA                                    Foster City, CA   \n",
       "18288        Seattle, WA                                  Redmond, WA 98052   \n",
       "186          Atlanta, GA                                        Atlanta, GA   \n",
       "12279         Boston, MA                                         Boston, MA   \n",
       "18261        Seattle, WA                                        Seattle, WA   \n",
       "12848         Boston, MA                                         Boston, MA   \n",
       "7451        New York, NY                                       New York, NY   \n",
       "3475      Washington, DC                                   Reston, VA 20191   \n",
       "4343      Washington, DC                                Chantilly, VA 20151   \n",
       "6561        New York, NY                                       New York, NY   \n",
       "7089        New York, NY                                       New York, NY   \n",
       "15048         Austin, TX                                         Austin, TX   \n",
       "18289        Seattle, WA                                        Seattle, WA   \n",
       "15107         Austin, TX                                         Austin, TX   \n",
       "27100    Minneapolis, MN                                       Plymouth, MN   \n",
       "6434        New York, NY                  New York, NY 10011 (Chelsea area)   \n",
       "12261         Boston, MA                                         Boston, MA   \n",
       "3308      Washington, DC                                   College Park, MD   \n",
       "3429      Washington, DC                                 Bethesda, MD 20813   \n",
       "27008    Minneapolis, MN            Minneapolis, MN 55401 (North Loop area)   \n",
       "21830  San Francisco, CA                               Burlingame, CA 94010   \n",
       "18234        Seattle, WA                                        Seattle, WA   \n",
       "18790        Seattle, WA                                        Bothell, WA   \n",
       "6014        New York, NY                                       New York, NY   \n",
       "15075         Austin, TX                                         Austin, TX   \n",
       "4005      Washington, DC                                    Springfield, VA   \n",
       "15066         Austin, TX                                         Austin, TX   \n",
       "12850         Boston, MA                                         Boston, MA   \n",
       "12354         Boston, MA                                      Cambridge, MA   \n",
       "3012      Washington, DC                   Washington, DC 20001 (Shaw area)   \n",
       "7435        New York, NY                                      Rockleigh, NJ   \n",
       "6537        New York, NY                                       New York, NY   \n",
       "22240  San Francisco, CA                                  San Francisco, CA   \n",
       "140          Atlanta, GA                                     Alpharetta, GA   \n",
       "27124    Minneapolis, MN                                         Chaska, MN   \n",
       "3158      Washington, DC                                     Washington, DC   \n",
       "21159  San Francisco, CA                                  San Francisco, CA   \n",
       "13087         Boston, MA          Cambridge, MA 02142 (East Cambridge area)   \n",
       "6732        New York, NY                                       New York, NY   \n",
       "12488         Boston, MA               Boston, MA 02210 (South Boston area)   \n",
       "6606        New York, NY                 New York, NY 10016 (Gramercy area)   \n",
       "20977  San Francisco, CA                                  San Francisco, CA   \n",
       "6517        New York, NY                                      Manhattan, NY   \n",
       "20966  San Francisco, CA                                  San Francisco, CA   \n",
       "23938        Detroit, MI                                      United States   \n",
       "3660      Washington, DC             Washington, DC 20024 (South West area)   \n",
       "7446        New York, NY                                       New York, NY   \n",
       "6773        New York, NY       New York, NY 10005 (Financial District area)   \n",
       "12740         Boston, MA                                      Cambridge, MA   \n",
       "6149        New York, NY                                       New York, NY   \n",
       "6119        New York, NY                  New York, NY 10001 (Chelsea area)   \n",
       "13231         Boston, MA                                      Cambridge, MA   \n",
       "11965         Boston, MA                               Framingham, MA 01701   \n",
       "12802         Boston, MA                 Cambridge, MA 02139 (Area IV area)   \n",
       "24062        Detroit, MI                                      Rochester, MI   \n",
       "24040        Detroit, MI                               Farmington Hills, MI   \n",
       "12097         Boston, MA                                         Boston, MA   \n",
       "21708  San Francisco, CA                                  San Francisco, CA   \n",
       "20974  San Francisco, CA                                  San Francisco, CA   \n",
       "12924         Boston, MA                 Cambridge, MA 02139 (Area IV area)   \n",
       "21916  San Francisco, CA                 Oakland, CA 94612 (Northgate area)   \n",
       "27188    Minneapolis, MN                                    Minneapolis, MN   \n",
       "20976  San Francisco, CA     San Francisco, CA 94103 (South Of Market area)   \n",
       "18559        Seattle, WA                                        Redmond, WA   \n",
       "12338         Boston, MA                                         Boston, MA   \n",
       "21052  San Francisco, CA                            South San Francisco, CA   \n",
       "22145  San Francisco, CA                                 Millbrae, CA 94030   \n",
       "18302        Seattle, WA                                         SeaTac, WA   \n",
       "15127         Austin, TX                   Austin, TX 78701 (Downtown area)   \n",
       "18980        Seattle, WA                                        Seattle, WA   \n",
       "18474        Seattle, WA                                        Tukwila, WA   \n",
       "3787      Washington, DC                                      Rockville, MD   \n",
       "18115        Seattle, WA                  Seattle, WA 98109 (Westlake area)   \n",
       "13325         Boston, MA          Cambridge, MA 02142 (East Cambridge area)   \n",
       "22059  San Francisco, CA                                      Greenbrae, CA   \n",
       "3098      Washington, DC                                    Springfield, VA   \n",
       "12635         Boston, MA                 Cambridge, MA 02139 (Area IV area)   \n",
       "3086      Washington, DC           Washington, DC 20006 (Foggy Bottom area)   \n",
       "13232         Boston, MA                                      Cambridge, MA   \n",
       "18259        Seattle, WA                                        Seattle, WA   \n",
       "12937         Boston, MA                    Boston, MA 02111 (Central area)   \n",
       "21167  San Francisco, CA     San Francisco, CA 94103 (South Of Market area)   \n",
       "12544         Boston, MA                                      Cambridge, MA   \n",
       "383          Atlanta, GA                                        Atlanta, GA   \n",
       "15047         Austin, TX                                         Austin, TX   \n",
       "21754  San Francisco, CA             San Francisco, CA 94124 (Bayview area)   \n",
       "\n",
       "       in_city  \n",
       "11966        1  \n",
       "6300         1  \n",
       "4433         0  \n",
       "7165         0  \n",
       "26996        1  \n",
       "12832        0  \n",
       "12834        0  \n",
       "3518         0  \n",
       "21082        1  \n",
       "7281         0  \n",
       "12114        1  \n",
       "19057        1  \n",
       "15020        1  \n",
       "21130        1  \n",
       "12602        1  \n",
       "414          0  \n",
       "13265        0  \n",
       "6431         1  \n",
       "12782        0  \n",
       "18385        0  \n",
       "13131        0  \n",
       "6585         1  \n",
       "3325         0  \n",
       "3924         0  \n",
       "22223        0  \n",
       "27204        0  \n",
       "22357        1  \n",
       "7290         1  \n",
       "6045         1  \n",
       "3397         1  \n",
       "18651        0  \n",
       "4476         0  \n",
       "21802        1  \n",
       "6387         1  \n",
       "21026        1  \n",
       "15024        1  \n",
       "13144        0  \n",
       "18410        1  \n",
       "18965        1  \n",
       "12547        0  \n",
       "21278        1  \n",
       "22296        1  \n",
       "21050        1  \n",
       "6160         1  \n",
       "7042         0  \n",
       "3653         0  \n",
       "21905        1  \n",
       "18679        1  \n",
       "12842        1  \n",
       "7358         1  \n",
       "11991        1  \n",
       "6459         1  \n",
       "3764         0  \n",
       "9040         1  \n",
       "42           0  \n",
       "12660        0  \n",
       "4207         0  \n",
       "13432        0  \n",
       "3989         0  \n",
       "22100        1  \n",
       "21756        1  \n",
       "18670        1  \n",
       "6372         1  \n",
       "15018        1  \n",
       "13263        0  \n",
       "6685         1  \n",
       "19252        1  \n",
       "6765         1  \n",
       "3621         0  \n",
       "18277        1  \n",
       "604          1  \n",
       "4319         1  \n",
       "87           1  \n",
       "21803        1  \n",
       "9001         1  \n",
       "4418         0  \n",
       "18905        1  \n",
       "6741         1  \n",
       "27055        0  \n",
       "6306         1  \n",
       "22056        1  \n",
       "12487        0  \n",
       "6895         1  \n",
       "21865        1  \n",
       "3431         1  \n",
       "6580         1  \n",
       "3951         0  \n",
       "12923        0  \n",
       "12724        0  \n",
       "20933        1  \n",
       "18020        1  \n",
       "19022        0  \n",
       "6009         1  \n",
       "18101        1  \n",
       "21863        0  \n",
       "26934        0  \n",
       "21497        1  \n",
       "21624        0  \n",
       "12707        0  \n",
       "21273        1  \n",
       "...        ...  \n",
       "12665        0  \n",
       "12720        1  \n",
       "21185        1  \n",
       "26951        0  \n",
       "18393        0  \n",
       "6567         1  \n",
       "83           1  \n",
       "6416         1  \n",
       "18741        1  \n",
       "22130        1  \n",
       "21632        1  \n",
       "53           1  \n",
       "6615         1  \n",
       "21099        1  \n",
       "21861        0  \n",
       "18288        0  \n",
       "186          1  \n",
       "12279        1  \n",
       "18261        1  \n",
       "12848        1  \n",
       "7451         1  \n",
       "3475         0  \n",
       "4343         0  \n",
       "6561         1  \n",
       "7089         1  \n",
       "15048        1  \n",
       "18289        1  \n",
       "15107        1  \n",
       "27100        0  \n",
       "6434         1  \n",
       "12261        1  \n",
       "3308         0  \n",
       "3429         0  \n",
       "27008        1  \n",
       "21830        0  \n",
       "18234        1  \n",
       "18790        0  \n",
       "6014         1  \n",
       "15075        1  \n",
       "4005         0  \n",
       "15066        1  \n",
       "12850        1  \n",
       "12354        0  \n",
       "3012         1  \n",
       "7435         0  \n",
       "6537         1  \n",
       "22240        1  \n",
       "140          0  \n",
       "27124        0  \n",
       "3158         1  \n",
       "21159        1  \n",
       "13087        0  \n",
       "6732         1  \n",
       "12488        1  \n",
       "6606         1  \n",
       "20977        1  \n",
       "6517         0  \n",
       "20966        1  \n",
       "23938        0  \n",
       "3660         1  \n",
       "7446         1  \n",
       "6773         1  \n",
       "12740        0  \n",
       "6149         1  \n",
       "6119         1  \n",
       "13231        0  \n",
       "11965        0  \n",
       "12802        0  \n",
       "24062        0  \n",
       "24040        0  \n",
       "12097        1  \n",
       "21708        1  \n",
       "20974        1  \n",
       "12924        0  \n",
       "21916        0  \n",
       "27188        1  \n",
       "20976        1  \n",
       "18559        0  \n",
       "12338        1  \n",
       "21052        1  \n",
       "22145        0  \n",
       "18302        0  \n",
       "15127        1  \n",
       "18980        1  \n",
       "18474        0  \n",
       "3787         0  \n",
       "18115        1  \n",
       "13325        0  \n",
       "22059        0  \n",
       "3098         0  \n",
       "12635        0  \n",
       "3086         1  \n",
       "13232        0  \n",
       "18259        1  \n",
       "12937        1  \n",
       "21167        1  \n",
       "12544        0  \n",
       "383          1  \n",
       "15047        1  \n",
       "21754        1  \n",
       "\n",
       "[5535 rows x 3 columns]"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# checking if it worked well\n",
    "ds_jobs_clean[['search_city', 'location', 'in_city']].sample(frac=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "2\n",
      "41\n"
     ]
    }
   ],
   "source": [
    "# convert \"start\" column to something that actually shows me what page something is on.\n",
    "\n",
    "def convert_to_page(start_value):\n",
    "    start = range(0,2000,10)\n",
    "    page = range(1,201)\n",
    "    d = {start:page for start, page in zip(start, page)} \n",
    "    return d[start_value]\n",
    "#test\n",
    "print convert_to_page(0)\n",
    "print convert_to_page(10)\n",
    "print convert_to_page(400)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>start</th>\n",
       "      <th>page</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3595</th>\n",
       "      <td>400</td>\n",
       "      <td>41</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13041</th>\n",
       "      <td>720</td>\n",
       "      <td>73</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15127</th>\n",
       "      <td>110</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9010</th>\n",
       "      <td>10</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24127</th>\n",
       "      <td>130</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3375</th>\n",
       "      <td>250</td>\n",
       "      <td>26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3942</th>\n",
       "      <td>630</td>\n",
       "      <td>64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6404</th>\n",
       "      <td>270</td>\n",
       "      <td>28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27072</th>\n",
       "      <td>100</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21520</th>\n",
       "      <td>390</td>\n",
       "      <td>40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22072</th>\n",
       "      <td>760</td>\n",
       "      <td>77</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18880</th>\n",
       "      <td>630</td>\n",
       "      <td>64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13052</th>\n",
       "      <td>730</td>\n",
       "      <td>74</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21414</th>\n",
       "      <td>320</td>\n",
       "      <td>33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19070</th>\n",
       "      <td>760</td>\n",
       "      <td>77</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21469</th>\n",
       "      <td>360</td>\n",
       "      <td>37</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6818</th>\n",
       "      <td>550</td>\n",
       "      <td>56</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7138</th>\n",
       "      <td>760</td>\n",
       "      <td>77</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4095</th>\n",
       "      <td>730</td>\n",
       "      <td>74</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18032</th>\n",
       "      <td>70</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23961</th>\n",
       "      <td>20</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18172</th>\n",
       "      <td>160</td>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13442</th>\n",
       "      <td>990</td>\n",
       "      <td>100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4270</th>\n",
       "      <td>850</td>\n",
       "      <td>86</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12767</th>\n",
       "      <td>540</td>\n",
       "      <td>55</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3866</th>\n",
       "      <td>580</td>\n",
       "      <td>59</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6655</th>\n",
       "      <td>440</td>\n",
       "      <td>45</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18472</th>\n",
       "      <td>360</td>\n",
       "      <td>37</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13268</th>\n",
       "      <td>870</td>\n",
       "      <td>88</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4462</th>\n",
       "      <td>980</td>\n",
       "      <td>99</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4395</th>\n",
       "      <td>930</td>\n",
       "      <td>94</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21455</th>\n",
       "      <td>350</td>\n",
       "      <td>36</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6249</th>\n",
       "      <td>170</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19189</th>\n",
       "      <td>840</td>\n",
       "      <td>85</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19015</th>\n",
       "      <td>720</td>\n",
       "      <td>73</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21378</th>\n",
       "      <td>300</td>\n",
       "      <td>31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14971</th>\n",
       "      <td>10</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21980</th>\n",
       "      <td>700</td>\n",
       "      <td>71</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6717</th>\n",
       "      <td>480</td>\n",
       "      <td>49</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18770</th>\n",
       "      <td>560</td>\n",
       "      <td>57</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6982</th>\n",
       "      <td>660</td>\n",
       "      <td>67</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18511</th>\n",
       "      <td>390</td>\n",
       "      <td>40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>348</th>\n",
       "      <td>230</td>\n",
       "      <td>24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6853</th>\n",
       "      <td>570</td>\n",
       "      <td>58</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6375</th>\n",
       "      <td>250</td>\n",
       "      <td>26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6495</th>\n",
       "      <td>330</td>\n",
       "      <td>34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26918</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7034</th>\n",
       "      <td>690</td>\n",
       "      <td>70</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7432</th>\n",
       "      <td>960</td>\n",
       "      <td>97</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21036</th>\n",
       "      <td>70</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7137</th>\n",
       "      <td>760</td>\n",
       "      <td>77</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27026</th>\n",
       "      <td>70</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>94</th>\n",
       "      <td>60</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18860</th>\n",
       "      <td>620</td>\n",
       "      <td>63</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18707</th>\n",
       "      <td>520</td>\n",
       "      <td>53</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12279</th>\n",
       "      <td>210</td>\n",
       "      <td>22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4378</th>\n",
       "      <td>920</td>\n",
       "      <td>93</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8992</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6306</th>\n",
       "      <td>210</td>\n",
       "      <td>22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27143</th>\n",
       "      <td>150</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21047</th>\n",
       "      <td>80</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12737</th>\n",
       "      <td>520</td>\n",
       "      <td>53</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18353</th>\n",
       "      <td>280</td>\n",
       "      <td>29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12781</th>\n",
       "      <td>550</td>\n",
       "      <td>56</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12246</th>\n",
       "      <td>190</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6669</th>\n",
       "      <td>450</td>\n",
       "      <td>46</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23945</th>\n",
       "      <td>10</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27132</th>\n",
       "      <td>140</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3180</th>\n",
       "      <td>120</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13410</th>\n",
       "      <td>970</td>\n",
       "      <td>98</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6088</th>\n",
       "      <td>60</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12145</th>\n",
       "      <td>120</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27025</th>\n",
       "      <td>70</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21726</th>\n",
       "      <td>530</td>\n",
       "      <td>54</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22239</th>\n",
       "      <td>870</td>\n",
       "      <td>88</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9045</th>\n",
       "      <td>30</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12385</th>\n",
       "      <td>280</td>\n",
       "      <td>29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18422</th>\n",
       "      <td>330</td>\n",
       "      <td>34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12669</th>\n",
       "      <td>470</td>\n",
       "      <td>48</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4283</th>\n",
       "      <td>860</td>\n",
       "      <td>87</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12017</th>\n",
       "      <td>40</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13110</th>\n",
       "      <td>770</td>\n",
       "      <td>78</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21234</th>\n",
       "      <td>200</td>\n",
       "      <td>21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12829</th>\n",
       "      <td>580</td>\n",
       "      <td>59</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7062</th>\n",
       "      <td>710</td>\n",
       "      <td>72</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3023</th>\n",
       "      <td>20</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12563</th>\n",
       "      <td>400</td>\n",
       "      <td>41</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21617</th>\n",
       "      <td>460</td>\n",
       "      <td>47</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13085</th>\n",
       "      <td>750</td>\n",
       "      <td>76</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>426</th>\n",
       "      <td>280</td>\n",
       "      <td>29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4031</th>\n",
       "      <td>690</td>\n",
       "      <td>70</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12618</th>\n",
       "      <td>440</td>\n",
       "      <td>45</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18610</th>\n",
       "      <td>450</td>\n",
       "      <td>46</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>185</th>\n",
       "      <td>120</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23938</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>336</th>\n",
       "      <td>220</td>\n",
       "      <td>23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3466</th>\n",
       "      <td>310</td>\n",
       "      <td>32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21604</th>\n",
       "      <td>450</td>\n",
       "      <td>46</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11386</th>\n",
       "      <td>1620</td>\n",
       "      <td>163</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23935</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12428</th>\n",
       "      <td>310</td>\n",
       "      <td>32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13253</th>\n",
       "      <td>860</td>\n",
       "      <td>87</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13402</th>\n",
       "      <td>960</td>\n",
       "      <td>97</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6653</th>\n",
       "      <td>440</td>\n",
       "      <td>45</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3248</th>\n",
       "      <td>170</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12082</th>\n",
       "      <td>80</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13366</th>\n",
       "      <td>940</td>\n",
       "      <td>95</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4092</th>\n",
       "      <td>730</td>\n",
       "      <td>74</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6164</th>\n",
       "      <td>110</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21289</th>\n",
       "      <td>240</td>\n",
       "      <td>25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6491</th>\n",
       "      <td>330</td>\n",
       "      <td>34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21139</th>\n",
       "      <td>140</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18587</th>\n",
       "      <td>440</td>\n",
       "      <td>45</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18378</th>\n",
       "      <td>300</td>\n",
       "      <td>31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6372</th>\n",
       "      <td>250</td>\n",
       "      <td>26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6039</th>\n",
       "      <td>30</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19253</th>\n",
       "      <td>880</td>\n",
       "      <td>89</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6825</th>\n",
       "      <td>550</td>\n",
       "      <td>56</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4065</th>\n",
       "      <td>710</td>\n",
       "      <td>72</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22386</th>\n",
       "      <td>970</td>\n",
       "      <td>98</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15113</th>\n",
       "      <td>100</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3145</th>\n",
       "      <td>100</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12051</th>\n",
       "      <td>60</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21857</th>\n",
       "      <td>620</td>\n",
       "      <td>63</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7094</th>\n",
       "      <td>730</td>\n",
       "      <td>74</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19187</th>\n",
       "      <td>840</td>\n",
       "      <td>85</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6057</th>\n",
       "      <td>40</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3300</th>\n",
       "      <td>200</td>\n",
       "      <td>21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4316</th>\n",
       "      <td>880</td>\n",
       "      <td>89</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7449</th>\n",
       "      <td>970</td>\n",
       "      <td>98</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12430</th>\n",
       "      <td>310</td>\n",
       "      <td>32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12348</th>\n",
       "      <td>260</td>\n",
       "      <td>27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7107</th>\n",
       "      <td>740</td>\n",
       "      <td>75</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6492</th>\n",
       "      <td>330</td>\n",
       "      <td>34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18215</th>\n",
       "      <td>190</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12785</th>\n",
       "      <td>550</td>\n",
       "      <td>56</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>309</th>\n",
       "      <td>200</td>\n",
       "      <td>21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>318</th>\n",
       "      <td>210</td>\n",
       "      <td>22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21082</th>\n",
       "      <td>100</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7481</th>\n",
       "      <td>990</td>\n",
       "      <td>100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13072</th>\n",
       "      <td>740</td>\n",
       "      <td>75</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6699</th>\n",
       "      <td>470</td>\n",
       "      <td>48</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3342</th>\n",
       "      <td>230</td>\n",
       "      <td>24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3697</th>\n",
       "      <td>470</td>\n",
       "      <td>48</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18785</th>\n",
       "      <td>570</td>\n",
       "      <td>58</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6921</th>\n",
       "      <td>620</td>\n",
       "      <td>63</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20987</th>\n",
       "      <td>40</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12981</th>\n",
       "      <td>680</td>\n",
       "      <td>69</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27162</th>\n",
       "      <td>160</td>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3341</th>\n",
       "      <td>230</td>\n",
       "      <td>24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26947</th>\n",
       "      <td>20</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13188</th>\n",
       "      <td>820</td>\n",
       "      <td>83</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21760</th>\n",
       "      <td>550</td>\n",
       "      <td>56</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12052</th>\n",
       "      <td>60</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24086</th>\n",
       "      <td>100</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3584</th>\n",
       "      <td>390</td>\n",
       "      <td>40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3445</th>\n",
       "      <td>300</td>\n",
       "      <td>31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18173</th>\n",
       "      <td>160</td>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18392</th>\n",
       "      <td>310</td>\n",
       "      <td>32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18556</th>\n",
       "      <td>420</td>\n",
       "      <td>43</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21550</th>\n",
       "      <td>410</td>\n",
       "      <td>42</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15066</th>\n",
       "      <td>70</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22359</th>\n",
       "      <td>950</td>\n",
       "      <td>96</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6951</th>\n",
       "      <td>640</td>\n",
       "      <td>65</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13277</th>\n",
       "      <td>880</td>\n",
       "      <td>89</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12037</th>\n",
       "      <td>50</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4012</th>\n",
       "      <td>680</td>\n",
       "      <td>69</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13087</th>\n",
       "      <td>750</td>\n",
       "      <td>76</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21279</th>\n",
       "      <td>230</td>\n",
       "      <td>24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9024</th>\n",
       "      <td>20</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18097</th>\n",
       "      <td>110</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6909</th>\n",
       "      <td>610</td>\n",
       "      <td>62</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12645</th>\n",
       "      <td>460</td>\n",
       "      <td>47</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12003</th>\n",
       "      <td>30</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3000</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12751</th>\n",
       "      <td>530</td>\n",
       "      <td>54</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18205</th>\n",
       "      <td>180</td>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12826</th>\n",
       "      <td>580</td>\n",
       "      <td>59</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22219</th>\n",
       "      <td>860</td>\n",
       "      <td>87</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>143</th>\n",
       "      <td>90</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4093</th>\n",
       "      <td>730</td>\n",
       "      <td>74</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22325</th>\n",
       "      <td>930</td>\n",
       "      <td>94</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6775</th>\n",
       "      <td>520</td>\n",
       "      <td>53</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6341</th>\n",
       "      <td>230</td>\n",
       "      <td>24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6702</th>\n",
       "      <td>470</td>\n",
       "      <td>48</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12226</th>\n",
       "      <td>180</td>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21982</th>\n",
       "      <td>700</td>\n",
       "      <td>71</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15159</th>\n",
       "      <td>130</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12195</th>\n",
       "      <td>160</td>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7408</th>\n",
       "      <td>940</td>\n",
       "      <td>95</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>72</th>\n",
       "      <td>40</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6099</th>\n",
       "      <td>70</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3265</th>\n",
       "      <td>180</td>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6324</th>\n",
       "      <td>220</td>\n",
       "      <td>23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4109</th>\n",
       "      <td>740</td>\n",
       "      <td>75</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>20</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>124</th>\n",
       "      <td>80</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3719</th>\n",
       "      <td>480</td>\n",
       "      <td>49</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18862</th>\n",
       "      <td>620</td>\n",
       "      <td>63</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21277</th>\n",
       "      <td>230</td>\n",
       "      <td>24</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5535 rows Ã— 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       start  page\n",
       "3595     400    41\n",
       "13041    720    73\n",
       "15127    110    12\n",
       "9010      10     2\n",
       "24127    130    14\n",
       "3375     250    26\n",
       "3942     630    64\n",
       "6404     270    28\n",
       "27072    100    11\n",
       "21520    390    40\n",
       "22072    760    77\n",
       "18880    630    64\n",
       "13052    730    74\n",
       "21414    320    33\n",
       "19070    760    77\n",
       "21469    360    37\n",
       "6818     550    56\n",
       "7138     760    77\n",
       "4095     730    74\n",
       "18032     70     8\n",
       "23961     20     3\n",
       "18172    160    17\n",
       "13442    990   100\n",
       "4270     850    86\n",
       "12767    540    55\n",
       "3866     580    59\n",
       "6655     440    45\n",
       "18472    360    37\n",
       "13268    870    88\n",
       "4462     980    99\n",
       "4395     930    94\n",
       "21455    350    36\n",
       "6249     170    18\n",
       "19189    840    85\n",
       "19015    720    73\n",
       "21378    300    31\n",
       "14971     10     2\n",
       "21980    700    71\n",
       "6717     480    49\n",
       "18770    560    57\n",
       "6982     660    67\n",
       "18511    390    40\n",
       "348      230    24\n",
       "6853     570    58\n",
       "6375     250    26\n",
       "6495     330    34\n",
       "26918      0     1\n",
       "7034     690    70\n",
       "7432     960    97\n",
       "21036     70     8\n",
       "7137     760    77\n",
       "27026     70     8\n",
       "94        60     7\n",
       "18860    620    63\n",
       "18707    520    53\n",
       "12279    210    22\n",
       "4378     920    93\n",
       "8992       0     1\n",
       "6306     210    22\n",
       "27143    150    16\n",
       "21047     80     9\n",
       "12737    520    53\n",
       "18353    280    29\n",
       "12781    550    56\n",
       "12246    190    20\n",
       "6669     450    46\n",
       "23945     10     2\n",
       "27132    140    15\n",
       "3180     120    13\n",
       "13410    970    98\n",
       "6088      60     7\n",
       "12145    120    13\n",
       "27025     70     8\n",
       "21726    530    54\n",
       "22239    870    88\n",
       "9045      30     4\n",
       "12385    280    29\n",
       "18422    330    34\n",
       "12669    470    48\n",
       "4283     860    87\n",
       "12017     40     5\n",
       "13110    770    78\n",
       "21234    200    21\n",
       "12829    580    59\n",
       "7062     710    72\n",
       "3023      20     3\n",
       "12563    400    41\n",
       "21617    460    47\n",
       "13085    750    76\n",
       "426      280    29\n",
       "4031     690    70\n",
       "12618    440    45\n",
       "18610    450    46\n",
       "185      120    13\n",
       "23938      0     1\n",
       "336      220    23\n",
       "3466     310    32\n",
       "21604    450    46\n",
       "11386   1620   163\n",
       "23935      0     1\n",
       "...      ...   ...\n",
       "12428    310    32\n",
       "13253    860    87\n",
       "13402    960    97\n",
       "6653     440    45\n",
       "3248     170    18\n",
       "12082     80     9\n",
       "13366    940    95\n",
       "4092     730    74\n",
       "6164     110    12\n",
       "21289    240    25\n",
       "6491     330    34\n",
       "21139    140    15\n",
       "18587    440    45\n",
       "18378    300    31\n",
       "6372     250    26\n",
       "6039      30     4\n",
       "19253    880    89\n",
       "6825     550    56\n",
       "4065     710    72\n",
       "22386    970    98\n",
       "15113    100    11\n",
       "3145     100    11\n",
       "12051     60     7\n",
       "21857    620    63\n",
       "7094     730    74\n",
       "19187    840    85\n",
       "6057      40     5\n",
       "3300     200    21\n",
       "4316     880    89\n",
       "7449     970    98\n",
       "12430    310    32\n",
       "12348    260    27\n",
       "7107     740    75\n",
       "6492     330    34\n",
       "18215    190    20\n",
       "12785    550    56\n",
       "309      200    21\n",
       "318      210    22\n",
       "21082    100    11\n",
       "7481     990   100\n",
       "13072    740    75\n",
       "6699     470    48\n",
       "3342     230    24\n",
       "3697     470    48\n",
       "18785    570    58\n",
       "6921     620    63\n",
       "20987     40     5\n",
       "12981    680    69\n",
       "27162    160    17\n",
       "3341     230    24\n",
       "26947     20     3\n",
       "13188    820    83\n",
       "21760    550    56\n",
       "12052     60     7\n",
       "24086    100    11\n",
       "3584     390    40\n",
       "3445     300    31\n",
       "18173    160    17\n",
       "18392    310    32\n",
       "18556    420    43\n",
       "21550    410    42\n",
       "15066     70     8\n",
       "22359    950    96\n",
       "6951     640    65\n",
       "13277    880    89\n",
       "12037     50     6\n",
       "4012     680    69\n",
       "13087    750    76\n",
       "21279    230    24\n",
       "9024      20     3\n",
       "18097    110    12\n",
       "6909     610    62\n",
       "12645    460    47\n",
       "12003     30     4\n",
       "3000       0     1\n",
       "12751    530    54\n",
       "18205    180    19\n",
       "12826    580    59\n",
       "22219    860    87\n",
       "143       90    10\n",
       "4093     730    74\n",
       "22325    930    94\n",
       "6775     520    53\n",
       "6341     230    24\n",
       "6702     470    48\n",
       "12226    180    19\n",
       "21982    700    71\n",
       "15159    130    14\n",
       "12195    160    17\n",
       "7408     940    95\n",
       "72        40     5\n",
       "6099      70     8\n",
       "3265     180    19\n",
       "6324     220    23\n",
       "4109     740    75\n",
       "36        20     3\n",
       "124       80     9\n",
       "3719     480    49\n",
       "18862    620    63\n",
       "21277    230    24\n",
       "\n",
       "[5535 rows x 2 columns]"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# applying\n",
    "ds_jobs_clean.ix[:,'page'] = ds_jobs_clean.start.apply(convert_to_page)\n",
    "ds_jobs_clean[['start', 'page']].sample(frac=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# I want to export the data for visualization in Tableau without the superfluous categories\n",
    "col = [x for x in ds_jobs_clean.columns if x not in ['location', 'salary', 'sponsored', 'start', 'date_posted']]\n",
    "\n",
    "ds_jobs_clean[col].to_csv('data_science_jobs2.csv', encoding='utf-8')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "focus": false,
    "id": "6e8a5a1c-1580-4845-a9b6-482bc00c73cd"
   },
   "source": [
    "## Predicting salaries using Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "collapsed": false,
    "focus": false,
    "id": "634ab7c1-c76f-4b04-a36e-5ff3cb1f9eb2"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>company</th>\n",
       "      <th>number_reviews</th>\n",
       "      <th>search_city</th>\n",
       "      <th>star_rating</th>\n",
       "      <th>summary</th>\n",
       "      <th>title</th>\n",
       "      <th>website</th>\n",
       "      <th>how_paid</th>\n",
       "      <th>annual_salary</th>\n",
       "      <th>is_sponsored</th>\n",
       "      <th>time_since_posted</th>\n",
       "      <th>in_city</th>\n",
       "      <th>page</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>Cotiviti</td>\n",
       "      <td>30.0</td>\n",
       "      <td>Atlanta, GA</td>\n",
       "      <td>3.35</td>\n",
       "      <td>This is a pioneering data scientist who will participate in expanding the new analytics backbone. Cotiviti is looking for an industry leading Data Scientist to...</td>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>http://www.indeed.com/pagead/clk?mo=r&amp;ad=-6NYlbfkN0AbexXlh6WlNaC12RNLKcRQH8fywLm61v9KQllly0vTVrm9U0Iy0AOsYwOq9YOpDX03iprvWHw_SY6xCXG90mwLvOd8fb5BdJ-fu_-2tfp_KoWry1hPm7FaVRyBGPoeYEaNltu7W5i0j-OYtPh1ozEJ4oN7u_zLF7PnEIYwsSJTUyra1nlPHHQpGEq7KH9P1UhJyt0gLdmaXr7oC9iG41hrLTLQM6Dy4jOfZIDOXaBdIjV_m-vrLzXNwMCEHNxAuNUsOUWu9fNUIO6h2dpkDtS46fwUq5bUGThLBpg1h_JsmngU4OOpPDCmzhyOIZujq7kpNxhKt2UxH0Sm5knOVKSmYxJ1lNKEnygA8DCD6U_1zkkTxJJ5LBcAr9lpizyc6MVLmeSSISBIrGKE9SvJv_WjfNXpznu3719huu8jLhA-4dpvovDIXnXZf5ddKRiNMGDJ_o8d2rLvrnNdM6ksJXYj&amp;p=1&amp;sk=&amp;fvj=0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>more than 30 days ago</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>Cox Automotive</td>\n",
       "      <td>46.0</td>\n",
       "      <td>Atlanta, GA</td>\n",
       "      <td>3.40</td>\n",
       "      <td>Interprets problems and develops solutions to business problems using data analysis, data mining, optimization tools, and machine learning techniques and...</td>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>http://www.indeed.com/pagead/clk?mo=r&amp;ad=-6NYlbfkN0Aqmv_5JD5v6gg1ICRL12VY6BolF0XAUkQtat1DEGOKAas7v4hqpX3lzUM4h7L4VGsyuyDvf1POStkSJgHsuP2fB8YliLIijj53wvHBII5P9eQQwhBoT2Vrz0Dv0LOR9cmhA2uclIYN001l_R0jB6OflQ3KEmNIKzoNezeQCnu5X1bPju79uAEHbaTS6LdJvB-hJTy0PZPPeNKSkMyWxp3Wc2N8qN2FIq69xIhd7NBdjwnWuSZEDZvdGAtcdwsplmc_6i_owekmLU0Zj9rRIQYMM4CCSqkchPU_LsOfeRYl0NSHhXylFvCq02OyIvg1KznvqQ7PPXo_fB0sk1_bs3_otngXRLhv8vkj1BFB91Yk951kq_RGaTq5Z94UiOx8vqbM6V4495DCvkTFhmxPx8jUsGpZ6kQVHUXPRdq4CZxNPdlpgypTkUKGSHiuF2jTN7edfKfbZELHMxMILPWKq1PX7Etfm45MtiI=&amp;p=2&amp;sk=&amp;fvj=0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>more than 30 days ago</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>Honeywell</td>\n",
       "      <td>3557.0</td>\n",
       "      <td>Atlanta, GA</td>\n",
       "      <td>3.70</td>\n",
       "      <td>Support and mentor data scientists. Minimum of 5 years of experience in a combination of data science, machine learning, predictive analytics, statistical...</td>\n",
       "      <td>Principal Data Scientist - Atlanta, GA</td>\n",
       "      <td>http://www.indeed.com/pagead/clk?mo=r&amp;ad=-6NYlbfkN0BT1oD7gxL4d4q7k2XK_xqJz55UkLlcqeX4XFuXt5iz9snYfsSUT3YCjhoIHnNQ-5Dn3WpSwV_to5gRmnY1dWxevmGFzqLqqlIFz_9Edyh1_IXncaR6MCLo7f5ouI8dmb8uuCR-Gmx3D0JDk0Mr6-bDRl6_oL__-yabT9kowHDUPeBtZkMJognwbgSn7JKNdyR8xVuWFFOTK19pmuU2dd5avUCBVFtU2sKLt8sbDK9kZmatBTvLWw9mSk9saicemGkngM_SN-JaPwW2wHCjEO5hK98T035f01nOI9o3ia3L5wR1VUQJgkEqq37uz9VQlxlzLpE9e-1UkEpSSuVpab7uYAzIunguUW-Veb9PE7QBNJkn1V2aLOTbuEYDgbiHxkQQy5UqMb6a7SV1IxkpbHkbfInjk9I-rbwVtqZduH3r8D_W_d1EbYFUhzGETCT-VTLBqqwyAv_rFadY2vmiP5R3t_H5qjb5foJI0iHryGOAf4taEETWvPjj5-ovMDCSWJlDwEvyiMmFjw==&amp;p=3&amp;sk=&amp;fvj=0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>more than 30 days ago</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>Vision3 Solutions, Inc</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Atlanta, GA</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Data Scientist- Big Data*. May write code to automate reports and templates and consolidate data into reports and knowledge. 12 Months Contract*....</td>\n",
       "      <td>Data Scientist- Big Data</td>\n",
       "      <td>http://www.indeed.com/company/Vision3-Solutions,-Inc/jobs/Data-Scientist-1a8c086f5f6f1294?r=1&amp;fccid=37d33d67f3fba52b</td>\n",
       "      <td>hourly</td>\n",
       "      <td>187200.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1-6 days ago</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>FraudScope</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Atlanta, GA</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Experience with healthcare-related data and familiarity with current methods applied to healthcare data is preferred....</td>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>http://www.indeed.com/company/FraudScope/jobs/Data-Scientist-d72c337465398caf?r=1&amp;fccid=e87f46501099545c</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>1-6 days ago</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0                 company  number_reviews  search_city  \\\n",
       "0           0                Cotiviti            30.0  Atlanta, GA   \n",
       "1           1          Cox Automotive            46.0  Atlanta, GA   \n",
       "2           2               Honeywell          3557.0  Atlanta, GA   \n",
       "3           3  Vision3 Solutions, Inc             NaN  Atlanta, GA   \n",
       "4           4              FraudScope             NaN  Atlanta, GA   \n",
       "\n",
       "   star_rating  \\\n",
       "0         3.35   \n",
       "1         3.40   \n",
       "2         3.70   \n",
       "3          NaN   \n",
       "4          NaN   \n",
       "\n",
       "                                                                                                                                                              summary  \\\n",
       "0  This is a pioneering data scientist who will participate in expanding the new analytics backbone. Cotiviti is looking for an industry leading Data Scientist to...   \n",
       "1        Interprets problems and develops solutions to business problems using data analysis, data mining, optimization tools, and machine learning techniques and...   \n",
       "2       Support and mentor data scientists. Minimum of 5 years of experience in a combination of data science, machine learning, predictive analytics, statistical...   \n",
       "3                Data Scientist- Big Data*. May write code to automate reports and templates and consolidate data into reports and knowledge. 12 Months Contract*....   \n",
       "4                                            Experience with healthcare-related data and familiarity with current methods applied to healthcare data is preferred....   \n",
       "\n",
       "                                    title  \\\n",
       "0                          Data Scientist   \n",
       "1                          Data Scientist   \n",
       "2  Principal Data Scientist - Atlanta, GA   \n",
       "3                Data Scientist- Big Data   \n",
       "4                          Data Scientist   \n",
       "\n",
       "                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                           website  \\\n",
       "0                                                          http://www.indeed.com/pagead/clk?mo=r&ad=-6NYlbfkN0AbexXlh6WlNaC12RNLKcRQH8fywLm61v9KQllly0vTVrm9U0Iy0AOsYwOq9YOpDX03iprvWHw_SY6xCXG90mwLvOd8fb5BdJ-fu_-2tfp_KoWry1hPm7FaVRyBGPoeYEaNltu7W5i0j-OYtPh1ozEJ4oN7u_zLF7PnEIYwsSJTUyra1nlPHHQpGEq7KH9P1UhJyt0gLdmaXr7oC9iG41hrLTLQM6Dy4jOfZIDOXaBdIjV_m-vrLzXNwMCEHNxAuNUsOUWu9fNUIO6h2dpkDtS46fwUq5bUGThLBpg1h_JsmngU4OOpPDCmzhyOIZujq7kpNxhKt2UxH0Sm5knOVKSmYxJ1lNKEnygA8DCD6U_1zkkTxJJ5LBcAr9lpizyc6MVLmeSSISBIrGKE9SvJv_WjfNXpznu3719huu8jLhA-4dpvovDIXnXZf5ddKRiNMGDJ_o8d2rLvrnNdM6ksJXYj&p=1&sk=&fvj=0   \n",
       "1                                              http://www.indeed.com/pagead/clk?mo=r&ad=-6NYlbfkN0Aqmv_5JD5v6gg1ICRL12VY6BolF0XAUkQtat1DEGOKAas7v4hqpX3lzUM4h7L4VGsyuyDvf1POStkSJgHsuP2fB8YliLIijj53wvHBII5P9eQQwhBoT2Vrz0Dv0LOR9cmhA2uclIYN001l_R0jB6OflQ3KEmNIKzoNezeQCnu5X1bPju79uAEHbaTS6LdJvB-hJTy0PZPPeNKSkMyWxp3Wc2N8qN2FIq69xIhd7NBdjwnWuSZEDZvdGAtcdwsplmc_6i_owekmLU0Zj9rRIQYMM4CCSqkchPU_LsOfeRYl0NSHhXylFvCq02OyIvg1KznvqQ7PPXo_fB0sk1_bs3_otngXRLhv8vkj1BFB91Yk951kq_RGaTq5Z94UiOx8vqbM6V4495DCvkTFhmxPx8jUsGpZ6kQVHUXPRdq4CZxNPdlpgypTkUKGSHiuF2jTN7edfKfbZELHMxMILPWKq1PX7Etfm45MtiI=&p=2&sk=&fvj=0   \n",
       "2  http://www.indeed.com/pagead/clk?mo=r&ad=-6NYlbfkN0BT1oD7gxL4d4q7k2XK_xqJz55UkLlcqeX4XFuXt5iz9snYfsSUT3YCjhoIHnNQ-5Dn3WpSwV_to5gRmnY1dWxevmGFzqLqqlIFz_9Edyh1_IXncaR6MCLo7f5ouI8dmb8uuCR-Gmx3D0JDk0Mr6-bDRl6_oL__-yabT9kowHDUPeBtZkMJognwbgSn7JKNdyR8xVuWFFOTK19pmuU2dd5avUCBVFtU2sKLt8sbDK9kZmatBTvLWw9mSk9saicemGkngM_SN-JaPwW2wHCjEO5hK98T035f01nOI9o3ia3L5wR1VUQJgkEqq37uz9VQlxlzLpE9e-1UkEpSSuVpab7uYAzIunguUW-Veb9PE7QBNJkn1V2aLOTbuEYDgbiHxkQQy5UqMb6a7SV1IxkpbHkbfInjk9I-rbwVtqZduH3r8D_W_d1EbYFUhzGETCT-VTLBqqwyAv_rFadY2vmiP5R3t_H5qjb5foJI0iHryGOAf4taEETWvPjj5-ovMDCSWJlDwEvyiMmFjw==&p=3&sk=&fvj=0   \n",
       "3                                                                                                                                                                                                                                                                                                                                                                                                                                                                                             http://www.indeed.com/company/Vision3-Solutions,-Inc/jobs/Data-Scientist-1a8c086f5f6f1294?r=1&fccid=37d33d67f3fba52b   \n",
       "4                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                         http://www.indeed.com/company/FraudScope/jobs/Data-Scientist-d72c337465398caf?r=1&fccid=e87f46501099545c   \n",
       "\n",
       "  how_paid  annual_salary  is_sponsored      time_since_posted  in_city  page  \n",
       "0      NaN            NaN             1  more than 30 days ago        1     1  \n",
       "1      NaN            NaN             1  more than 30 days ago        1     1  \n",
       "2      NaN            NaN             1  more than 30 days ago        1     1  \n",
       "3   hourly       187200.0             0           1-6 days ago        1     1  \n",
       "4      NaN            NaN             0           1-6 days ago        1     1  "
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# load in the the data of scraped salaries\n",
    "jobs = pd.read_csv('data_science_jobs2.csv')\n",
    "jobs.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(303, 14)"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Making a subset with only jobs with salary included so I can make a model.\n",
    "jobs_w_salary = jobs[jobs.annual_salary.notnull()].copy()\n",
    "jobs_w_salary.info"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "focus": false,
    "id": "c3ed6de7-8fe0-4cf4-abbd-abb2a188e05b"
   },
   "source": [
    "#### We want to predict a binary variable - whether the salary was low or high. Compute the median salary and create a new binary variable that is true when the salary is high (above the median)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "collapsed": false,
    "focus": false,
    "id": "073e3f3e-21bc-4ab7-ae2e-272be0a409cc"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda/envs/py27/lib/python2.7/site-packages/ipykernel/__main__.py:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  app.launch_new_instance()\n"
     ]
    }
   ],
   "source": [
    "# calculate median and create feature with 1 as high salary\n",
    "jobs_w_salary['high_paid'] = jobs_w_salary.annual_salary.apply(lambda x: 1 if x> jobs_w_salary.annual_salary.median() else 0)\n",
    "print annual_salary.median()\n",
    "jobs_w_salary[['high_paid', 'annual_salary']].sample(frac=1) #test if worked"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "focus": false,
    "id": "3c7ec3d2-87a0-4290-9d83-a6f4a9ae7e9c"
   },
   "source": [
    "### Q: What is the baseline accuracy for this model?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "focus": false,
    "id": "987666b2-d8e6-4715-b499-c9d314fb70ce"
   },
   "source": [
    "It is 50% if we guess randomly, half the salaries will be below the median and half will be above."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "focus": false,
    "id": "ea7e00cb-9956-44ec-b585-7b95f4d6284c"
   },
   "source": [
    "#### Create a Logistic Regression model to predict High/Low salary using statsmodel. Start by ONLY using the location as a feature. Display the coefficients and write a short summary of what they mean."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 497,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimization terminated successfully.\n",
      "         Current function value: 0.633213\n",
      "         Iterations 6\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<caption>Logit Regression Results</caption>\n",
       "<tr>\n",
       "  <th>Dep. Variable:</th>     <td>high_paid</td>    <th>  No. Observations:  </th>  <td>   303</td>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Model:</th>               <td>Logit</td>      <th>  Df Residuals:      </th>  <td>   293</td>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Method:</th>               <td>MLE</td>       <th>  Df Model:          </th>  <td>     9</td>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Date:</th>          <td>Mon, 21 Nov 2016</td> <th>  Pseudo R-squ.:     </th>  <td>0.08646</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Time:</th>              <td>10:04:01</td>     <th>  Log-Likelihood:    </th> <td> -191.86</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>converged:</th>           <td>True</td>       <th>  LL-Null:           </th> <td> -210.02</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th> </th>                      <td> </td>        <th>  LLR p-value:       </th> <td>3.483e-05</td>\n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "                  <td></td>                    <th>coef</th>     <th>std err</th>      <th>z</th>      <th>P>|z|</th> <th>[95.0% Conf. Int.]</th> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Intercept</th>                        <td>   -0.7885</td> <td>    0.539</td> <td>   -1.462</td> <td> 0.144</td> <td>   -1.846     0.269</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>search_city[T.Austin, TX]</th>        <td>   -0.8855</td> <td>    0.829</td> <td>   -1.069</td> <td> 0.285</td> <td>   -2.510     0.739</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>search_city[T.Boston, MA]</th>        <td>    1.2452</td> <td>    0.614</td> <td>    2.028</td> <td> 0.043</td> <td>    0.042     2.448</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>search_city[T.Detroit, MI]</th>       <td>    0.2776</td> <td>    0.908</td> <td>    0.306</td> <td> 0.760</td> <td>   -1.502     2.057</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>search_city[T.Minneapolis, MN]</th>   <td>   -0.0588</td> <td>    0.876</td> <td>   -0.067</td> <td> 0.946</td> <td>   -1.775     1.658</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>search_city[T.New Orleans, LA]</th>   <td>    0.0953</td> <td>    1.338</td> <td>    0.071</td> <td> 0.943</td> <td>   -2.528     2.718</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>search_city[T.New York, NY]</th>      <td>    1.1122</td> <td>    0.584</td> <td>    1.903</td> <td> 0.057</td> <td>   -0.033     2.258</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>search_city[T.San Francisco, CA]</th> <td>    1.8563</td> <td>    0.643</td> <td>    2.888</td> <td> 0.004</td> <td>    0.597     3.116</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>search_city[T.Seattle, WA]</th>       <td>   -0.0445</td> <td>    0.659</td> <td>   -0.067</td> <td> 0.946</td> <td>   -1.336     1.247</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>search_city[T.Washington, DC]</th>    <td>    0.4436</td> <td>    0.626</td> <td>    0.709</td> <td> 0.478</td> <td>   -0.783     1.670</td>\n",
       "</tr>\n",
       "</table>"
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.summary.Summary'>\n",
       "\"\"\"\n",
       "                           Logit Regression Results                           \n",
       "==============================================================================\n",
       "Dep. Variable:              high_paid   No. Observations:                  303\n",
       "Model:                          Logit   Df Residuals:                      293\n",
       "Method:                           MLE   Df Model:                            9\n",
       "Date:                Mon, 21 Nov 2016   Pseudo R-squ.:                 0.08646\n",
       "Time:                        10:04:01   Log-Likelihood:                -191.86\n",
       "converged:                       True   LL-Null:                       -210.02\n",
       "                                        LLR p-value:                 3.483e-05\n",
       "====================================================================================================\n",
       "                                       coef    std err          z      P>|z|      [95.0% Conf. Int.]\n",
       "----------------------------------------------------------------------------------------------------\n",
       "Intercept                           -0.7885      0.539     -1.462      0.144        -1.846     0.269\n",
       "search_city[T.Austin, TX]           -0.8855      0.829     -1.069      0.285        -2.510     0.739\n",
       "search_city[T.Boston, MA]            1.2452      0.614      2.028      0.043         0.042     2.448\n",
       "search_city[T.Detroit, MI]           0.2776      0.908      0.306      0.760        -1.502     2.057\n",
       "search_city[T.Minneapolis, MN]      -0.0588      0.876     -0.067      0.946        -1.775     1.658\n",
       "search_city[T.New Orleans, LA]       0.0953      1.338      0.071      0.943        -2.528     2.718\n",
       "search_city[T.New York, NY]          1.1122      0.584      1.903      0.057        -0.033     2.258\n",
       "search_city[T.San Francisco, CA]     1.8563      0.643      2.888      0.004         0.597     3.116\n",
       "search_city[T.Seattle, WA]          -0.0445      0.659     -0.067      0.946        -1.336     1.247\n",
       "search_city[T.Washington, DC]        0.4436      0.626      0.709      0.478        -0.783     1.670\n",
       "====================================================================================================\n",
       "\"\"\""
      ]
     },
     "execution_count": 497,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# create statsmodel and summary\n",
    "import statsmodels.formula.api as sm\n",
    "import patsy\n",
    "\n",
    "y, X = patsy.dmatrices('high_paid ~ search_city', data=jobs_w_salary)\n",
    "sm.Logit(y, X).fit().summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "City|Coefficient|Odds Ratio|Interpretation|p-value\n",
    "--|--|--|--|--\n",
    "Austin|-0.8855|0.41|The odds a job in Austin will be \"high-paid\" is 0.41 times the odds of a job not in Austin (or 144% lower), all else being equal|0.285 (not statistically significant)\n",
    "Boston|1.2452|3.47|The odds a job in Boston will be \"high-paid\" is 3.47 times the odds of a job not in Boston (or 247% higher, all else being equal.|0.043 (statistically significant, but borderline)\n",
    "Detroit|0.2776|1.32|The odds a job in Detroit will be \"high-paid\" is 1.32 times the odds of a job not in Detroit (or 32% higher), all else being equal.|0.760 (not statistically significant)\n",
    "Minneapolis|-0.0588|0.94|The odds a job in Minneapolis will be \"high-paid\" is 0.94 times the odds of a job not in Minneapolis (or 6% lower), all else being equal.|0.946 (not statistically significant)\n",
    "New Orleans|0.0953|1.09|The odds a job in New Orleans will be \"high-paid\" is 1.09 times the odds of a job not in New Orleans (or 9% higher), all else being equal.|0.943 (not statistically significant)\n",
    "New York|1.1122|3.04|The odds a job in New York will be \"high-paid\" is 3.04 times the odds of a job not in New York (or 204% higher), all else being equal.|0.057 (borderline statistically significant)\n",
    "San Francisco|1.8563|6.40|The odds a job in San Francisco will be \"high-paid\" is 6.40 times the odds of a job not in San Francisco (or 540% higher), all else being equal.|0.004 (statistically significant)\n",
    "Seattle|-0.0445|0.96|The odds a job in Seattle will be \"high-paid\" is 0.96 times the odds of a job not in Seattle (or 4% lower), all else being equal.|0.946 (not statistically significant)\n",
    "Washington, DC|0.4436|1.56|The odds a job in DC will be \"high-paid\" is 1.56 times the odds of a job not in DC (or 56% higher), all else being equal.|0.478 (not statistically significant)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "There seems to be some relationship between city and whether a job's salary will be higher or lower than the median (evidenced by the Log-Likelihood with a low p-value, and some low p-values associated with certain cities). However, the high p-values associated with many of the cities suggests that each city isn't strongly associated with the income variable by themselves. Given that New York, San Francisco, Boston, and DC are known to be expensive cities with higher salaries to compensate, it may make sense to categorize these cities as \"expensive cities\" and try to keep this single yes-no variable in the model instead."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 265,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda/envs/py27/lib/python2.7/site-packages/ipykernel/__main__.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  from ipykernel import kernelapp as app\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>search_city</th>\n",
       "      <th>expensive_city</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4209</th>\n",
       "      <td>Seattle, WA</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018</th>\n",
       "      <td>New York, NY</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2641</th>\n",
       "      <td>Boston, MA</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3337</th>\n",
       "      <td>Austin, TX</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5396</th>\n",
       "      <td>Minneapolis, MN</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3138</th>\n",
       "      <td>Boston, MA</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>911</th>\n",
       "      <td>Washington, DC</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1368</th>\n",
       "      <td>New York, NY</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1755</th>\n",
       "      <td>New York, NY</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4981</th>\n",
       "      <td>San Francisco, CA</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            search_city  expensive_city\n",
       "4209        Seattle, WA               0\n",
       "2018       New York, NY               1\n",
       "2641         Boston, MA               1\n",
       "3337         Austin, TX               0\n",
       "5396    Minneapolis, MN               0\n",
       "3138         Boston, MA               1\n",
       "911      Washington, DC               1\n",
       "1368       New York, NY               1\n",
       "1755       New York, NY               1\n",
       "4981  San Francisco, CA               1"
      ]
     },
     "execution_count": 265,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "expensive_cities = ['Washington, DC', 'San Francisco, CA', 'Boston, MA', 'New York, NY']\n",
    "jobs_w_salary['expensive_city'] = jobs_w_salary.search_city.apply(lambda x: 1 if x in expensive_cities else 0)\n",
    "jobs_w_salary[['search_city', 'expensive_city']].sample(frac=1).head(10) #checking if it worked"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 266,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimization terminated successfully.\n",
      "         Current function value: 0.652772\n",
      "         Iterations 5\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<caption>Logit Regression Results</caption>\n",
       "<tr>\n",
       "  <th>Dep. Variable:</th>     <td>high_paid</td>    <th>  No. Observations:  </th>  <td>   303</td>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Model:</th>               <td>Logit</td>      <th>  Df Residuals:      </th>  <td>   301</td>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Method:</th>               <td>MLE</td>       <th>  Df Model:          </th>  <td>     1</td>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Date:</th>          <td>Sat, 19 Nov 2016</td> <th>  Pseudo R-squ.:     </th>  <td>0.05824</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Time:</th>              <td>17:51:35</td>     <th>  Log-Likelihood:    </th> <td> -197.79</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>converged:</th>           <td>True</td>       <th>  LL-Null:           </th> <td> -210.02</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th> </th>                      <td> </td>        <th>  LLR p-value:       </th> <td>7.571e-07</td>\n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "         <td></td>           <th>coef</th>     <th>std err</th>      <th>z</th>      <th>P>|z|</th> <th>[95.0% Conf. Int.]</th> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Intercept</th>      <td>   -0.9400</td> <td>    0.236</td> <td>   -3.986</td> <td> 0.000</td> <td>   -1.402    -0.478</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>expensive_city</th> <td>    1.2990</td> <td>    0.274</td> <td>    4.745</td> <td> 0.000</td> <td>    0.762     1.835</td>\n",
       "</tr>\n",
       "</table>"
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.summary.Summary'>\n",
       "\"\"\"\n",
       "                           Logit Regression Results                           \n",
       "==============================================================================\n",
       "Dep. Variable:              high_paid   No. Observations:                  303\n",
       "Model:                          Logit   Df Residuals:                      301\n",
       "Method:                           MLE   Df Model:                            1\n",
       "Date:                Sat, 19 Nov 2016   Pseudo R-squ.:                 0.05824\n",
       "Time:                        17:51:35   Log-Likelihood:                -197.79\n",
       "converged:                       True   LL-Null:                       -210.02\n",
       "                                        LLR p-value:                 7.571e-07\n",
       "==================================================================================\n",
       "                     coef    std err          z      P>|z|      [95.0% Conf. Int.]\n",
       "----------------------------------------------------------------------------------\n",
       "Intercept         -0.9400      0.236     -3.986      0.000        -1.402    -0.478\n",
       "expensive_city     1.2990      0.274      4.745      0.000         0.762     1.835\n",
       "==================================================================================\n",
       "\"\"\""
      ]
     },
     "execution_count": 266,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y, X = patsy.dmatrices('high_paid ~ expensive_city', data=jobs_w_salary)\n",
    "sm.Logit(y, X).fit().summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The pseudo R-squared isn't much lower doing this method, but the p-values are consistently stronger. These \"expensive cities\" have 3.67X the odds of being a high-paid job compared to the other cities, or in other words the odds are 267% higher. Since this greatly reduces the number of parameters, I will keep this change."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 294,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimization terminated successfully.\n",
      "         Current function value: 0.636962\n",
      "         Iterations 5\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<caption>Logit Regression Results</caption>\n",
       "<tr>\n",
       "  <th>Dep. Variable:</th>     <td>high_paid</td>    <th>  No. Observations:  </th>  <td>   303</td>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Model:</th>               <td>Logit</td>      <th>  Df Residuals:      </th>  <td>   300</td>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Method:</th>               <td>MLE</td>       <th>  Df Model:          </th>  <td>     2</td>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Date:</th>          <td>Sat, 19 Nov 2016</td> <th>  Pseudo R-squ.:     </th>  <td>0.08105</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Time:</th>              <td>19:09:33</td>     <th>  Log-Likelihood:    </th> <td> -193.00</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>converged:</th>           <td>True</td>       <th>  LL-Null:           </th> <td> -210.02</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th> </th>                      <td> </td>        <th>  LLR p-value:       </th> <td>4.048e-08</td>\n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "         <td></td>           <th>coef</th>     <th>std err</th>      <th>z</th>      <th>P>|z|</th> <th>[95.0% Conf. Int.]</th> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Intercept</th>      <td>   -1.6342</td> <td>    0.336</td> <td>   -4.862</td> <td> 0.000</td> <td>   -2.293    -0.975</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>expensive_city</th> <td>    1.4045</td> <td>    0.281</td> <td>    5.003</td> <td> 0.000</td> <td>    0.854     1.955</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>in_city</th>        <td>    0.8473</td> <td>    0.278</td> <td>    3.045</td> <td> 0.002</td> <td>    0.302     1.393</td>\n",
       "</tr>\n",
       "</table>"
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.summary.Summary'>\n",
       "\"\"\"\n",
       "                           Logit Regression Results                           \n",
       "==============================================================================\n",
       "Dep. Variable:              high_paid   No. Observations:                  303\n",
       "Model:                          Logit   Df Residuals:                      300\n",
       "Method:                           MLE   Df Model:                            2\n",
       "Date:                Sat, 19 Nov 2016   Pseudo R-squ.:                 0.08105\n",
       "Time:                        19:09:33   Log-Likelihood:                -193.00\n",
       "converged:                       True   LL-Null:                       -210.02\n",
       "                                        LLR p-value:                 4.048e-08\n",
       "==================================================================================\n",
       "                     coef    std err          z      P>|z|      [95.0% Conf. Int.]\n",
       "----------------------------------------------------------------------------------\n",
       "Intercept         -1.6342      0.336     -4.862      0.000        -2.293    -0.975\n",
       "expensive_city     1.4045      0.281      5.003      0.000         0.854     1.955\n",
       "in_city            0.8473      0.278      3.045      0.002         0.302     1.393\n",
       "==================================================================================\n",
       "\"\"\""
      ]
     },
     "execution_count": 294,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# now I want to see if being inside the city adds something to the model\n",
    "y, X = patsy.dmatrices('high_paid ~ expensive_city + in_city', data=jobs_w_salary)\n",
    "sm.Logit(y, X).fit().summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It definitely appears that being in the city is a predictor, so I will keep in model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "focus": false,
    "id": "1ecd7811-d200-44bc-942f-4beb76d2689c"
   },
   "source": [
    "#### Create a few new variables in your dataframe to represent interesting features of a job title.\n",
    "- For example, create a feature that represents whether 'Senior' or 'Manager' is in the title \n",
    "- Then build a new Logistic Regression model with these features. Do they add any value? \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>word</th>\n",
       "      <th>count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>89</th>\n",
       "      <td>data</td>\n",
       "      <td>119</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>102</th>\n",
       "      <td>scientist</td>\n",
       "      <td>109</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>346</th>\n",
       "      <td>analyst</td>\n",
       "      <td>73</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>136</th>\n",
       "      <td>research</td>\n",
       "      <td>42</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>200</th>\n",
       "      <td>senior</td>\n",
       "      <td>35</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>158</th>\n",
       "      <td>engineer</td>\n",
       "      <td>26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>291</th>\n",
       "      <td>quantitative</td>\n",
       "      <td>24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>248</th>\n",
       "      <td>learning</td>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>76</th>\n",
       "      <td>machine</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>314</th>\n",
       "      <td>lead</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>355</th>\n",
       "      <td>engineering</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>326</th>\n",
       "      <td>of</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>manager</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61</th>\n",
       "      <td>science</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>105</th>\n",
       "      <td>developer</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>226</th>\n",
       "      <td>specialist</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>343</th>\n",
       "      <td>technician</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>329</th>\n",
       "      <td>software</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>179</th>\n",
       "      <td>and</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>130</th>\n",
       "      <td>laboratory</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>risk</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>196</th>\n",
       "      <td>medical</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>140</th>\n",
       "      <td>associate</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>368</th>\n",
       "      <td>for</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>92</th>\n",
       "      <td>sr</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>307</th>\n",
       "      <td>big</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>281</th>\n",
       "      <td>director</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>278</th>\n",
       "      <td>development</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>286</th>\n",
       "      <td>i</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57</th>\n",
       "      <td>iii</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52</th>\n",
       "      <td>market</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>103</th>\n",
       "      <td>statistical</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>88</th>\n",
       "      <td>president</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>328</th>\n",
       "      <td>or</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>217</th>\n",
       "      <td>assistant</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>business</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>230</th>\n",
       "      <td>analytics</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>354</th>\n",
       "      <td>coordinator</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>112</th>\n",
       "      <td>python</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>271</th>\n",
       "      <td>vp</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>174</th>\n",
       "      <td>forensic</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>369</th>\n",
       "      <td>vice</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>311</th>\n",
       "      <td>security</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>global</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>321</th>\n",
       "      <td>statistician</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>94</th>\n",
       "      <td>chief</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>356</th>\n",
       "      <td>at</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>287</th>\n",
       "      <td>analysis</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55</th>\n",
       "      <td>company</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>152</th>\n",
       "      <td>researcher</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>138</th>\n",
       "      <td>health</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>313</th>\n",
       "      <td>recommendation</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>336</th>\n",
       "      <td>support</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>159</th>\n",
       "      <td>city</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>114</th>\n",
       "      <td>scene</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>337</th>\n",
       "      <td>clinical</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>210</th>\n",
       "      <td>crime</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>microbiologist</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>223</th>\n",
       "      <td>banking</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>program</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>367</th>\n",
       "      <td>remote</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>231</th>\n",
       "      <td>computer</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>221</th>\n",
       "      <td>hedge</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>220</th>\n",
       "      <td>new</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>level</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>237</th>\n",
       "      <td>bureau</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>171</th>\n",
       "      <td>environmental</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>84</th>\n",
       "      <td>lab</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>127</th>\n",
       "      <td>aide</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>junior</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>access</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>principal</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>350</th>\n",
       "      <td>supervisor</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>257</th>\n",
       "      <td>sales</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>177</th>\n",
       "      <td>architect</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>175</th>\n",
       "      <td>project</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>284</th>\n",
       "      <td>center</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>293</th>\n",
       "      <td>clearance</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>298</th>\n",
       "      <td>executive</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>279</th>\n",
       "      <td>reporting</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>280</th>\n",
       "      <td>ios</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>282</th>\n",
       "      <td>identity</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>292</th>\n",
       "      <td>the</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>170</th>\n",
       "      <td>midlevel</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>142</th>\n",
       "      <td>scientistengineer</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>277</th>\n",
       "      <td>quant</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>236</th>\n",
       "      <td>fullstack</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>213</th>\n",
       "      <td>equity</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>211</th>\n",
       "      <td>only</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>208</th>\n",
       "      <td>office</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>207</th>\n",
       "      <td>staff</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>201</th>\n",
       "      <td>consumer</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>250</th>\n",
       "      <td>java</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>251</th>\n",
       "      <td>consultancy</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>188</th>\n",
       "      <td>multiple</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>186</th>\n",
       "      <td>korean</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>183</th>\n",
       "      <td>contact</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>260</th>\n",
       "      <td>representative</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>173</th>\n",
       "      <td>b</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>169</th>\n",
       "      <td>gps</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>des</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>biological</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>skills</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>giving</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>cool</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>depar</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>evaluatio</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>safety</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>dollar</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>chain</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>investment</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>section</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53</th>\n",
       "      <td>devops</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>experience</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51</th>\n",
       "      <td>viz</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>api</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>app</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>york</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>talend</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>chemical</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>compliance</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>international</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>study</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>biostatistician</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>water</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>mec</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>med</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>net</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>113</th>\n",
       "      <td>practice</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>115</th>\n",
       "      <td>records</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>116</th>\n",
       "      <td>cutting</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>gs</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>193</th>\n",
       "      <td>device</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>192</th>\n",
       "      <td>organization</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>191</th>\n",
       "      <td>engineercomplete</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>190</th>\n",
       "      <td>aws</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>189</th>\n",
       "      <td>wendydata</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>187</th>\n",
       "      <td>experienced</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>184</th>\n",
       "      <td>advis</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>195</th>\n",
       "      <td>sensing</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>182</th>\n",
       "      <td>sciences</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>181</th>\n",
       "      <td>conversion</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>180</th>\n",
       "      <td>endocrinology</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>178</th>\n",
       "      <td>hacking</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>176</th>\n",
       "      <td>r</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>172</th>\n",
       "      <td>datawarehouse</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>194</th>\n",
       "      <td>mobile</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>197</th>\n",
       "      <td>engineerteam</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>117</th>\n",
       "      <td>fingerprint</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>212</th>\n",
       "      <td>candidates</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>222</th>\n",
       "      <td>nurse</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>219</th>\n",
       "      <td>dx</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>218</th>\n",
       "      <td>hematology</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>216</th>\n",
       "      <td>topranked</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>215</th>\n",
       "      <td>local</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>214</th>\n",
       "      <td>technicianscientist</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>209</th>\n",
       "      <td>earned</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>198</th>\n",
       "      <td>ext</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>206</th>\n",
       "      <td>solutions</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>205</th>\n",
       "      <td>postdoctoral</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>204</th>\n",
       "      <td>planning</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>203</th>\n",
       "      <td>extractions</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>202</th>\n",
       "      <td>advisory</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>199</th>\n",
       "      <td>tech</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>168</th>\n",
       "      <td>molecular</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>167</th>\n",
       "      <td>analytical</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>166</th>\n",
       "      <td>engineersscala</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>125</th>\n",
       "      <td>energy</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>133</th>\n",
       "      <td>driving</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>132</th>\n",
       "      <td>ftr</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>131</th>\n",
       "      <td>fu</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>129</th>\n",
       "      <td>simnjp</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>128</th>\n",
       "      <td>invitro</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>126</th>\n",
       "      <td>administrator</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>124</th>\n",
       "      <td>mental</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>165</th>\n",
       "      <td>needed</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>123</th>\n",
       "      <td>financial</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>122</th>\n",
       "      <td>worldclass</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>121</th>\n",
       "      <td>l</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>120</th>\n",
       "      <td>bank</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>119</th>\n",
       "      <td>hall</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>118</th>\n",
       "      <td>impaired</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>134</th>\n",
       "      <td>open</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>135</th>\n",
       "      <td>dsr</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>137</th>\n",
       "      <td>investigation</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>139</th>\n",
       "      <td>assurance</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>141</th>\n",
       "      <td>cockpit</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>143</th>\n",
       "      <td>imaging</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>144</th>\n",
       "      <td>jira</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>146</th>\n",
       "      <td>care</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>147</th>\n",
       "      <td>language</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>148</th>\n",
       "      <td>w</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>149</th>\n",
       "      <td>retail</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>151</th>\n",
       "      <td>plastics</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>153</th>\n",
       "      <td>coding</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>154</th>\n",
       "      <td>primary</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>157</th>\n",
       "      <td>ecommerce</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>161</th>\n",
       "      <td>leading</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>163</th>\n",
       "      <td>virologymolecular</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>370</th>\n",
       "      <td>behavioral</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>371 rows Ã— 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                    word  count\n",
       "89                  data    119\n",
       "102            scientist    109\n",
       "346              analyst     73\n",
       "136             research     42\n",
       "200               senior     35\n",
       "158             engineer     26\n",
       "291         quantitative     24\n",
       "248             learning     19\n",
       "76               machine     18\n",
       "314                 lead     15\n",
       "355          engineering     14\n",
       "326                   of     13\n",
       "5                manager     12\n",
       "61               science     11\n",
       "105            developer     11\n",
       "226           specialist     10\n",
       "343           technician     10\n",
       "329             software     10\n",
       "179                  and     10\n",
       "130           laboratory     10\n",
       "13                  risk      9\n",
       "196              medical      9\n",
       "140            associate      8\n",
       "368                  for      8\n",
       "92                    sr      8\n",
       "307                  big      7\n",
       "281             director      7\n",
       "278          development      6\n",
       "286                    i      5\n",
       "57                   iii      5\n",
       "52                market      5\n",
       "103          statistical      5\n",
       "88             president      5\n",
       "328                   or      5\n",
       "217            assistant      5\n",
       "28              business      5\n",
       "230            analytics      5\n",
       "354          coordinator      4\n",
       "112               python      4\n",
       "271                   vp      4\n",
       "174             forensic      4\n",
       "369                 vice      4\n",
       "311             security      4\n",
       "3                 global      4\n",
       "321         statistician      4\n",
       "94                 chief      4\n",
       "356                   at      4\n",
       "287             analysis      4\n",
       "55               company      4\n",
       "152           researcher      3\n",
       "138               health      3\n",
       "313       recommendation      3\n",
       "336              support      3\n",
       "159                 city      3\n",
       "114                scene      3\n",
       "337             clinical      3\n",
       "210                crime      3\n",
       "7         microbiologist      3\n",
       "223              banking      3\n",
       "10               program      3\n",
       "367               remote      3\n",
       "231             computer      3\n",
       "221                hedge      3\n",
       "220                  new      3\n",
       "16                 level      3\n",
       "237               bureau      3\n",
       "171        environmental      3\n",
       "84                   lab      3\n",
       "127                 aide      3\n",
       "29                junior      3\n",
       "32                access      3\n",
       "35             principal      3\n",
       "350           supervisor      3\n",
       "257                sales      3\n",
       "177            architect      3\n",
       "175              project      3\n",
       "284               center      3\n",
       "293            clearance      2\n",
       "298            executive      2\n",
       "279            reporting      2\n",
       "280                  ios      2\n",
       "282             identity      2\n",
       "292                  the      2\n",
       "170             midlevel      2\n",
       "142    scientistengineer      2\n",
       "277                quant      2\n",
       "236            fullstack      2\n",
       "213               equity      2\n",
       "211                 only      2\n",
       "208               office      2\n",
       "207                staff      2\n",
       "201             consumer      2\n",
       "250                 java      2\n",
       "251          consultancy      2\n",
       "188             multiple      2\n",
       "186               korean      2\n",
       "183              contact      2\n",
       "260       representative      2\n",
       "173                    b      2\n",
       "169                  gps      2\n",
       "..                   ...    ...\n",
       "20                   des      1\n",
       "19            biological      1\n",
       "17                skills      1\n",
       "30                giving      1\n",
       "15                  cool      1\n",
       "14                 depar      1\n",
       "12             evaluatio      1\n",
       "11                safety      1\n",
       "4                 dollar      1\n",
       "2                  chain      1\n",
       "26            investment      1\n",
       "31               section      1\n",
       "53                devops      1\n",
       "43            experience      1\n",
       "51                   viz      1\n",
       "49                   api      1\n",
       "48                   app      1\n",
       "47                  york      1\n",
       "46                talend      1\n",
       "45              chemical      1\n",
       "42            compliance      1\n",
       "33         international      1\n",
       "41                 study      1\n",
       "39       biostatistician      1\n",
       "38                 water      1\n",
       "37                   mec      1\n",
       "36                   med      1\n",
       "34                   net      1\n",
       "113             practice      1\n",
       "115              records      1\n",
       "116              cutting      1\n",
       "1                     gs      1\n",
       "193               device      1\n",
       "192         organization      1\n",
       "191     engineercomplete      1\n",
       "190                  aws      1\n",
       "189            wendydata      1\n",
       "187          experienced      1\n",
       "184                advis      1\n",
       "195              sensing      1\n",
       "182             sciences      1\n",
       "181           conversion      1\n",
       "180        endocrinology      1\n",
       "178              hacking      1\n",
       "176                    r      1\n",
       "172        datawarehouse      1\n",
       "194               mobile      1\n",
       "197         engineerteam      1\n",
       "117          fingerprint      1\n",
       "212           candidates      1\n",
       "222                nurse      1\n",
       "219                   dx      1\n",
       "218           hematology      1\n",
       "216            topranked      1\n",
       "215                local      1\n",
       "214  technicianscientist      1\n",
       "209               earned      1\n",
       "198                  ext      1\n",
       "206            solutions      1\n",
       "205         postdoctoral      1\n",
       "204             planning      1\n",
       "203          extractions      1\n",
       "202             advisory      1\n",
       "199                 tech      1\n",
       "168            molecular      1\n",
       "167           analytical      1\n",
       "166       engineersscala      1\n",
       "125               energy      1\n",
       "133              driving      1\n",
       "132                  ftr      1\n",
       "131                   fu      1\n",
       "129               simnjp      1\n",
       "128              invitro      1\n",
       "126        administrator      1\n",
       "124               mental      1\n",
       "165               needed      1\n",
       "123            financial      1\n",
       "122           worldclass      1\n",
       "121                    l      1\n",
       "120                 bank      1\n",
       "119                 hall      1\n",
       "118             impaired      1\n",
       "134                 open      1\n",
       "135                  dsr      1\n",
       "137        investigation      1\n",
       "139            assurance      1\n",
       "141              cockpit      1\n",
       "143              imaging      1\n",
       "144                 jira      1\n",
       "146                 care      1\n",
       "147             language      1\n",
       "148                    w      1\n",
       "149               retail      1\n",
       "151             plastics      1\n",
       "153               coding      1\n",
       "154              primary      1\n",
       "157            ecommerce      1\n",
       "161              leading      1\n",
       "163    virologymolecular      1\n",
       "370           behavioral      1\n",
       "\n",
       "[371 rows x 2 columns]"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#creating a dataframe with the words and how frequent they are to identify what words may be associated with different types of jobs\n",
    "words = [re.sub('[^A-Za-z]', '', x.lower()) for x in ' '.join(list(jobs_w_salary.title)).split(' ') if re.sub('[^A-Za-z]', '', x.lower()) != '']\n",
    "from collections import Counter\n",
    "word_counts = pd.DataFrame(Counter(words).items(), columns = ['word', 'count']).sort_values('count', ascending=False)\n",
    "word_counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 468,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>word</th>\n",
       "      <th>count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>517</th>\n",
       "      <td>and</td>\n",
       "      <td>345</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>443</th>\n",
       "      <td>data</td>\n",
       "      <td>247</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>747</th>\n",
       "      <td>to</td>\n",
       "      <td>202</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>278</th>\n",
       "      <td>the</td>\n",
       "      <td>195</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>677</th>\n",
       "      <td>of</td>\n",
       "      <td>177</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>819</th>\n",
       "      <td>a</td>\n",
       "      <td>162</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>251</th>\n",
       "      <td>in</td>\n",
       "      <td>126</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>707</th>\n",
       "      <td>with</td>\n",
       "      <td>97</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>309</th>\n",
       "      <td>for</td>\n",
       "      <td>91</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>247</th>\n",
       "      <td>is</td>\n",
       "      <td>91</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>771</th>\n",
       "      <td>scientists</td>\n",
       "      <td>70</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>213</th>\n",
       "      <td>analytics</td>\n",
       "      <td>59</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>80</th>\n",
       "      <td>machine</td>\n",
       "      <td>58</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1338</th>\n",
       "      <td>will</td>\n",
       "      <td>56</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>591</th>\n",
       "      <td>learning</td>\n",
       "      <td>55</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>372</th>\n",
       "      <td>team</td>\n",
       "      <td>48</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>780</th>\n",
       "      <td>experience</td>\n",
       "      <td>47</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>827</th>\n",
       "      <td>scientist</td>\n",
       "      <td>46</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>719</th>\n",
       "      <td>as</td>\n",
       "      <td>45</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1334</th>\n",
       "      <td>an</td>\n",
       "      <td>40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>749</th>\n",
       "      <td>health</td>\n",
       "      <td>40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>683</th>\n",
       "      <td>or</td>\n",
       "      <td>40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1214</th>\n",
       "      <td>our</td>\n",
       "      <td>38</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>855</th>\n",
       "      <td>research</td>\n",
       "      <td>37</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>378</th>\n",
       "      <td>be</td>\n",
       "      <td>37</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>481</th>\n",
       "      <td>looking</td>\n",
       "      <td>35</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>674</th>\n",
       "      <td>on</td>\n",
       "      <td>33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>772</th>\n",
       "      <td>public</td>\n",
       "      <td>33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>69</th>\n",
       "      <td>work</td>\n",
       "      <td>31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>935</th>\n",
       "      <td>are</td>\n",
       "      <td>31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1161</th>\n",
       "      <td>this</td>\n",
       "      <td>30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>507</th>\n",
       "      <td>that</td>\n",
       "      <td>27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>795</th>\n",
       "      <td>company</td>\n",
       "      <td>26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>798</th>\n",
       "      <td>science</td>\n",
       "      <td>25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>728</th>\n",
       "      <td>you</td>\n",
       "      <td>25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>998</th>\n",
       "      <td>analysis</td>\n",
       "      <td>25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1403</th>\n",
       "      <td>software</td>\n",
       "      <td>24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1237</th>\n",
       "      <td>their</td>\n",
       "      <td>24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>456</th>\n",
       "      <td>statistical</td>\n",
       "      <td>24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1276</th>\n",
       "      <td>knowledge</td>\n",
       "      <td>23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1153</th>\n",
       "      <td>from</td>\n",
       "      <td>23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>328</th>\n",
       "      <td>clinical</td>\n",
       "      <td>22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1054</th>\n",
       "      <td>by</td>\n",
       "      <td>22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>981</th>\n",
       "      <td>engineers</td>\n",
       "      <td>21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>351</th>\n",
       "      <td>sql</td>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1029</th>\n",
       "      <td>methods</td>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1017</th>\n",
       "      <td>big</td>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>296</th>\n",
       "      <td>advanced</td>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>520</th>\n",
       "      <td>san</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>542</th>\n",
       "      <td>senior</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>720</th>\n",
       "      <td>at</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1247</th>\n",
       "      <td>have</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>420</th>\n",
       "      <td>growing</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>222</th>\n",
       "      <td>we</td>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1291</th>\n",
       "      <td>predictive</td>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>185</th>\n",
       "      <td>medical</td>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>risk</td>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>514</th>\n",
       "      <td>r</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>669</th>\n",
       "      <td>scientific</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>453</th>\n",
       "      <td>years</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>67</th>\n",
       "      <td>join</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>123</th>\n",
       "      <td>laboratory</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>407</th>\n",
       "      <td>working</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>160</th>\n",
       "      <td>project</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>506</th>\n",
       "      <td>mining</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>88</th>\n",
       "      <td>algorithms</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1438</th>\n",
       "      <td>francisco</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1435</th>\n",
       "      <td>other</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>216</th>\n",
       "      <td>subject</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>369</th>\n",
       "      <td>level</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>697</th>\n",
       "      <td>area</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1132</th>\n",
       "      <td>degree</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>434</th>\n",
       "      <td>product</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>348</th>\n",
       "      <td>developers</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>658</th>\n",
       "      <td>using</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1064</th>\n",
       "      <td>statistics</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>988</th>\n",
       "      <td>development</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1319</th>\n",
       "      <td>relevant</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1233</th>\n",
       "      <td>quality</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>717</th>\n",
       "      <td>deep</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1259</th>\n",
       "      <td>who</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>436</th>\n",
       "      <td>information</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>226</th>\n",
       "      <td>modeling</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1254</th>\n",
       "      <td>techniques</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1246</th>\n",
       "      <td>providing</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>899</th>\n",
       "      <td>experienced</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1145</th>\n",
       "      <td>manage</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>826</th>\n",
       "      <td>mission</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>523</th>\n",
       "      <td>sas</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>430</th>\n",
       "      <td>requirements</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>146</th>\n",
       "      <td>primary</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>490</th>\n",
       "      <td>care</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>497</th>\n",
       "      <td>one</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1208</th>\n",
       "      <td>university</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1066</th>\n",
       "      <td>fast</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1128</th>\n",
       "      <td>access</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>306</th>\n",
       "      <td>people</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1201</th>\n",
       "      <td>python</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>277</th>\n",
       "      <td>quantitative</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>548</th>\n",
       "      <td>only</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>567</th>\n",
       "      <td>representatives</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>568</th>\n",
       "      <td>boundaries</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>573</th>\n",
       "      <td>screen</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>575</th>\n",
       "      <td>uptodate</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>581</th>\n",
       "      <td>contract</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>582</th>\n",
       "      <td>nephrology</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>529</th>\n",
       "      <td>take</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>526</th>\n",
       "      <td>consortium</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>525</th>\n",
       "      <td>conversion</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>524</th>\n",
       "      <td>any</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>473</th>\n",
       "      <td>term</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>474</th>\n",
       "      <td>ed</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>476</th>\n",
       "      <td>challenges</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>477</th>\n",
       "      <td>year</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>478</th>\n",
       "      <td>obsession</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>480</th>\n",
       "      <td>space</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>485</th>\n",
       "      <td>theory</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>486</th>\n",
       "      <td>diagnostic</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>488</th>\n",
       "      <td>california</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>489</th>\n",
       "      <td>ord</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>491</th>\n",
       "      <td>training</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>492</th>\n",
       "      <td>language</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>494</th>\n",
       "      <td>turn</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>495</th>\n",
       "      <td>first</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>496</th>\n",
       "      <td>coming</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>498</th>\n",
       "      <td>long</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>499</th>\n",
       "      <td>directly</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>500</th>\n",
       "      <td>methodological</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>504</th>\n",
       "      <td>white</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>508</th>\n",
       "      <td>accurately</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>509</th>\n",
       "      <td>specialists</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>513</th>\n",
       "      <td>scraping</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>515</th>\n",
       "      <td>proactive</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>516</th>\n",
       "      <td>stateof</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>518</th>\n",
       "      <td>gathering</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>521</th>\n",
       "      <td>briefs</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>522</th>\n",
       "      <td>crossover</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>585</th>\n",
       "      <td>residency</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>586</th>\n",
       "      <td>traded</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>587</th>\n",
       "      <td>cancer</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>644</th>\n",
       "      <td>improvement</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>653</th>\n",
       "      <td>papers</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>655</th>\n",
       "      <td>early</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>656</th>\n",
       "      <td>eihaas</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>659</th>\n",
       "      <td>fortune</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>663</th>\n",
       "      <td>either</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>664</th>\n",
       "      <td>competition</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>665</th>\n",
       "      <td>organizing</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>666</th>\n",
       "      <td>confirm</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>667</th>\n",
       "      <td>bigdata</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>675</th>\n",
       "      <td>central</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>676</th>\n",
       "      <td>package</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>679</th>\n",
       "      <td>acclimate</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>680</th>\n",
       "      <td>acl</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>682</th>\n",
       "      <td>testimony</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>688</th>\n",
       "      <td>newtons</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>689</th>\n",
       "      <td>involvement</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>691</th>\n",
       "      <td>scientistdata</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>692</th>\n",
       "      <td>elementary</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>695</th>\n",
       "      <td>supervising</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>696</th>\n",
       "      <td>prepare</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>698</th>\n",
       "      <td>there</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>699</th>\n",
       "      <td>hazards</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>701</th>\n",
       "      <td>attends</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>702</th>\n",
       "      <td>recommends</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>703</th>\n",
       "      <td>trainings</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>706</th>\n",
       "      <td>promote</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>708</th>\n",
       "      <td>extend</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>652</th>\n",
       "      <td>specimen</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>642</th>\n",
       "      <td>spatiotemporal</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>588</th>\n",
       "      <td>period</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>640</th>\n",
       "      <td>valuable</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>589</th>\n",
       "      <td>sampling</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>590</th>\n",
       "      <td>grants</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>592</th>\n",
       "      <td>poc</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>593</th>\n",
       "      <td>specializing</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>596</th>\n",
       "      <td>locally</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>599</th>\n",
       "      <td>reflective</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>600</th>\n",
       "      <td>prototype</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>602</th>\n",
       "      <td>direction</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>603</th>\n",
       "      <td>shopping</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>604</th>\n",
       "      <td>bayesian</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>608</th>\n",
       "      <td>consultant</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>609</th>\n",
       "      <td>single</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>611</th>\n",
       "      <td>ongoing</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>613</th>\n",
       "      <td>investigating</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>614</th>\n",
       "      <td>learningled</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>615</th>\n",
       "      <td>analystscientist</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>616</th>\n",
       "      <td>middle</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>622</th>\n",
       "      <td>same</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>623</th>\n",
       "      <td>inquiry</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>624</th>\n",
       "      <td>document</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>626</th>\n",
       "      <td>finish</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>627</th>\n",
       "      <td>faculty</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>631</th>\n",
       "      <td>validate</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>634</th>\n",
       "      <td>largely</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>635</th>\n",
       "      <td>toproduce</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>636</th>\n",
       "      <td>components</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>637</th>\n",
       "      <td>coordinate</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1443</th>\n",
       "      <td>validation</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1444 rows Ã— 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                  word  count\n",
       "517                and    345\n",
       "443               data    247\n",
       "747                 to    202\n",
       "278                the    195\n",
       "677                 of    177\n",
       "819                  a    162\n",
       "251                 in    126\n",
       "707               with     97\n",
       "309                for     91\n",
       "247                 is     91\n",
       "771         scientists     70\n",
       "213          analytics     59\n",
       "80             machine     58\n",
       "1338              will     56\n",
       "591           learning     55\n",
       "372               team     48\n",
       "780         experience     47\n",
       "827          scientist     46\n",
       "719                 as     45\n",
       "1334                an     40\n",
       "749             health     40\n",
       "683                 or     40\n",
       "1214               our     38\n",
       "855           research     37\n",
       "378                 be     37\n",
       "481            looking     35\n",
       "674                 on     33\n",
       "772             public     33\n",
       "69                work     31\n",
       "935                are     31\n",
       "1161              this     30\n",
       "507               that     27\n",
       "795            company     26\n",
       "798            science     25\n",
       "728                you     25\n",
       "998           analysis     25\n",
       "1403          software     24\n",
       "1237             their     24\n",
       "456        statistical     24\n",
       "1276         knowledge     23\n",
       "1153              from     23\n",
       "328           clinical     22\n",
       "1054                by     22\n",
       "981          engineers     21\n",
       "351                sql     19\n",
       "1029           methods     19\n",
       "1017               big     19\n",
       "296           advanced     19\n",
       "520                san     18\n",
       "542             senior     18\n",
       "720                 at     18\n",
       "1247              have     18\n",
       "420            growing     18\n",
       "222                 we     17\n",
       "1291        predictive     17\n",
       "185            medical     17\n",
       "12                risk     17\n",
       "514                  r     16\n",
       "669         scientific     16\n",
       "453              years     16\n",
       "67                join     16\n",
       "123         laboratory     16\n",
       "407            working     15\n",
       "160            project     15\n",
       "506             mining     15\n",
       "88          algorithms     15\n",
       "1438         francisco     14\n",
       "1435             other     14\n",
       "216            subject     14\n",
       "369              level     14\n",
       "697               area     13\n",
       "1132            degree     13\n",
       "434            product     13\n",
       "348         developers     12\n",
       "658              using     12\n",
       "1064        statistics     12\n",
       "988        development     12\n",
       "1319          relevant     12\n",
       "1233           quality     12\n",
       "717               deep     12\n",
       "1259               who     12\n",
       "436        information     12\n",
       "226           modeling     12\n",
       "1254        techniques     11\n",
       "1246         providing     11\n",
       "899        experienced     11\n",
       "1145            manage     11\n",
       "826            mission     11\n",
       "523                sas     11\n",
       "430       requirements     11\n",
       "146            primary     11\n",
       "490               care     10\n",
       "497                one     10\n",
       "1208        university     10\n",
       "1066              fast     10\n",
       "1128            access     10\n",
       "306             people     10\n",
       "1201            python     10\n",
       "277       quantitative     10\n",
       "548               only      9\n",
       "...                ...    ...\n",
       "567    representatives      1\n",
       "568         boundaries      1\n",
       "573             screen      1\n",
       "575           uptodate      1\n",
       "581           contract      1\n",
       "582         nephrology      1\n",
       "529               take      1\n",
       "526         consortium      1\n",
       "525         conversion      1\n",
       "524                any      1\n",
       "473               term      1\n",
       "474                 ed      1\n",
       "476         challenges      1\n",
       "477               year      1\n",
       "478          obsession      1\n",
       "480              space      1\n",
       "485             theory      1\n",
       "486         diagnostic      1\n",
       "488         california      1\n",
       "489                ord      1\n",
       "491           training      1\n",
       "492           language      1\n",
       "494               turn      1\n",
       "495              first      1\n",
       "496             coming      1\n",
       "498               long      1\n",
       "499           directly      1\n",
       "500     methodological      1\n",
       "504              white      1\n",
       "508         accurately      1\n",
       "509        specialists      1\n",
       "513           scraping      1\n",
       "515          proactive      1\n",
       "516            stateof      1\n",
       "518          gathering      1\n",
       "521             briefs      1\n",
       "522          crossover      1\n",
       "585          residency      1\n",
       "586             traded      1\n",
       "587             cancer      1\n",
       "644        improvement      1\n",
       "653             papers      1\n",
       "655              early      1\n",
       "656             eihaas      1\n",
       "659            fortune      1\n",
       "663             either      1\n",
       "664        competition      1\n",
       "665         organizing      1\n",
       "666            confirm      1\n",
       "667            bigdata      1\n",
       "675            central      1\n",
       "676            package      1\n",
       "679          acclimate      1\n",
       "680                acl      1\n",
       "682          testimony      1\n",
       "688            newtons      1\n",
       "689        involvement      1\n",
       "691      scientistdata      1\n",
       "692         elementary      1\n",
       "695        supervising      1\n",
       "696            prepare      1\n",
       "698              there      1\n",
       "699            hazards      1\n",
       "701            attends      1\n",
       "702         recommends      1\n",
       "703          trainings      1\n",
       "706            promote      1\n",
       "708             extend      1\n",
       "652           specimen      1\n",
       "642     spatiotemporal      1\n",
       "588             period      1\n",
       "640           valuable      1\n",
       "589           sampling      1\n",
       "590             grants      1\n",
       "592                poc      1\n",
       "593       specializing      1\n",
       "596            locally      1\n",
       "599         reflective      1\n",
       "600          prototype      1\n",
       "602          direction      1\n",
       "603           shopping      1\n",
       "604           bayesian      1\n",
       "608         consultant      1\n",
       "609             single      1\n",
       "611            ongoing      1\n",
       "613      investigating      1\n",
       "614        learningled      1\n",
       "615   analystscientist      1\n",
       "616             middle      1\n",
       "622               same      1\n",
       "623            inquiry      1\n",
       "624           document      1\n",
       "626             finish      1\n",
       "627            faculty      1\n",
       "631           validate      1\n",
       "634            largely      1\n",
       "635          toproduce      1\n",
       "636         components      1\n",
       "637         coordinate      1\n",
       "1443        validation      1\n",
       "\n",
       "[1444 rows x 2 columns]"
      ]
     },
     "execution_count": 468,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#creating a dataframe with the words from the summary and how frequent they are to identify what words may be associated with different types of jobs\n",
    "sum_words = [re.sub('[^A-Za-z]', '', x.lower()) for x in ' '.join(list(jobs_w_salary.summary)).split(' ') if re.sub('[^A-Za-z]', '', x.lower()) != '']\n",
    "from collections import Counter\n",
    "sum_word_counts = pd.DataFrame(Counter(sum_words).items(), columns = ['word', 'count']).sort_values('count', ascending=False)\n",
    "sum_word_counts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I don't see any words that stick out as being significantly different from what's found in the titles in terms of differentiating job types"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# creating a function that I can use to filter out many different types of jobs\n",
    "def word_filter(wordlist, title):\n",
    "    for word in wordlist:\n",
    "        if re.findall(word.lower(), title.lower()):\n",
    "            return 1\n",
    "    else:\n",
    "        return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 271,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda/envs/py27/lib/python2.7/site-packages/ipykernel/__main__.py:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  app.launch_new_instance()\n",
      "/anaconda/envs/py27/lib/python2.7/site-packages/ipykernel/__main__.py:6: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "/anaconda/envs/py27/lib/python2.7/site-packages/ipykernel/__main__.py:7: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "/anaconda/envs/py27/lib/python2.7/site-packages/ipykernel/__main__.py:10: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "/anaconda/envs/py27/lib/python2.7/site-packages/ipykernel/__main__.py:11: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "/anaconda/envs/py27/lib/python2.7/site-packages/ipykernel/__main__.py:12: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "/anaconda/envs/py27/lib/python2.7/site-packages/ipykernel/__main__.py:15: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n"
     ]
    }
   ],
   "source": [
    "# categorizing job titles that suggest a higher-level job\n",
    "high_level_words = ['senior', 'lead', 'manager', 'director', 'president', 'sr', 'vp', 'vice', 'chief', 'executive']\n",
    "jobs_w_salary['is_high_level'] = jobs_w_salary.title.apply(lambda x: word_filter(high_level_words, x))\n",
    "\n",
    "# Jobs like \"data scientist\" and \"data analyst\" may come with different income levels - want to categorize\n",
    "jobs_w_salary['analyst_in_name'] = jobs_w_salary.title.apply(lambda x: word_filter(['analyst'], x))\n",
    "jobs_w_salary['ds_in_name'] = jobs_w_salary.title.apply(lambda x: word_filter(['data scien'], x))\n",
    "\n",
    "# There are many jobs that include words like \"engineer\", \"developer\", \"technician\", and \"laboratory\" which seem like different types of jobs from other data science jobs\n",
    "jobs_w_salary['engineer_in_name'] = jobs_w_salary.title.apply(lambda x: word_filter(['engineer'], x))\n",
    "jobs_w_salary['dev_in_name'] = jobs_w_salary.title.apply(lambda x: word_filter(['developer'], x))\n",
    "jobs_w_salary['tech_in_name'] = jobs_w_salary.title.apply(lambda x: word_filter(['technician'], x))\n",
    "jobs_w_salary['lab_in_name'] = jobs_w_salary.title.apply(lambda x: word_filter(['laboratory'], x))\n",
    "\n",
    "# Since machine learning is a pretty advanced part of data science, I thought it might influence salary.\n",
    "jobs_w_salary['ml_in_name'] = jobs_w_salary.title.apply(lambda x: word_filter(['machine learning'], x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 295,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimization terminated successfully.\n",
      "         Current function value: 0.597796\n",
      "         Iterations 5\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<caption>Logit Regression Results</caption>\n",
       "<tr>\n",
       "  <th>Dep. Variable:</th>     <td>high_paid</td>    <th>  No. Observations:  </th>  <td>   303</td>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Model:</th>               <td>Logit</td>      <th>  Df Residuals:      </th>  <td>   299</td>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Method:</th>               <td>MLE</td>       <th>  Df Model:          </th>  <td>     3</td>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Date:</th>          <td>Sat, 19 Nov 2016</td> <th>  Pseudo R-squ.:     </th>  <td>0.1376</td>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Time:</th>              <td>19:10:14</td>     <th>  Log-Likelihood:    </th> <td> -181.13</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>converged:</th>           <td>True</td>       <th>  LL-Null:           </th> <td> -210.02</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th> </th>                      <td> </td>        <th>  LLR p-value:       </th> <td>1.752e-12</td>\n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "         <td></td>           <th>coef</th>     <th>std err</th>      <th>z</th>      <th>P>|z|</th> <th>[95.0% Conf. Int.]</th> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Intercept</th>      <td>   -1.8367</td> <td>    0.351</td> <td>   -5.227</td> <td> 0.000</td> <td>   -2.525    -1.148</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>is_high_level</th>  <td>    1.3864</td> <td>    0.298</td> <td>    4.658</td> <td> 0.000</td> <td>    0.803     1.970</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>expensive_city</th> <td>    1.3512</td> <td>    0.292</td> <td>    4.629</td> <td> 0.000</td> <td>    0.779     1.923</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>in_city</th>        <td>    0.6652</td> <td>    0.288</td> <td>    2.307</td> <td> 0.021</td> <td>    0.100     1.230</td>\n",
       "</tr>\n",
       "</table>"
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.summary.Summary'>\n",
       "\"\"\"\n",
       "                           Logit Regression Results                           \n",
       "==============================================================================\n",
       "Dep. Variable:              high_paid   No. Observations:                  303\n",
       "Model:                          Logit   Df Residuals:                      299\n",
       "Method:                           MLE   Df Model:                            3\n",
       "Date:                Sat, 19 Nov 2016   Pseudo R-squ.:                  0.1376\n",
       "Time:                        19:10:14   Log-Likelihood:                -181.13\n",
       "converged:                       True   LL-Null:                       -210.02\n",
       "                                        LLR p-value:                 1.752e-12\n",
       "==================================================================================\n",
       "                     coef    std err          z      P>|z|      [95.0% Conf. Int.]\n",
       "----------------------------------------------------------------------------------\n",
       "Intercept         -1.8367      0.351     -5.227      0.000        -2.525    -1.148\n",
       "is_high_level      1.3864      0.298      4.658      0.000         0.803     1.970\n",
       "expensive_city     1.3512      0.292      4.629      0.000         0.779     1.923\n",
       "in_city            0.6652      0.288      2.307      0.021         0.100     1.230\n",
       "==================================================================================\n",
       "\"\"\""
      ]
     },
     "execution_count": 295,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y, X = patsy.dmatrices('high_paid ~ is_high_level + expensive_city + in_city', data=jobs_w_salary)\n",
    "sm.Logit(y, X).fit().summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "High-level words do increase the odds of a job being high-paid; higher-level words are associated with a 335% increase in the odds of being a high-paid job."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 302,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda/envs/py27/lib/python2.7/site-packages/ipykernel/__main__.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  if __name__ == '__main__':\n"
     ]
    }
   ],
   "source": [
    "jobs_w_salary['lab_in_name'] = jobs_w_salary.title.apply(lambda x: word_filter(['laboratory'], x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 303,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "//anaconda/envs/py27/lib/python2.7/site-packages/statsmodels/base/model.py:466: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n",
      "  \"Check mle_retvals\", ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: Maximum number of iterations has been exceeded.\n",
      "         Current function value: 0.465869\n",
      "         Iterations: 35\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<caption>Logit Regression Results</caption>\n",
       "<tr>\n",
       "  <th>Dep. Variable:</th>     <td>high_paid</td>    <th>  No. Observations:  </th>  <td>   303</td>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Model:</th>               <td>Logit</td>      <th>  Df Residuals:      </th>  <td>   292</td>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Method:</th>               <td>MLE</td>       <th>  Df Model:          </th>  <td>    10</td>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Date:</th>          <td>Sat, 19 Nov 2016</td> <th>  Pseudo R-squ.:     </th>  <td>0.3279</td>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Time:</th>              <td>19:14:51</td>     <th>  Log-Likelihood:    </th> <td> -141.16</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>converged:</th>           <td>False</td>      <th>  LL-Null:           </th> <td> -210.02</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th> </th>                      <td> </td>        <th>  LLR p-value:       </th> <td>1.231e-24</td>\n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "          <td></td>            <th>coef</th>     <th>std err</th>      <th>z</th>      <th>P>|z|</th> <th>[95.0% Conf. Int.]</th> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Intercept</th>        <td>   -2.4228</td> <td>    0.453</td> <td>   -5.351</td> <td> 0.000</td> <td>   -3.310    -1.535</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>is_high_level</th>    <td>    1.3983</td> <td>    0.347</td> <td>    4.034</td> <td> 0.000</td> <td>    0.719     2.078</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>in_city</th>          <td>    0.8223</td> <td>    0.334</td> <td>    2.459</td> <td> 0.014</td> <td>    0.167     1.478</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>expensive_city</th>   <td>    1.5110</td> <td>    0.359</td> <td>    4.215</td> <td> 0.000</td> <td>    0.808     2.214</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>lab_in_name</th>      <td>  -25.5965</td> <td> 2.14e+05</td> <td>   -0.000</td> <td> 1.000</td> <td> -4.2e+05   4.2e+05</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>analyst_in_name</th>  <td>   -0.8245</td> <td>    0.373</td> <td>   -2.208</td> <td> 0.027</td> <td>   -1.556    -0.093</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>ds_in_name</th>       <td>    1.5923</td> <td>    0.381</td> <td>    4.178</td> <td> 0.000</td> <td>    0.845     2.339</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>engineer_in_name</th> <td>    0.8504</td> <td>    0.439</td> <td>    1.937</td> <td> 0.053</td> <td>   -0.010     1.711</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>dev_in_name</th>      <td>    0.2703</td> <td>    0.739</td> <td>    0.366</td> <td> 0.714</td> <td>   -1.177     1.718</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>tech_in_name</th>     <td>  -22.5831</td> <td> 3.29e+04</td> <td>   -0.001</td> <td> 0.999</td> <td>-6.46e+04  6.45e+04</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>ml_in_name</th>       <td>    3.1954</td> <td>    1.126</td> <td>    2.839</td> <td> 0.005</td> <td>    0.989     5.402</td>\n",
       "</tr>\n",
       "</table>"
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.summary.Summary'>\n",
       "\"\"\"\n",
       "                           Logit Regression Results                           \n",
       "==============================================================================\n",
       "Dep. Variable:              high_paid   No. Observations:                  303\n",
       "Model:                          Logit   Df Residuals:                      292\n",
       "Method:                           MLE   Df Model:                           10\n",
       "Date:                Sat, 19 Nov 2016   Pseudo R-squ.:                  0.3279\n",
       "Time:                        19:14:51   Log-Likelihood:                -141.16\n",
       "converged:                      False   LL-Null:                       -210.02\n",
       "                                        LLR p-value:                 1.231e-24\n",
       "====================================================================================\n",
       "                       coef    std err          z      P>|z|      [95.0% Conf. Int.]\n",
       "------------------------------------------------------------------------------------\n",
       "Intercept           -2.4228      0.453     -5.351      0.000        -3.310    -1.535\n",
       "is_high_level        1.3983      0.347      4.034      0.000         0.719     2.078\n",
       "in_city              0.8223      0.334      2.459      0.014         0.167     1.478\n",
       "expensive_city       1.5110      0.359      4.215      0.000         0.808     2.214\n",
       "lab_in_name        -25.5965   2.14e+05     -0.000      1.000      -4.2e+05   4.2e+05\n",
       "analyst_in_name     -0.8245      0.373     -2.208      0.027        -1.556    -0.093\n",
       "ds_in_name           1.5923      0.381      4.178      0.000         0.845     2.339\n",
       "engineer_in_name     0.8504      0.439      1.937      0.053        -0.010     1.711\n",
       "dev_in_name          0.2703      0.739      0.366      0.714        -1.177     1.718\n",
       "tech_in_name       -22.5831   3.29e+04     -0.001      0.999     -6.46e+04  6.45e+04\n",
       "ml_in_name           3.1954      1.126      2.839      0.005         0.989     5.402\n",
       "====================================================================================\n",
       "\"\"\""
      ]
     },
     "execution_count": 303,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y, X = patsy.dmatrices('high_paid ~ is_high_level + in_city + expensive_city + lab_in_name + analyst_in_name + ds_in_name + analyst_in_name + engineer_in_name + dev_in_name + tech_in_name + ml_in_name', data=jobs_w_salary)\n",
    "sm.Logit(y, X).fit().summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\"data science\" and \"machine learning\" in the name are definitely strongly associated with a higher-paid job and \"developer\" and \"technician\" and \"laboratory\" appear to definitely not be associated with income. I will take those two out of the model and then re-examine \"analyst\" and \"engineer\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 297,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimization terminated successfully.\n",
      "         Current function value: 0.484568\n",
      "         Iterations 7\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<caption>Logit Regression Results</caption>\n",
       "<tr>\n",
       "  <th>Dep. Variable:</th>     <td>high_paid</td>    <th>  No. Observations:  </th>  <td>   303</td>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Model:</th>               <td>Logit</td>      <th>  Df Residuals:      </th>  <td>   295</td>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Method:</th>               <td>MLE</td>       <th>  Df Model:          </th>  <td>     7</td>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Date:</th>          <td>Sat, 19 Nov 2016</td> <th>  Pseudo R-squ.:     </th>  <td>0.3009</td>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Time:</th>              <td>19:10:42</td>     <th>  Log-Likelihood:    </th> <td> -146.82</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>converged:</th>           <td>True</td>       <th>  LL-Null:           </th> <td> -210.02</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th> </th>                      <td> </td>        <th>  LLR p-value:       </th> <td>3.555e-24</td>\n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "          <td></td>            <th>coef</th>     <th>std err</th>      <th>z</th>      <th>P>|z|</th> <th>[95.0% Conf. Int.]</th> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Intercept</th>        <td>   -2.7042</td> <td>    0.437</td> <td>   -6.182</td> <td> 0.000</td> <td>   -3.561    -1.847</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>is_high_level</th>    <td>    1.3364</td> <td>    0.336</td> <td>    3.972</td> <td> 0.000</td> <td>    0.677     1.996</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>expensive_city</th>   <td>    1.6737</td> <td>    0.350</td> <td>    4.783</td> <td> 0.000</td> <td>    0.988     2.360</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>in_city</th>          <td>    0.8146</td> <td>    0.330</td> <td>    2.472</td> <td> 0.013</td> <td>    0.169     1.461</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>analyst_in_name</th>  <td>   -0.6663</td> <td>    0.363</td> <td>   -1.836</td> <td> 0.066</td> <td>   -1.378     0.045</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>ds_in_name</th>       <td>    1.7642</td> <td>    0.376</td> <td>    4.697</td> <td> 0.000</td> <td>    1.028     2.500</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>engineer_in_name</th> <td>    0.9845</td> <td>    0.432</td> <td>    2.280</td> <td> 0.023</td> <td>    0.138     1.831</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>ml_in_name</th>       <td>    3.3560</td> <td>    1.133</td> <td>    2.961</td> <td> 0.003</td> <td>    1.135     5.577</td>\n",
       "</tr>\n",
       "</table>"
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.summary.Summary'>\n",
       "\"\"\"\n",
       "                           Logit Regression Results                           \n",
       "==============================================================================\n",
       "Dep. Variable:              high_paid   No. Observations:                  303\n",
       "Model:                          Logit   Df Residuals:                      295\n",
       "Method:                           MLE   Df Model:                            7\n",
       "Date:                Sat, 19 Nov 2016   Pseudo R-squ.:                  0.3009\n",
       "Time:                        19:10:42   Log-Likelihood:                -146.82\n",
       "converged:                       True   LL-Null:                       -210.02\n",
       "                                        LLR p-value:                 3.555e-24\n",
       "====================================================================================\n",
       "                       coef    std err          z      P>|z|      [95.0% Conf. Int.]\n",
       "------------------------------------------------------------------------------------\n",
       "Intercept           -2.7042      0.437     -6.182      0.000        -3.561    -1.847\n",
       "is_high_level        1.3364      0.336      3.972      0.000         0.677     1.996\n",
       "expensive_city       1.6737      0.350      4.783      0.000         0.988     2.360\n",
       "in_city              0.8146      0.330      2.472      0.013         0.169     1.461\n",
       "analyst_in_name     -0.6663      0.363     -1.836      0.066        -1.378     0.045\n",
       "ds_in_name           1.7642      0.376      4.697      0.000         1.028     2.500\n",
       "engineer_in_name     0.9845      0.432      2.280      0.023         0.138     1.831\n",
       "ml_in_name           3.3560      1.133      2.961      0.003         1.135     5.577\n",
       "====================================================================================\n",
       "\"\"\""
      ]
     },
     "execution_count": 297,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y, X = patsy.dmatrices('high_paid ~ is_high_level + expensive_city + in_city + analyst_in_name + ds_in_name + engineer_in_name + ml_in_name', data=jobs_w_salary)\n",
    "sm.Logit(y, X).fit().summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Taking out \"technician\", \"laboratory\" and \"developer\"make it clearer that \"analyst\" is not a significant predictor of salary - it is probably too general a term to have predictive value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 304,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimization terminated successfully.\n",
      "         Current function value: 0.490295\n",
      "         Iterations 7\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<caption>Logit Regression Results</caption>\n",
       "<tr>\n",
       "  <th>Dep. Variable:</th>     <td>high_paid</td>    <th>  No. Observations:  </th>  <td>   303</td>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Model:</th>               <td>Logit</td>      <th>  Df Residuals:      </th>  <td>   296</td>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Method:</th>               <td>MLE</td>       <th>  Df Model:          </th>  <td>     6</td>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Date:</th>          <td>Sat, 19 Nov 2016</td> <th>  Pseudo R-squ.:     </th>  <td>0.2926</td>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Time:</th>              <td>19:25:38</td>     <th>  Log-Likelihood:    </th> <td> -148.56</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>converged:</th>           <td>True</td>       <th>  LL-Null:           </th> <td> -210.02</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th> </th>                      <td> </td>        <th>  LLR p-value:       </th> <td>3.958e-24</td>\n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "          <td></td>            <th>coef</th>     <th>std err</th>      <th>z</th>      <th>P>|z|</th> <th>[95.0% Conf. Int.]</th> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Intercept</th>        <td>   -2.8241</td> <td>    0.434</td> <td>   -6.509</td> <td> 0.000</td> <td>   -3.675    -1.974</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>is_high_level</th>    <td>    1.3144</td> <td>    0.334</td> <td>    3.941</td> <td> 0.000</td> <td>    0.661     1.968</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>expensive_city</th>   <td>    1.5838</td> <td>    0.346</td> <td>    4.583</td> <td> 0.000</td> <td>    0.906     2.261</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>in_city</th>          <td>    0.7253</td> <td>    0.323</td> <td>    2.248</td> <td> 0.025</td> <td>    0.093     1.358</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>ds_in_name</th>       <td>    1.9940</td> <td>    0.355</td> <td>    5.613</td> <td> 0.000</td> <td>    1.298     2.690</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>engineer_in_name</th> <td>    1.1588</td> <td>    0.418</td> <td>    2.771</td> <td> 0.006</td> <td>    0.339     1.979</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>ml_in_name</th>       <td>    3.4367</td> <td>    1.132</td> <td>    3.037</td> <td> 0.002</td> <td>    1.219     5.655</td>\n",
       "</tr>\n",
       "</table>"
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.summary.Summary'>\n",
       "\"\"\"\n",
       "                           Logit Regression Results                           \n",
       "==============================================================================\n",
       "Dep. Variable:              high_paid   No. Observations:                  303\n",
       "Model:                          Logit   Df Residuals:                      296\n",
       "Method:                           MLE   Df Model:                            6\n",
       "Date:                Sat, 19 Nov 2016   Pseudo R-squ.:                  0.2926\n",
       "Time:                        19:25:38   Log-Likelihood:                -148.56\n",
       "converged:                       True   LL-Null:                       -210.02\n",
       "                                        LLR p-value:                 3.958e-24\n",
       "====================================================================================\n",
       "                       coef    std err          z      P>|z|      [95.0% Conf. Int.]\n",
       "------------------------------------------------------------------------------------\n",
       "Intercept           -2.8241      0.434     -6.509      0.000        -3.675    -1.974\n",
       "is_high_level        1.3144      0.334      3.941      0.000         0.661     1.968\n",
       "expensive_city       1.5838      0.346      4.583      0.000         0.906     2.261\n",
       "in_city              0.7253      0.323      2.248      0.025         0.093     1.358\n",
       "ds_in_name           1.9940      0.355      5.613      0.000         1.298     2.690\n",
       "engineer_in_name     1.1588      0.418      2.771      0.006         0.339     1.979\n",
       "ml_in_name           3.4367      1.132      3.037      0.002         1.219     5.655\n",
       "====================================================================================\n",
       "\"\"\""
      ]
     },
     "execution_count": 304,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y, X = patsy.dmatrices('high_paid ~ is_high_level + expensive_city + in_city + ds_in_name + engineer_in_name + ml_in_name', data=jobs_w_salary)\n",
    "sm.Logit(y, X).fit().summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 299,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimization terminated successfully.\n",
      "         Current function value: 0.482938\n",
      "         Iterations 7\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<caption>Logit Regression Results</caption>\n",
       "<tr>\n",
       "  <th>Dep. Variable:</th>     <td>high_paid</td>    <th>  No. Observations:  </th>  <td>   303</td>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Model:</th>               <td>Logit</td>      <th>  Df Residuals:      </th>  <td>   290</td>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Method:</th>               <td>MLE</td>       <th>  Df Model:          </th>  <td>    12</td>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Date:</th>          <td>Sat, 19 Nov 2016</td> <th>  Pseudo R-squ.:     </th>  <td>0.3033</td>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Time:</th>              <td>19:11:31</td>     <th>  Log-Likelihood:    </th> <td> -146.33</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>converged:</th>           <td>True</td>       <th>  LL-Null:           </th> <td> -210.02</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th> </th>                      <td> </td>        <th>  LLR p-value:       </th> <td>2.066e-21</td>\n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "                       <td></td>                         <th>coef</th>     <th>std err</th>      <th>z</th>      <th>P>|z|</th> <th>[95.0% Conf. Int.]</th> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Intercept</th>                                  <td>   -2.7889</td> <td>    0.555</td> <td>   -5.020</td> <td> 0.000</td> <td>   -3.878    -1.700</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>time_since_posted[T.13-18 days ago]</th>        <td>   -0.1559</td> <td>    0.527</td> <td>   -0.296</td> <td> 0.767</td> <td>   -1.188     0.876</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>time_since_posted[T.19-24 days ago]</th>        <td>    0.4497</td> <td>    0.570</td> <td>    0.789</td> <td> 0.430</td> <td>   -0.667     1.566</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>time_since_posted[T.25-30 days ago]</th>        <td>   -1.1011</td> <td>    0.760</td> <td>   -1.450</td> <td> 0.147</td> <td>   -2.590     0.388</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>time_since_posted[T.7-12 days ago]</th>         <td>    0.1772</td> <td>    0.518</td> <td>    0.342</td> <td> 0.732</td> <td>   -0.838     1.192</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>time_since_posted[T.in the last day]</th>       <td>   -0.0527</td> <td>    0.851</td> <td>   -0.062</td> <td> 0.951</td> <td>   -1.721     1.616</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>time_since_posted[T.more than 30 days ago]</th> <td>   -0.1954</td> <td>    0.416</td> <td>   -0.470</td> <td> 0.638</td> <td>   -1.010     0.619</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>in_city</th>                                    <td>    0.7262</td> <td>    0.338</td> <td>    2.150</td> <td> 0.032</td> <td>    0.064     1.388</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>is_high_level</th>                              <td>    1.3014</td> <td>    0.343</td> <td>    3.795</td> <td> 0.000</td> <td>    0.629     1.974</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>expensive_city</th>                             <td>    1.6194</td> <td>    0.355</td> <td>    4.563</td> <td> 0.000</td> <td>    0.924     2.315</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>ds_in_name</th>                                 <td>    2.0164</td> <td>    0.363</td> <td>    5.558</td> <td> 0.000</td> <td>    1.305     2.728</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>engineer_in_name</th>                           <td>    1.2502</td> <td>    0.435</td> <td>    2.875</td> <td> 0.004</td> <td>    0.398     2.103</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>ml_in_name</th>                                 <td>    3.4504</td> <td>    1.151</td> <td>    2.997</td> <td> 0.003</td> <td>    1.194     5.707</td>\n",
       "</tr>\n",
       "</table>"
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.summary.Summary'>\n",
       "\"\"\"\n",
       "                           Logit Regression Results                           \n",
       "==============================================================================\n",
       "Dep. Variable:              high_paid   No. Observations:                  303\n",
       "Model:                          Logit   Df Residuals:                      290\n",
       "Method:                           MLE   Df Model:                           12\n",
       "Date:                Sat, 19 Nov 2016   Pseudo R-squ.:                  0.3033\n",
       "Time:                        19:11:31   Log-Likelihood:                -146.33\n",
       "converged:                       True   LL-Null:                       -210.02\n",
       "                                        LLR p-value:                 2.066e-21\n",
       "==============================================================================================================\n",
       "                                                 coef    std err          z      P>|z|      [95.0% Conf. Int.]\n",
       "--------------------------------------------------------------------------------------------------------------\n",
       "Intercept                                     -2.7889      0.555     -5.020      0.000        -3.878    -1.700\n",
       "time_since_posted[T.13-18 days ago]           -0.1559      0.527     -0.296      0.767        -1.188     0.876\n",
       "time_since_posted[T.19-24 days ago]            0.4497      0.570      0.789      0.430        -0.667     1.566\n",
       "time_since_posted[T.25-30 days ago]           -1.1011      0.760     -1.450      0.147        -2.590     0.388\n",
       "time_since_posted[T.7-12 days ago]             0.1772      0.518      0.342      0.732        -0.838     1.192\n",
       "time_since_posted[T.in the last day]          -0.0527      0.851     -0.062      0.951        -1.721     1.616\n",
       "time_since_posted[T.more than 30 days ago]    -0.1954      0.416     -0.470      0.638        -1.010     0.619\n",
       "in_city                                        0.7262      0.338      2.150      0.032         0.064     1.388\n",
       "is_high_level                                  1.3014      0.343      3.795      0.000         0.629     1.974\n",
       "expensive_city                                 1.6194      0.355      4.563      0.000         0.924     2.315\n",
       "ds_in_name                                     2.0164      0.363      5.558      0.000         1.305     2.728\n",
       "engineer_in_name                               1.2502      0.435      2.875      0.004         0.398     2.103\n",
       "ml_in_name                                     3.4504      1.151      2.997      0.003         1.194     5.707\n",
       "==============================================================================================================\n",
       "\"\"\""
      ]
     },
     "execution_count": 299,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# checking to see if Time since Posted adds anything to the model\n",
    "y, X = patsy.dmatrices('high_paid ~ time_since_posted + in_city + is_high_level + expensive_city + ds_in_name + engineer_in_name + ml_in_name', data=jobs_w_salary)\n",
    "sm.Logit(y, X).fit().summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It appears not to."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 300,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: Maximum number of iterations has been exceeded.\n",
      "         Current function value: 0.439433\n",
      "         Iterations: 35\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "//anaconda/envs/py27/lib/python2.7/site-packages/statsmodels/base/model.py:466: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n",
      "  \"Check mle_retvals\", ConvergenceWarning)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<caption>Logit Regression Results</caption>\n",
       "<tr>\n",
       "  <th>Dep. Variable:</th>     <td>high_paid</td>    <th>  No. Observations:  </th>  <td>   303</td>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Model:</th>               <td>Logit</td>      <th>  Df Residuals:      </th>  <td>   293</td>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Method:</th>               <td>MLE</td>       <th>  Df Model:          </th>  <td>     9</td>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Date:</th>          <td>Sat, 19 Nov 2016</td> <th>  Pseudo R-squ.:     </th>  <td>0.3660</td>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Time:</th>              <td>19:11:43</td>     <th>  Log-Likelihood:    </th> <td> -133.15</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>converged:</th>           <td>False</td>      <th>  LL-Null:           </th> <td> -210.02</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th> </th>                      <td> </td>        <th>  LLR p-value:       </th> <td>1.475e-28</td>\n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "           <td></td>              <th>coef</th>     <th>std err</th>      <th>z</th>      <th>P>|z|</th> <th>[95.0% Conf. Int.]</th> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Intercept</th>           <td>   -2.3713</td> <td>    0.515</td> <td>   -4.608</td> <td> 0.000</td> <td>   -3.380    -1.363</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>how_paid[T.monthly]</th> <td>  -27.0540</td> <td> 1.76e+05</td> <td>   -0.000</td> <td> 1.000</td> <td>-3.45e+05  3.45e+05</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>how_paid[T.weekly]</th>  <td>  -23.5123</td> <td> 2.49e+04</td> <td>   -0.001</td> <td> 0.999</td> <td>-4.89e+04  4.88e+04</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>how_paid[T.yearly]</th>  <td>    0.0421</td> <td>    0.417</td> <td>    0.101</td> <td> 0.920</td> <td>   -0.776     0.860</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>is_high_level</th>       <td>    1.4967</td> <td>    0.372</td> <td>    4.020</td> <td> 0.000</td> <td>    0.767     2.226</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>expensive_city</th>      <td>    0.9643</td> <td>    0.378</td> <td>    2.554</td> <td> 0.011</td> <td>    0.224     1.704</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>in_city</th>             <td>    0.9816</td> <td>    0.334</td> <td>    2.935</td> <td> 0.003</td> <td>    0.326     1.637</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>ds_in_name</th>          <td>    1.9099</td> <td>    0.377</td> <td>    5.068</td> <td> 0.000</td> <td>    1.171     2.649</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>engineer_in_name</th>    <td>    1.3327</td> <td>    0.483</td> <td>    2.760</td> <td> 0.006</td> <td>    0.386     2.279</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>ml_in_name</th>          <td>    2.9460</td> <td>    1.133</td> <td>    2.600</td> <td> 0.009</td> <td>    0.725     5.167</td>\n",
       "</tr>\n",
       "</table>"
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.summary.Summary'>\n",
       "\"\"\"\n",
       "                           Logit Regression Results                           \n",
       "==============================================================================\n",
       "Dep. Variable:              high_paid   No. Observations:                  303\n",
       "Model:                          Logit   Df Residuals:                      293\n",
       "Method:                           MLE   Df Model:                            9\n",
       "Date:                Sat, 19 Nov 2016   Pseudo R-squ.:                  0.3660\n",
       "Time:                        19:11:43   Log-Likelihood:                -133.15\n",
       "converged:                      False   LL-Null:                       -210.02\n",
       "                                        LLR p-value:                 1.475e-28\n",
       "=======================================================================================\n",
       "                          coef    std err          z      P>|z|      [95.0% Conf. Int.]\n",
       "---------------------------------------------------------------------------------------\n",
       "Intercept              -2.3713      0.515     -4.608      0.000        -3.380    -1.363\n",
       "how_paid[T.monthly]   -27.0540   1.76e+05     -0.000      1.000     -3.45e+05  3.45e+05\n",
       "how_paid[T.weekly]    -23.5123   2.49e+04     -0.001      0.999     -4.89e+04  4.88e+04\n",
       "how_paid[T.yearly]      0.0421      0.417      0.101      0.920        -0.776     0.860\n",
       "is_high_level           1.4967      0.372      4.020      0.000         0.767     2.226\n",
       "expensive_city          0.9643      0.378      2.554      0.011         0.224     1.704\n",
       "in_city                 0.9816      0.334      2.935      0.003         0.326     1.637\n",
       "ds_in_name              1.9099      0.377      5.068      0.000         1.171     2.649\n",
       "engineer_in_name        1.3327      0.483      2.760      0.006         0.386     2.279\n",
       "ml_in_name              2.9460      1.133      2.600      0.009         0.725     5.167\n",
       "=======================================================================================\n",
       "\"\"\""
      ]
     },
     "execution_count": 300,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# checking to see if how paid adds anything to the model\n",
    "y, X = patsy.dmatrices('high_paid ~ how_paid + is_high_level + expensive_city + in_city +ds_in_name + engineer_in_name + ml_in_name', data=jobs_w_salary)\n",
    "sm.Logit(y, X).fit().summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It also appears not to be statistically significant, although interestingly the pseudo-r2 did go up significantly when I added this to the model..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 306,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# To use number of reviews, I will have to fill NaN with 0 reviews, since ones with 0 reviews would just show up as Nans\n",
    "jobs_w_salary.number_reviews.fillna(0, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 309,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimization terminated successfully.\n",
      "         Current function value: 0.482100\n",
      "         Iterations 7\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<caption>Logit Regression Results</caption>\n",
       "<tr>\n",
       "  <th>Dep. Variable:</th>     <td>high_paid</td>    <th>  No. Observations:  </th>  <td>   303</td>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Model:</th>               <td>Logit</td>      <th>  Df Residuals:      </th>  <td>   295</td>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Method:</th>               <td>MLE</td>       <th>  Df Model:          </th>  <td>     7</td>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Date:</th>          <td>Sat, 19 Nov 2016</td> <th>  Pseudo R-squ.:     </th>  <td>0.3045</td>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Time:</th>              <td>19:35:20</td>     <th>  Log-Likelihood:    </th> <td> -146.08</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>converged:</th>           <td>True</td>       <th>  LL-Null:           </th> <td> -210.02</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th> </th>                      <td> </td>        <th>  LLR p-value:       </th> <td>1.733e-24</td>\n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "          <td></td>            <th>coef</th>     <th>std err</th>      <th>z</th>      <th>P>|z|</th> <th>[95.0% Conf. Int.]</th> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Intercept</th>        <td>   -2.6614</td> <td>    0.438</td> <td>   -6.075</td> <td> 0.000</td> <td>   -3.520    -1.803</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>number_reviews</th>   <td>   -0.0016</td> <td>    0.001</td> <td>   -2.117</td> <td> 0.034</td> <td>   -0.003    -0.000</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>is_high_level</th>    <td>    1.3879</td> <td>    0.341</td> <td>    4.069</td> <td> 0.000</td> <td>    0.719     2.056</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>expensive_city</th>   <td>    1.4387</td> <td>    0.353</td> <td>    4.078</td> <td> 0.000</td> <td>    0.747     2.130</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>in_city</th>          <td>    0.8321</td> <td>    0.328</td> <td>    2.533</td> <td> 0.011</td> <td>    0.188     1.476</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>ds_in_name</th>       <td>    1.9076</td> <td>    0.359</td> <td>    5.307</td> <td> 0.000</td> <td>    1.203     2.612</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>engineer_in_name</th> <td>    1.1781</td> <td>    0.430</td> <td>    2.739</td> <td> 0.006</td> <td>    0.335     2.021</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>ml_in_name</th>       <td>    3.7046</td> <td>    1.196</td> <td>    3.097</td> <td> 0.002</td> <td>    1.360     6.049</td>\n",
       "</tr>\n",
       "</table>"
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.summary.Summary'>\n",
       "\"\"\"\n",
       "                           Logit Regression Results                           \n",
       "==============================================================================\n",
       "Dep. Variable:              high_paid   No. Observations:                  303\n",
       "Model:                          Logit   Df Residuals:                      295\n",
       "Method:                           MLE   Df Model:                            7\n",
       "Date:                Sat, 19 Nov 2016   Pseudo R-squ.:                  0.3045\n",
       "Time:                        19:35:20   Log-Likelihood:                -146.08\n",
       "converged:                       True   LL-Null:                       -210.02\n",
       "                                        LLR p-value:                 1.733e-24\n",
       "====================================================================================\n",
       "                       coef    std err          z      P>|z|      [95.0% Conf. Int.]\n",
       "------------------------------------------------------------------------------------\n",
       "Intercept           -2.6614      0.438     -6.075      0.000        -3.520    -1.803\n",
       "number_reviews      -0.0016      0.001     -2.117      0.034        -0.003    -0.000\n",
       "is_high_level        1.3879      0.341      4.069      0.000         0.719     2.056\n",
       "expensive_city       1.4387      0.353      4.078      0.000         0.747     2.130\n",
       "in_city              0.8321      0.328      2.533      0.011         0.188     1.476\n",
       "ds_in_name           1.9076      0.359      5.307      0.000         1.203     2.612\n",
       "engineer_in_name     1.1781      0.430      2.739      0.006         0.335     2.021\n",
       "ml_in_name           3.7046      1.196      3.097      0.002         1.360     6.049\n",
       "====================================================================================\n",
       "\"\"\""
      ]
     },
     "execution_count": 309,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# checking if number of reviews adds anything to the model. \n",
    "y, X = patsy.dmatrices('high_paid ~ number_reviews + is_high_level + expensive_city + in_city +ds_in_name + engineer_in_name + ml_in_name', data=jobs_w_salary)\n",
    "sm.Logit(y, X).fit().summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Number of reviews does appear to add to the model based on p-value, although the coefficient is small and it doesn't affect the pseudo-r2 much. However, if you consider that the coefficient is based on an increase in 1 review, that small coefficient can make a big difference. For instance, the odds are only reduced by 0.16% with each review, with an increase in 100 reviews that's an increase of 17%, and many employers do have hundreds of reviews. I will keep it in the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 310,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimization terminated successfully.\n",
      "         Current function value: 0.546780\n",
      "         Iterations 5\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<caption>Logit Regression Results</caption>\n",
       "<tr>\n",
       "  <th>Dep. Variable:</th>     <td>high_paid</td>    <th>  No. Observations:  </th>  <td>   147</td>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Model:</th>               <td>Logit</td>      <th>  Df Residuals:      </th>  <td>   145</td>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Method:</th>               <td>MLE</td>       <th>  Df Model:          </th>  <td>     1</td>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Date:</th>          <td>Sat, 19 Nov 2016</td> <th>  Pseudo R-squ.:     </th>  <td>0.1585</td>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Time:</th>              <td>19:44:08</td>     <th>  Log-Likelihood:    </th> <td> -80.377</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>converged:</th>           <td>True</td>       <th>  LL-Null:           </th> <td> -95.511</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th> </th>                      <td> </td>        <th>  LLR p-value:       </th> <td>3.763e-08</td>\n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "       <td></td>          <th>coef</th>     <th>std err</th>      <th>z</th>      <th>P>|z|</th> <th>[95.0% Conf. Int.]</th> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Intercept</th>   <td>    8.2309</td> <td>    1.715</td> <td>    4.800</td> <td> 0.000</td> <td>    4.870    11.591</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>star_rating</th> <td>   -2.2194</td> <td>    0.432</td> <td>   -5.139</td> <td> 0.000</td> <td>   -3.066    -1.373</td>\n",
       "</tr>\n",
       "</table>"
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.summary.Summary'>\n",
       "\"\"\"\n",
       "                           Logit Regression Results                           \n",
       "==============================================================================\n",
       "Dep. Variable:              high_paid   No. Observations:                  147\n",
       "Model:                          Logit   Df Residuals:                      145\n",
       "Method:                           MLE   Df Model:                            1\n",
       "Date:                Sat, 19 Nov 2016   Pseudo R-squ.:                  0.1585\n",
       "Time:                        19:44:08   Log-Likelihood:                -80.377\n",
       "converged:                       True   LL-Null:                       -95.511\n",
       "                                        LLR p-value:                 3.763e-08\n",
       "===============================================================================\n",
       "                  coef    std err          z      P>|z|      [95.0% Conf. Int.]\n",
       "-------------------------------------------------------------------------------\n",
       "Intercept       8.2309      1.715      4.800      0.000         4.870    11.591\n",
       "star_rating    -2.2194      0.432     -5.139      0.000        -3.066    -1.373\n",
       "===============================================================================\n",
       "\"\"\""
      ]
     },
     "execution_count": 310,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Checking if star reviews make a different by themselves - if so, I will have to consider how I can include it in my model without losing too much data (many don't have a star rating). \n",
    "y, X = patsy.dmatrices('high_paid ~ star_rating', data=jobs_w_salary)\n",
    "sm.Logit(y, X).fit().summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Star rating does seem to make a huge difference! (In a negative direction). I will categorize the data so I will be able to keep all the data and have one category of \"no reviews\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 249,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nan\n",
      "no_rating\n",
      "4.3\n",
      "high_rating\n",
      "3.25\n",
      "low_rating\n"
     ]
    }
   ],
   "source": [
    "# creating a function that will recode into 'high', 'low', and 'no' ratings \n",
    "# choosing 4 as the cut-off for high vs low because about half the data is above, half below, and there's a big gap between the two groups\n",
    "def recode_star_rating(rating):\n",
    "    if np.isnan(rating) == False:\n",
    "        if rating >=4:\n",
    "            return 'high_rating'\n",
    "        else:\n",
    "            return 'low_rating'\n",
    "    else:\n",
    "        return 'no_rating'\n",
    "# test\n",
    "print jobs_w_salary.star_rating.iloc[0]\n",
    "print recode_star_rating(jobs_w_salary.star_rating.iloc[0])\n",
    "print jobs_w_salary.star_rating.iloc[10]\n",
    "print recode_star_rating(jobs_w_salary.star_rating.iloc[10])\n",
    "print jobs_w_salary.star_rating.iloc[19]\n",
    "print recode_star_rating(jobs_w_salary.star_rating.iloc[19])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 250,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda/envs/py27/lib/python2.7/site-packages/ipykernel/__main__.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  if __name__ == '__main__':\n"
     ]
    }
   ],
   "source": [
    "# applying the function\n",
    "jobs_w_salary['rating_cat'] = jobs_w_salary.star_rating.apply(recode_star_rating)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 311,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimization terminated successfully.\n",
      "         Current function value: 0.539150\n",
      "         Iterations 5\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<caption>Logit Regression Results</caption>\n",
       "<tr>\n",
       "  <th>Dep. Variable:</th>     <td>high_paid</td>    <th>  No. Observations:  </th>  <td>   147</td>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Model:</th>               <td>Logit</td>      <th>  Df Residuals:      </th>  <td>   145</td>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Method:</th>               <td>MLE</td>       <th>  Df Model:          </th>  <td>     1</td>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Date:</th>          <td>Sun, 20 Nov 2016</td> <th>  Pseudo R-squ.:     </th>  <td>0.1702</td>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Time:</th>              <td>10:40:01</td>     <th>  Log-Likelihood:    </th> <td> -79.255</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>converged:</th>           <td>True</td>       <th>  LL-Null:           </th> <td> -95.511</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th> </th>                      <td> </td>        <th>  LLR p-value:       </th> <td>1.185e-08</td>\n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "              <td></td>                <th>coef</th>     <th>std err</th>      <th>z</th>      <th>P>|z|</th> <th>[95.0% Conf. Int.]</th> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Intercept</th>                <td>   -1.4975</td> <td>    0.268</td> <td>   -5.582</td> <td> 0.000</td> <td>   -2.023    -0.972</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>rating_cat[T.low_rating]</th> <td>    2.1084</td> <td>    0.391</td> <td>    5.387</td> <td> 0.000</td> <td>    1.341     2.876</td>\n",
       "</tr>\n",
       "</table>"
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.summary.Summary'>\n",
       "\"\"\"\n",
       "                           Logit Regression Results                           \n",
       "==============================================================================\n",
       "Dep. Variable:              high_paid   No. Observations:                  147\n",
       "Model:                          Logit   Df Residuals:                      145\n",
       "Method:                           MLE   Df Model:                            1\n",
       "Date:                Sun, 20 Nov 2016   Pseudo R-squ.:                  0.1702\n",
       "Time:                        10:40:01   Log-Likelihood:                -79.255\n",
       "converged:                       True   LL-Null:                       -95.511\n",
       "                                        LLR p-value:                 1.185e-08\n",
       "============================================================================================\n",
       "                               coef    std err          z      P>|z|      [95.0% Conf. Int.]\n",
       "--------------------------------------------------------------------------------------------\n",
       "Intercept                   -1.4975      0.268     -5.582      0.000        -2.023    -0.972\n",
       "rating_cat[T.low_rating]     2.1084      0.391      5.387      0.000         1.341     2.876\n",
       "============================================================================================\n",
       "\"\"\""
      ]
     },
     "execution_count": 311,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# checking to see if too much is lost when categorizing the data (using only data with star ratings)\n",
    "y, X = patsy.dmatrices('high_paid ~ rating_cat', data=jobs_w_salary[jobs_w_salary.star_rating.notnull()])\n",
    "sm.Logit(y, X).fit().summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In fact, the pseudo-r2 is even better when it's a categorized variable!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 314,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimization terminated successfully.\n",
      "         Current function value: 0.599544\n",
      "         Iterations 5\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<caption>Logit Regression Results</caption>\n",
       "<tr>\n",
       "  <th>Dep. Variable:</th>     <td>high_paid</td>    <th>  No. Observations:  </th>  <td>   303</td>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Model:</th>               <td>Logit</td>      <th>  Df Residuals:      </th>  <td>   300</td>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Method:</th>               <td>MLE</td>       <th>  Df Model:          </th>  <td>     2</td>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Date:</th>          <td>Sun, 20 Nov 2016</td> <th>  Pseudo R-squ.:     </th>  <td>0.1350</td>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Time:</th>              <td>10:46:43</td>     <th>  Log-Likelihood:    </th> <td> -181.66</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>converged:</th>           <td>True</td>       <th>  LL-Null:           </th> <td> -210.02</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th> </th>                      <td> </td>        <th>  LLR p-value:       </th> <td>4.823e-13</td>\n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "              <td></td>                <th>coef</th>     <th>std err</th>      <th>z</th>      <th>P>|z|</th> <th>[95.0% Conf. Int.]</th> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Intercept</th>                <td>   -1.4975</td> <td>    0.268</td> <td>   -5.582</td> <td> 0.000</td> <td>   -2.023    -0.972</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>rating_cat[T.low_rating]</th> <td>    2.1084</td> <td>    0.391</td> <td>    5.387</td> <td> 0.000</td> <td>    1.341     2.876</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>rating_cat[T.no_rating]</th>  <td>    2.0496</td> <td>    0.316</td> <td>    6.494</td> <td> 0.000</td> <td>    1.431     2.668</td>\n",
       "</tr>\n",
       "</table>"
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.summary.Summary'>\n",
       "\"\"\"\n",
       "                           Logit Regression Results                           \n",
       "==============================================================================\n",
       "Dep. Variable:              high_paid   No. Observations:                  303\n",
       "Model:                          Logit   Df Residuals:                      300\n",
       "Method:                           MLE   Df Model:                            2\n",
       "Date:                Sun, 20 Nov 2016   Pseudo R-squ.:                  0.1350\n",
       "Time:                        10:46:43   Log-Likelihood:                -181.66\n",
       "converged:                       True   LL-Null:                       -210.02\n",
       "                                        LLR p-value:                 4.823e-13\n",
       "============================================================================================\n",
       "                               coef    std err          z      P>|z|      [95.0% Conf. Int.]\n",
       "--------------------------------------------------------------------------------------------\n",
       "Intercept                   -1.4975      0.268     -5.582      0.000        -2.023    -0.972\n",
       "rating_cat[T.low_rating]     2.1084      0.391      5.387      0.000         1.341     2.876\n",
       "rating_cat[T.no_rating]      2.0496      0.316      6.494      0.000         1.431     2.668\n",
       "============================================================================================\n",
       "\"\"\""
      ]
     },
     "execution_count": 314,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# One last check before I put it in the model to see if the \"no rating\" category is significant\n",
    "y, X = patsy.dmatrices('high_paid ~ rating_cat', data=jobs_w_salary)\n",
    "sm.Logit(y, X).fit().summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It is significant! I will add it to my model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 315,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimization terminated successfully.\n",
      "         Current function value: 0.440269\n",
      "         Iterations 7\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<caption>Logit Regression Results</caption>\n",
       "<tr>\n",
       "  <th>Dep. Variable:</th>     <td>high_paid</td>    <th>  No. Observations:  </th>  <td>   303</td>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Model:</th>               <td>Logit</td>      <th>  Df Residuals:      </th>  <td>   293</td>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Method:</th>               <td>MLE</td>       <th>  Df Model:          </th>  <td>     9</td>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Date:</th>          <td>Sun, 20 Nov 2016</td> <th>  Pseudo R-squ.:     </th>  <td>0.3648</td>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Time:</th>              <td>10:47:36</td>     <th>  Log-Likelihood:    </th> <td> -133.40</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>converged:</th>           <td>True</td>       <th>  LL-Null:           </th> <td> -210.02</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th> </th>                      <td> </td>        <th>  LLR p-value:       </th> <td>1.878e-28</td>\n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "              <td></td>                <th>coef</th>     <th>std err</th>      <th>z</th>      <th>P>|z|</th> <th>[95.0% Conf. Int.]</th> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Intercept</th>                <td>   -3.8878</td> <td>    0.539</td> <td>   -7.211</td> <td> 0.000</td> <td>   -4.945    -2.831</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>rating_cat[T.low_rating]</th> <td>    1.8380</td> <td>    0.485</td> <td>    3.788</td> <td> 0.000</td> <td>    0.887     2.789</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>rating_cat[T.no_rating]</th>  <td>    1.6938</td> <td>    0.388</td> <td>    4.365</td> <td> 0.000</td> <td>    0.933     2.454</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>number_reviews</th>           <td>   -0.0007</td> <td>    0.001</td> <td>   -0.927</td> <td> 0.354</td> <td>   -0.002     0.001</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>is_high_level</th>            <td>    1.4195</td> <td>    0.368</td> <td>    3.861</td> <td> 0.000</td> <td>    0.699     2.140</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>expensive_city</th>           <td>    1.3888</td> <td>    0.359</td> <td>    3.865</td> <td> 0.000</td> <td>    0.684     2.093</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>in_city</th>                  <td>    0.8862</td> <td>    0.340</td> <td>    2.610</td> <td> 0.009</td> <td>    0.221     1.552</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>ds_in_name</th>               <td>    1.6964</td> <td>    0.380</td> <td>    4.467</td> <td> 0.000</td> <td>    0.952     2.441</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>engineer_in_name</th>         <td>    1.0154</td> <td>    0.482</td> <td>    2.106</td> <td> 0.035</td> <td>    0.070     1.961</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>ml_in_name</th>               <td>    3.3930</td> <td>    1.183</td> <td>    2.867</td> <td> 0.004</td> <td>    1.074     5.712</td>\n",
       "</tr>\n",
       "</table>"
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.summary.Summary'>\n",
       "\"\"\"\n",
       "                           Logit Regression Results                           \n",
       "==============================================================================\n",
       "Dep. Variable:              high_paid   No. Observations:                  303\n",
       "Model:                          Logit   Df Residuals:                      293\n",
       "Method:                           MLE   Df Model:                            9\n",
       "Date:                Sun, 20 Nov 2016   Pseudo R-squ.:                  0.3648\n",
       "Time:                        10:47:36   Log-Likelihood:                -133.40\n",
       "converged:                       True   LL-Null:                       -210.02\n",
       "                                        LLR p-value:                 1.878e-28\n",
       "============================================================================================\n",
       "                               coef    std err          z      P>|z|      [95.0% Conf. Int.]\n",
       "--------------------------------------------------------------------------------------------\n",
       "Intercept                   -3.8878      0.539     -7.211      0.000        -4.945    -2.831\n",
       "rating_cat[T.low_rating]     1.8380      0.485      3.788      0.000         0.887     2.789\n",
       "rating_cat[T.no_rating]      1.6938      0.388      4.365      0.000         0.933     2.454\n",
       "number_reviews              -0.0007      0.001     -0.927      0.354        -0.002     0.001\n",
       "is_high_level                1.4195      0.368      3.861      0.000         0.699     2.140\n",
       "expensive_city               1.3888      0.359      3.865      0.000         0.684     2.093\n",
       "in_city                      0.8862      0.340      2.610      0.009         0.221     1.552\n",
       "ds_in_name                   1.6964      0.380      4.467      0.000         0.952     2.441\n",
       "engineer_in_name             1.0154      0.482      2.106      0.035         0.070     1.961\n",
       "ml_in_name                   3.3930      1.183      2.867      0.004         1.074     5.712\n",
       "============================================================================================\n",
       "\"\"\""
      ]
     },
     "execution_count": 315,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# adding star ratings category to model.\n",
    "y, X = patsy.dmatrices('high_paid ~ rating_cat + number_reviews + is_high_level + expensive_city + in_city +ds_in_name + engineer_in_name + ml_in_name', data=jobs_w_salary)\n",
    "sm.Logit(y, X).fit().summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This addition made \"number of reviews\" non-significant, which makes sense if you consider that all places with 0 reviews also have no star rating. I will remove it from my model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 317,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimization terminated successfully.\n",
      "         Current function value: 0.441690\n",
      "         Iterations 7\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<caption>Logit Regression Results</caption>\n",
       "<tr>\n",
       "  <th>Dep. Variable:</th>     <td>high_paid</td>    <th>  No. Observations:  </th>  <td>   303</td>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Model:</th>               <td>Logit</td>      <th>  Df Residuals:      </th>  <td>   294</td>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Method:</th>               <td>MLE</td>       <th>  Df Model:          </th>  <td>     8</td>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Date:</th>          <td>Sun, 20 Nov 2016</td> <th>  Pseudo R-squ.:     </th>  <td>0.3628</td>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Time:</th>              <td>10:58:26</td>     <th>  Log-Likelihood:    </th> <td> -133.83</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>converged:</th>           <td>True</td>       <th>  LL-Null:           </th> <td> -210.02</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th> </th>                      <td> </td>        <th>  LLR p-value:       </th> <td>6.250e-29</td>\n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "              <td></td>                <th>coef</th>     <th>std err</th>      <th>z</th>      <th>P>|z|</th> <th>[95.0% Conf. Int.]</th> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Intercept</th>                <td>   -3.9948</td> <td>    0.528</td> <td>   -7.571</td> <td> 0.000</td> <td>   -5.029    -2.961</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>rating_cat[T.low_rating]</th> <td>    1.8151</td> <td>    0.484</td> <td>    3.753</td> <td> 0.000</td> <td>    0.867     2.763</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>rating_cat[T.no_rating]</th>  <td>    1.8047</td> <td>    0.370</td> <td>    4.879</td> <td> 0.000</td> <td>    1.080     2.530</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>is_high_level</th>            <td>    1.3776</td> <td>    0.364</td> <td>    3.789</td> <td> 0.000</td> <td>    0.665     2.090</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>expensive_city</th>           <td>    1.4053</td> <td>    0.359</td> <td>    3.920</td> <td> 0.000</td> <td>    0.703     2.108</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>in_city</th>                  <td>    0.8603</td> <td>    0.338</td> <td>    2.545</td> <td> 0.011</td> <td>    0.198     1.523</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>ds_in_name</th>               <td>    1.7401</td> <td>    0.378</td> <td>    4.598</td> <td> 0.000</td> <td>    0.998     2.482</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>engineer_in_name</th>         <td>    1.0466</td> <td>    0.476</td> <td>    2.196</td> <td> 0.028</td> <td>    0.113     1.980</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>ml_in_name</th>               <td>    3.3398</td> <td>    1.188</td> <td>    2.811</td> <td> 0.005</td> <td>    1.011     5.669</td>\n",
       "</tr>\n",
       "</table>"
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.summary.Summary'>\n",
       "\"\"\"\n",
       "                           Logit Regression Results                           \n",
       "==============================================================================\n",
       "Dep. Variable:              high_paid   No. Observations:                  303\n",
       "Model:                          Logit   Df Residuals:                      294\n",
       "Method:                           MLE   Df Model:                            8\n",
       "Date:                Sun, 20 Nov 2016   Pseudo R-squ.:                  0.3628\n",
       "Time:                        10:58:26   Log-Likelihood:                -133.83\n",
       "converged:                       True   LL-Null:                       -210.02\n",
       "                                        LLR p-value:                 6.250e-29\n",
       "============================================================================================\n",
       "                               coef    std err          z      P>|z|      [95.0% Conf. Int.]\n",
       "--------------------------------------------------------------------------------------------\n",
       "Intercept                   -3.9948      0.528     -7.571      0.000        -5.029    -2.961\n",
       "rating_cat[T.low_rating]     1.8151      0.484      3.753      0.000         0.867     2.763\n",
       "rating_cat[T.no_rating]      1.8047      0.370      4.879      0.000         1.080     2.530\n",
       "is_high_level                1.3776      0.364      3.789      0.000         0.665     2.090\n",
       "expensive_city               1.4053      0.359      3.920      0.000         0.703     2.108\n",
       "in_city                      0.8603      0.338      2.545      0.011         0.198     1.523\n",
       "ds_in_name                   1.7401      0.378      4.598      0.000         0.998     2.482\n",
       "engineer_in_name             1.0466      0.476      2.196      0.028         0.113     1.980\n",
       "ml_in_name                   3.3398      1.188      2.811      0.005         1.011     5.669\n",
       "============================================================================================\n",
       "\"\"\""
      ]
     },
     "execution_count": 317,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# taking out the number_reviews category\n",
    "y, X = patsy.dmatrices('high_paid ~ rating_cat + is_high_level + expensive_city + in_city +ds_in_name + engineer_in_name + ml_in_name', data=jobs_w_salary)\n",
    "sm.Logit(y, X).fit().summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 327,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimization terminated successfully.\n",
      "         Current function value: 0.441307\n",
      "         Iterations 7\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<caption>Logit Regression Results</caption>\n",
       "<tr>\n",
       "  <th>Dep. Variable:</th>     <td>high_paid</td>    <th>  No. Observations:  </th>  <td>   303</td>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Model:</th>               <td>Logit</td>      <th>  Df Residuals:      </th>  <td>   293</td>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Method:</th>               <td>MLE</td>       <th>  Df Model:          </th>  <td>     9</td>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Date:</th>          <td>Sun, 20 Nov 2016</td> <th>  Pseudo R-squ.:     </th>  <td>0.3633</td>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Time:</th>              <td>11:03:33</td>     <th>  Log-Likelihood:    </th> <td> -133.72</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>converged:</th>           <td>True</td>       <th>  LL-Null:           </th> <td> -210.02</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th> </th>                      <td> </td>        <th>  LLR p-value:       </th> <td>2.536e-28</td>\n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "              <td></td>                <th>coef</th>     <th>std err</th>      <th>z</th>      <th>P>|z|</th> <th>[95.0% Conf. Int.]</th> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Intercept</th>                <td>   -3.9085</td> <td>    0.555</td> <td>   -7.041</td> <td> 0.000</td> <td>   -4.997    -2.820</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>rating_cat[T.low_rating]</th> <td>    1.8247</td> <td>    0.484</td> <td>    3.769</td> <td> 0.000</td> <td>    0.876     2.774</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>rating_cat[T.no_rating]</th>  <td>    1.8016</td> <td>    0.370</td> <td>    4.863</td> <td> 0.000</td> <td>    1.075     2.528</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>page</th>                     <td>   -0.0029</td> <td>    0.006</td> <td>   -0.481</td> <td> 0.631</td> <td>   -0.015     0.009</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>is_high_level</th>            <td>    1.4111</td> <td>    0.371</td> <td>    3.809</td> <td> 0.000</td> <td>    0.685     2.137</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>expensive_city</th>           <td>    1.4888</td> <td>    0.400</td> <td>    3.721</td> <td> 0.000</td> <td>    0.705     2.273</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>in_city</th>                  <td>    0.8358</td> <td>    0.342</td> <td>    2.447</td> <td> 0.014</td> <td>    0.166     1.505</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>ds_in_name</th>               <td>    1.6725</td> <td>    0.402</td> <td>    4.158</td> <td> 0.000</td> <td>    0.884     2.461</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>engineer_in_name</th>         <td>    1.0489</td> <td>    0.475</td> <td>    2.209</td> <td> 0.027</td> <td>    0.118     1.979</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>ml_in_name</th>               <td>    3.4308</td> <td>    1.218</td> <td>    2.816</td> <td> 0.005</td> <td>    1.043     5.819</td>\n",
       "</tr>\n",
       "</table>"
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.summary.Summary'>\n",
       "\"\"\"\n",
       "                           Logit Regression Results                           \n",
       "==============================================================================\n",
       "Dep. Variable:              high_paid   No. Observations:                  303\n",
       "Model:                          Logit   Df Residuals:                      293\n",
       "Method:                           MLE   Df Model:                            9\n",
       "Date:                Sun, 20 Nov 2016   Pseudo R-squ.:                  0.3633\n",
       "Time:                        11:03:33   Log-Likelihood:                -133.72\n",
       "converged:                       True   LL-Null:                       -210.02\n",
       "                                        LLR p-value:                 2.536e-28\n",
       "============================================================================================\n",
       "                               coef    std err          z      P>|z|      [95.0% Conf. Int.]\n",
       "--------------------------------------------------------------------------------------------\n",
       "Intercept                   -3.9085      0.555     -7.041      0.000        -4.997    -2.820\n",
       "rating_cat[T.low_rating]     1.8247      0.484      3.769      0.000         0.876     2.774\n",
       "rating_cat[T.no_rating]      1.8016      0.370      4.863      0.000         1.075     2.528\n",
       "page                        -0.0029      0.006     -0.481      0.631        -0.015     0.009\n",
       "is_high_level                1.4111      0.371      3.809      0.000         0.685     2.137\n",
       "expensive_city               1.4888      0.400      3.721      0.000         0.705     2.273\n",
       "in_city                      0.8358      0.342      2.447      0.014         0.166     1.505\n",
       "ds_in_name                   1.6725      0.402      4.158      0.000         0.884     2.461\n",
       "engineer_in_name             1.0489      0.475      2.209      0.027         0.118     1.979\n",
       "ml_in_name                   3.4308      1.218      2.816      0.005         1.043     5.819\n",
       "============================================================================================\n",
       "\"\"\""
      ]
     },
     "execution_count": 327,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# seeing if page number should go in the model.\n",
    "y, X = patsy.dmatrices('high_paid ~ page + rating_cat + is_high_level + expensive_city + in_city +ds_in_name + engineer_in_name + ml_in_name', data=jobs_w_salary)\n",
    "sm.Logit(y, X).fit().summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Page number is not significant"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 322,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    303\n",
       "Name: is_sponsored, dtype: int64"
      ]
     },
     "execution_count": 322,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "jobs_w_salary.is_sponsored.value_counts()\n",
    "# since there are on sponsored listings with salary info, I will not be able to consider that for my model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "My final model will be \"high_paid ~ rating_cat + is_high_level + expensive_city + in_city +ds_in_name + engineer_in_name + ml_in_name\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "focus": false,
    "id": "7ca5cfdd-958c-4199-aafa-3d3f6c5ba3c4"
   },
   "source": [
    "#### Rebuild this model with scikit-learn.\n",
    "- You can either create the dummy features manually or use the `dmatrix` function from `patsy`\n",
    "- Remember to scale the feature variables as well!\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 332,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import sklearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 485,
   "metadata": {
    "collapsed": false,
    "focus": false,
    "id": "c75a97f1-f30c-48b3-97cb-eaf7d525c734"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best C:  [ 2.5]\n",
      "Training model score on Test subset:  0.7\n"
     ]
    }
   ],
   "source": [
    "#fit \n",
    "\n",
    "X = patsy.dmatrix('~ rating_cat + is_high_level + expensive_city + in_city +ds_in_name + engineer_in_name + ml_in_name', jobs_w_salary)\n",
    "y = jobs_w_salary.high_paid.values\n",
    "\n",
    "X_train, X_test, y_train, y_test = sklearn.model_selection.train_test_split(X, y, test_size=0.33, random_state = 109)\n",
    "\n",
    "log_regCV = sklearn.linear_model.LogisticRegressionCV(Cs=[0.0001, 0.001, 0.01, 0.1, 0.5, 0.75, 1.0, 2.5, 5.0, 10.0, 100.0, 1000.0])\n",
    "log_regCV.fit(X_train, y_train)\n",
    "print 'best C: ', log_regCV.fit(X, y).C_\n",
    "print 'Training model score on Test subset: ', log_regCV.score(X_test, y_test)\n",
    "#note: I have no continuous features, so I have nothing to scale."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On this training set, the model accuracy is 70%, which is quite a bit better than the baseline of 50%."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "focus": false,
    "id": "1e6c6902-2b4a-49f0-b4c7-935a26577d22"
   },
   "source": [
    "#### Use cross-validation in scikit-learn to evaluate the model above. \n",
    "- Evaluate the accuracy, AUC, precision and recall of the model. \n",
    "- Discuss the differences and explain when you want a high-recall or a high-precision model in this scenario."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 484,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cross-val scores:  [ 0.68627451  0.75247525  0.71      ]\n",
      "mean cross-val:  0.71624991911\n"
     ]
    }
   ],
   "source": [
    "# looking at cross-validated scores\n",
    "print 'cross-val scores: ', sklearn.model_selection.cross_val_score(log_regCV, X, y, cv=3)\n",
    "print 'mean cross-val: ', sklearn.model_selection.cross_val_score(log_regCV, X, y, cv=3).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 472,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>actual</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cross_val_pred</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>114</td>\n",
       "      <td>48</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>38</td>\n",
       "      <td>103</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "actual            0    1\n",
       "cross_val_pred          \n",
       "0               114   48\n",
       "1                38  103"
      ]
     },
     "execution_count": 472,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#creating confusion matrix from cross-validated predictions.\n",
    "y_pred = sklearn.model_selection.cross_val_predict(log_regCV, X, y, cv=3)\n",
    "\n",
    "actual_vs_cross_val_pred = pd.DataFrame([y_pred, y]).transpose()\n",
    "actual_vs_cross_val_pred.columns = ['cross_val_pred', 'actual']\n",
    "pd.crosstab(actual_vs_cross_val_pred.cross_val_pred, actual_vs_cross_val_pred.actual)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 496,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cross_val_pred</th>\n",
       "      <th>actual</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>58</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>62</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>63</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>64</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>65</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>66</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>67</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>68</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>69</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>70</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>71</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>72</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>73</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>76</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>77</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>78</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>79</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>80</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>81</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>82</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>83</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>84</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>85</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>86</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>87</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>88</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>89</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>90</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>91</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>92</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>93</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>94</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>203</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>204</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>205</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>206</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>207</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>208</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>209</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>210</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>211</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>212</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>213</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>214</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>215</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>216</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>217</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>218</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>219</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>220</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>221</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>222</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>223</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>224</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>225</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>226</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>227</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>228</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>229</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>230</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>231</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>232</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>233</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>234</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>235</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>236</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>237</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>238</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>239</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>240</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>241</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>242</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>243</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>244</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>245</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>246</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>247</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>248</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>249</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>250</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>251</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>252</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>253</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>254</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>255</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>256</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>257</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>258</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>259</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>260</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>261</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>262</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>263</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>264</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>265</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>266</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>267</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>268</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>269</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>270</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>271</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>272</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>273</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>274</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>275</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>276</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>277</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>278</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>279</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>280</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>281</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>282</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>283</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>284</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>285</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>286</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>287</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>288</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>289</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>290</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>291</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>292</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>293</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>294</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>295</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>296</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>297</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>298</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>299</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>300</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>301</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>302</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>303 rows Ã— 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     cross_val_pred  actual\n",
       "0                 1       1\n",
       "1                 0       0\n",
       "2                 0       0\n",
       "3                 0       0\n",
       "4                 0       0\n",
       "5                 1       0\n",
       "6                 0       1\n",
       "7                 0       1\n",
       "8                 0       1\n",
       "9                 0       0\n",
       "10                0       0\n",
       "11                0       0\n",
       "12                0       0\n",
       "13                0       0\n",
       "14                0       1\n",
       "15                0       0\n",
       "16                0       1\n",
       "17                0       1\n",
       "18                1       1\n",
       "19                1       1\n",
       "20                0       1\n",
       "21                0       0\n",
       "22                1       1\n",
       "23                1       0\n",
       "24                0       0\n",
       "25                0       1\n",
       "26                0       0\n",
       "27                1       1\n",
       "28                1       0\n",
       "29                1       0\n",
       "30                0       0\n",
       "31                0       0\n",
       "32                1       1\n",
       "33                1       0\n",
       "34                1       1\n",
       "35                0       1\n",
       "36                0       1\n",
       "37                1       1\n",
       "38                0       0\n",
       "39                0       0\n",
       "40                1       1\n",
       "41                1       0\n",
       "42                0       0\n",
       "43                1       0\n",
       "44                1       0\n",
       "45                0       0\n",
       "46                0       1\n",
       "47                1       0\n",
       "48                1       0\n",
       "49                1       1\n",
       "50                0       0\n",
       "51                0       0\n",
       "52                0       0\n",
       "53                1       1\n",
       "54                0       0\n",
       "55                0       0\n",
       "56                1       0\n",
       "57                1       0\n",
       "58                1       0\n",
       "59                1       0\n",
       "60                1       1\n",
       "61                0       0\n",
       "62                1       1\n",
       "63                0       1\n",
       "64                1       1\n",
       "65                1       1\n",
       "66                1       1\n",
       "67                1       1\n",
       "68                1       1\n",
       "69                1       1\n",
       "70                1       1\n",
       "71                1       1\n",
       "72                1       1\n",
       "73                1       1\n",
       "74                1       1\n",
       "75                1       1\n",
       "76                1       1\n",
       "77                0       0\n",
       "78                1       0\n",
       "79                1       1\n",
       "80                1       1\n",
       "81                1       1\n",
       "82                1       1\n",
       "83                1       0\n",
       "84                1       1\n",
       "85                1       1\n",
       "86                0       0\n",
       "87                1       1\n",
       "88                0       0\n",
       "89                1       1\n",
       "90                0       0\n",
       "91                1       1\n",
       "92                0       0\n",
       "93                1       1\n",
       "94                1       0\n",
       "95                1       1\n",
       "96                1       0\n",
       "97                1       0\n",
       "98                1       0\n",
       "99                0       0\n",
       "..              ...     ...\n",
       "203               0       0\n",
       "204               1       0\n",
       "205               0       0\n",
       "206               0       1\n",
       "207               0       0\n",
       "208               0       0\n",
       "209               0       1\n",
       "210               1       1\n",
       "211               0       0\n",
       "212               0       1\n",
       "213               0       0\n",
       "214               1       1\n",
       "215               1       1\n",
       "216               0       1\n",
       "217               0       0\n",
       "218               0       0\n",
       "219               1       1\n",
       "220               0       0\n",
       "221               0       0\n",
       "222               0       0\n",
       "223               0       1\n",
       "224               0       0\n",
       "225               0       0\n",
       "226               0       0\n",
       "227               0       1\n",
       "228               0       0\n",
       "229               0       0\n",
       "230               0       0\n",
       "231               0       0\n",
       "232               0       0\n",
       "233               0       0\n",
       "234               0       0\n",
       "235               0       0\n",
       "236               0       0\n",
       "237               0       0\n",
       "238               0       0\n",
       "239               0       1\n",
       "240               0       0\n",
       "241               0       0\n",
       "242               0       1\n",
       "243               1       0\n",
       "244               1       1\n",
       "245               1       1\n",
       "246               0       1\n",
       "247               1       0\n",
       "248               0       0\n",
       "249               1       1\n",
       "250               1       1\n",
       "251               0       1\n",
       "252               0       1\n",
       "253               1       1\n",
       "254               0       0\n",
       "255               0       1\n",
       "256               1       1\n",
       "257               0       0\n",
       "258               1       1\n",
       "259               1       1\n",
       "260               0       1\n",
       "261               1       1\n",
       "262               0       1\n",
       "263               1       1\n",
       "264               1       1\n",
       "265               1       1\n",
       "266               1       1\n",
       "267               0       1\n",
       "268               1       1\n",
       "269               0       0\n",
       "270               0       0\n",
       "271               1       1\n",
       "272               0       1\n",
       "273               0       1\n",
       "274               0       1\n",
       "275               1       1\n",
       "276               1       0\n",
       "277               0       0\n",
       "278               1       0\n",
       "279               0       1\n",
       "280               0       0\n",
       "281               1       1\n",
       "282               1       1\n",
       "283               1       1\n",
       "284               1       1\n",
       "285               0       1\n",
       "286               1       1\n",
       "287               0       0\n",
       "288               0       0\n",
       "289               0       1\n",
       "290               0       0\n",
       "291               0       0\n",
       "292               0       0\n",
       "293               0       0\n",
       "294               0       0\n",
       "295               0       0\n",
       "296               1       1\n",
       "297               0       0\n",
       "298               0       1\n",
       "299               0       1\n",
       "300               0       0\n",
       "301               0       0\n",
       "302               0       0\n",
       "\n",
       "[303 rows x 2 columns]"
      ]
     },
     "execution_count": 496,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "actual_vs_cross_val_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 473,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy: 0.716171617162\n",
      "precision: 0.730496453901\n",
      "recall: 0.682119205298\n"
     ]
    }
   ],
   "source": [
    "print 'accuracy:', sklearn.metrics.accuracy_score(y, y_pred)\n",
    "print 'precision:', sklearn.metrics.precision_score(y, y_pred)\n",
    "print 'recall:', sklearn.metrics.recall_score(y, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 481,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AUC: 0.775397796818\n"
     ]
    }
   ],
   "source": [
    "y_score = log_regCV.decision_function(X_test)\n",
    "fpr, tpr, thresholds = sklearn.metrics.roc_curve(y_test, y_score)\n",
    "print 'AUC:', sklearn.metrics.auc(fpr, tpr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 475,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 476,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x269ed4410>"
      ]
     },
     "execution_count": 476,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAiAAAAGJCAYAAACzcoinAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\npwJEREREQqcCREREREKnAkRERERC9/8pTuXzJGmbzQAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x2677c2a10>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(fpr, tpr, label='AUC: {:.2}'.format(sklearn.metrics.auc(fpr, tpr)))\n",
    "plt.xlabel('FPR')\n",
    "plt.ylabel('TPR')\n",
    "plt.title('ROC Curve for Cross-Validated Model')\n",
    "plt.plot([0, 1], [0, 1], 'k--')\n",
    "plt.legend(loc='lower right')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "focus": false,
    "id": "4263b1c0-bfde-42bf-ab45-71c7cd798835"
   },
   "source": [
    "### Compare L1 and L2 regularization for this logistic regression model. What effect does this have on the coefficients learned?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 464,
   "metadata": {
    "collapsed": false,
    "focus": false,
    "id": "2e7d6a29-a515-468a-9953-9d73a0f81de0"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cross-val scores:  [ 0.67647059  0.73267327  0.8       ]\n",
      "mean score: 0.736381285187\n",
      "best c [ 2.5]\n"
     ]
    }
   ],
   "source": [
    "log_regL1 = sklearn.linear_model.LogisticRegressionCV(penalty = 'l1', solver='liblinear', Cs=[0.0001, 0.001, 0.01, 0.1, 0.5, 0.75, 1.0, 2.5, 5.0, 10.0, 100.0, 1000.0])\n",
    "print 'cross-val scores: ', sklearn.cross_validation.cross_val_score(log_regL1, X, y)\n",
    "print 'mean score:', sklearn.cross_validation.cross_val_score(log_regL1, X, y).mean()\n",
    "print 'best c', log_regL1.fit(X, y).C_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 486,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy: 0.73597359736\n",
      "precision: 0.748251748252\n",
      "recall: 0.708609271523\n"
     ]
    }
   ],
   "source": [
    "y_predL1 = sklearn.cross_validation.cross_val_predict(log_regL1, X, y)\n",
    "print 'accuracy:', sklearn.metrics.accuracy_score(y, y_predL1)\n",
    "print 'precision:', sklearn.metrics.precision_score(y, y_predL1)\n",
    "print 'recall:', sklearn.metrics.recall_score(y, y_predL1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 494,
   "metadata": {
    "collapsed": false,
    "focus": false,
    "id": "32d908a3-89d2-474c-a7f0-199bfae6da7e"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>*features</th>\n",
       "      <th>L1_model_coef</th>\n",
       "      <th>L2_model_coef</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Intercept</td>\n",
       "      <td>0.000057</td>\n",
       "      <td>-2.306868</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>rating_cat[T.low_rating]</td>\n",
       "      <td>1.599307</td>\n",
       "      <td>1.642488</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>rating_cat[T.no_rating]</td>\n",
       "      <td>1.647095</td>\n",
       "      <td>1.662423</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>is_high_level</td>\n",
       "      <td>1.273834</td>\n",
       "      <td>1.291438</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>expensive_city</td>\n",
       "      <td>1.286287</td>\n",
       "      <td>1.281481</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>in_city</td>\n",
       "      <td>0.782776</td>\n",
       "      <td>0.751067</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>ds_in_name</td>\n",
       "      <td>1.639942</td>\n",
       "      <td>1.664911</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>engineer_in_name</td>\n",
       "      <td>1.014526</td>\n",
       "      <td>0.958372</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>ml_in_name</td>\n",
       "      <td>2.318485</td>\n",
       "      <td>2.788317</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  *features  L1_model_coef  L2_model_coef\n",
       "0                 Intercept       0.000057      -2.306868\n",
       "1  rating_cat[T.low_rating]       1.599307       1.642488\n",
       "2   rating_cat[T.no_rating]       1.647095       1.662423\n",
       "3             is_high_level       1.273834       1.291438\n",
       "4            expensive_city       1.286287       1.281481\n",
       "5                   in_city       0.782776       0.751067\n",
       "6                ds_in_name       1.639942       1.664911\n",
       "7          engineer_in_name       1.014526       0.958372\n",
       "8                ml_in_name       2.318485       2.788317"
      ]
     },
     "execution_count": 494,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.DataFrame({'*features' : X.design_info.column_names, \n",
    "                   'L1_model_coef': log_regCV.coef_[0,:],\n",
    "                  'L2_model_coef': log_regL1.coef_[0,:]})\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The model using L1 regularization doesn't impact the coefficients of each variable much (though they are mostly lower), however it has a huge impact on the intercept! The intercept in the L2 model puts the baseline odds around 1:10, whereas the L1 model puts the baseline odds around 1:1. Compared to the un-penalized model, though, both are much more conservative."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 493,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>*scores</th>\n",
       "      <th>L1_model</th>\n",
       "      <th>L2_model</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>accuracy</td>\n",
       "      <td>0.735974</td>\n",
       "      <td>0.716172</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>precision</td>\n",
       "      <td>0.748252</td>\n",
       "      <td>0.730496</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>recall</td>\n",
       "      <td>0.708609</td>\n",
       "      <td>0.682119</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     *scores  L1_model  L2_model\n",
       "0   accuracy  0.735974  0.716172\n",
       "1  precision  0.748252  0.730496\n",
       "2     recall  0.708609  0.682119"
      ]
     },
     "execution_count": 493,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame({'*scores': ['accuracy', 'precision', 'recall'],\n",
    "             'L1_model': [sklearn.metrics.accuracy_score(y, y_predL1),sklearn.metrics.precision_score(y, y_predL1),sklearn.metrics.recall_score(y, y_predL1)],\n",
    "             'L2_model': [sklearn.metrics.accuracy_score(y, y_pred),sklearn.metrics.precision_score(y, y_pred),sklearn.metrics.recall_score(y, y_pred)]})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The L1 model has better cross-validated accuracy, precision, and recall."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "focus": true,
    "id": "82f16f60-6c8b-4376-b3ec-b8ec61a0cde7"
   },
   "source": [
    "#### Optional: Continue to incorporate other text features from the title or summary that you believe will predict the salary and examine their coefficients. Take ~100 scraped entries with salaries. Convert them to use with your model and predict the salary. Which entries have the highest predicted salaries?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "focus": false,
    "id": "3f242a55-4518-4c95-ae90-6888c68077d3"
   },
   "source": [
    "# Bonus Section: Use Count Vectorizer from scikit-learn to create features from the text summaries. \n",
    "- Examine using count or binary features in the model\n",
    "- Re-evaluate the logistic regression model using these. Does this improve the model performance? \n",
    "- What text features are most valuable? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 652,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>analysis</th>\n",
       "      <th>analytics</th>\n",
       "      <th>company</th>\n",
       "      <th>data</th>\n",
       "      <th>experience</th>\n",
       "      <th>health</th>\n",
       "      <th>learning</th>\n",
       "      <th>looking</th>\n",
       "      <th>machine</th>\n",
       "      <th>public</th>\n",
       "      <th>research</th>\n",
       "      <th>scientist</th>\n",
       "      <th>scientists</th>\n",
       "      <th>team</th>\n",
       "      <th>work</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   analysis  analytics  company  data  experience  health  learning  looking  \\\n",
       "0         0          0        0     3           0       0         0        0   \n",
       "1         0          0        0     0           0       2         0        0   \n",
       "2         0          0        0     0           0       2         0        0   \n",
       "3         0          0        0     0           0       0         0        0   \n",
       "4         0          0        0     1           1       0         0        0   \n",
       "\n",
       "   machine  public  research  scientist  scientists  team  work  \n",
       "0        0       0         0          1           0     0     0  \n",
       "1        0       2         0          0           0     0     0  \n",
       "2        0       2         0          0           0     0     0  \n",
       "3        0       0         0          0           1     1     0  \n",
       "4        0       0         0          0           0     0     0  "
      ]
     },
     "execution_count": 652,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "vectorizer = CountVectorizer(max_features=15,stop_words=\"english\")\n",
    "vectorizer.fit(jobs_w_salary.summary)\n",
    "\n",
    "vectorDF  = pd.DataFrame(vectorizer.transform(jobs_w_salary.summary).todense(),\n",
    "              columns=vectorizer.get_feature_names())\n",
    "vectorDF.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 653,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>analyst_tit</th>\n",
       "      <th>data_tit</th>\n",
       "      <th>developer_tit</th>\n",
       "      <th>engineer_tit</th>\n",
       "      <th>engineering_tit</th>\n",
       "      <th>lead_tit</th>\n",
       "      <th>learning_tit</th>\n",
       "      <th>machine_tit</th>\n",
       "      <th>manager_tit</th>\n",
       "      <th>quantitative_tit</th>\n",
       "      <th>research_tit</th>\n",
       "      <th>science_tit</th>\n",
       "      <th>scientist_tit</th>\n",
       "      <th>senior_tit</th>\n",
       "      <th>software_tit</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   analyst_tit  data_tit  developer_tit  engineer_tit  engineering_tit  \\\n",
       "0            0         2              0             0                0   \n",
       "1            0         0              0             0                0   \n",
       "2            0         0              0             0                0   \n",
       "3            0         0              0             0                0   \n",
       "4            0         1              0             0                0   \n",
       "\n",
       "   lead_tit  learning_tit  machine_tit  manager_tit  quantitative_tit  \\\n",
       "0         0             0            0            0                 0   \n",
       "1         0             0            0            0                 0   \n",
       "2         0             0            0            0                 0   \n",
       "3         0             0            0            0                 0   \n",
       "4         0             0            0            0                 0   \n",
       "\n",
       "   research_tit  science_tit  scientist_tit  senior_tit  software_tit  \n",
       "0             0            0              1           0             0  \n",
       "1             0            0              1           0             0  \n",
       "2             0            0              0           0             0  \n",
       "3             0            0              1           0             0  \n",
       "4             0            0              1           0             0  "
      ]
     },
     "execution_count": 653,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "vectorizer = CountVectorizer(max_features=15,stop_words=\"english\")\n",
    "vectorizer.fit(jobs_w_salary.title)\n",
    "\n",
    "col = [x + '_tit' for x in vectorizer.get_feature_names()]\n",
    "\n",
    "titlevectorDF  = pd.DataFrame(vectorizer.transform(jobs_w_salary.title).todense(),\n",
    "              columns=col)\n",
    "titlevectorDF.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 590,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_with_wordcounts = jobs_w_salary.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 609,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df_with_wordcounts = pd.concat([df_with_wordcounts.reset_index(), vectorDF], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 641,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df_with_wordcounts.columns = [            u'index',        u'Unnamed: 0',           u'company_name',\n",
    "          u'number_reviews',       u'search_city',       u'star_rating',\n",
    "                 u'summary',             u'title',           u'website',\n",
    "                u'how_paid',     u'annual_salary',      u'is_sponsored',\n",
    "       u'time_since_posted',           u'in_city',              u'page',\n",
    "               u'high_paid',     u'is_high_level',        u'ds_in_name',\n",
    "              u'ml_in_name',       u'lab_in_name',   u'analyst_in_name',\n",
    "        u'engineer_in_name',       u'dev_in_name',      u'tech_in_name',\n",
    "              u'rating_cat',    u'expensive_city',          u'analysis',\n",
    "               u'analytics',           u'company',              u'data',\n",
    "              u'experience',            u'health',          u'learning',\n",
    "                 u'looking',           u'machine',            u'public',\n",
    "                u'research',         u'scientist',        u'scientists',\n",
    "                    u'team',              u'work']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 654,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_with_wordcounts = pd.concat([df_with_wordcounts.reset_index(), titlevectorDF], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 655,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index([          u'level_0',             u'index',        u'Unnamed: 0',\n",
       "            u'company_name',    u'number_reviews',       u'search_city',\n",
       "             u'star_rating',           u'summary',             u'title',\n",
       "                 u'website',          u'how_paid',     u'annual_salary',\n",
       "            u'is_sponsored', u'time_since_posted',           u'in_city',\n",
       "                    u'page',         u'high_paid',     u'is_high_level',\n",
       "              u'ds_in_name',        u'ml_in_name',       u'lab_in_name',\n",
       "         u'analyst_in_name',  u'engineer_in_name',       u'dev_in_name',\n",
       "            u'tech_in_name',        u'rating_cat',    u'expensive_city',\n",
       "                u'analysis',         u'analytics',           u'company',\n",
       "                    u'data',        u'experience',            u'health',\n",
       "                u'learning',           u'looking',           u'machine',\n",
       "                  u'public',          u'research',         u'scientist',\n",
       "              u'scientists',              u'team',              u'work',\n",
       "             u'analyst_tit',          u'data_tit',     u'developer_tit',\n",
       "            u'engineer_tit',   u'engineering_tit',          u'lead_tit',\n",
       "            u'learning_tit',       u'machine_tit',       u'manager_tit',\n",
       "        u'quantitative_tit',      u'research_tit',       u'science_tit',\n",
       "           u'scientist_tit',        u'senior_tit',      u'software_tit'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 655,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_with_wordcounts.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 656,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimization terminated successfully.\n",
      "         Current function value: 0.353531\n",
      "         Iterations 8\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<caption>Logit Regression Results</caption>\n",
       "<tr>\n",
       "  <th>Dep. Variable:</th>     <td>high_paid</td>    <th>  No. Observations:  </th>  <td>   303</td>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Model:</th>               <td>Logit</td>      <th>  Df Residuals:      </th>  <td>   271</td>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Method:</th>               <td>MLE</td>       <th>  Df Model:          </th>  <td>    31</td>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Date:</th>          <td>Mon, 21 Nov 2016</td> <th>  Pseudo R-squ.:     </th>  <td>0.4900</td>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Time:</th>              <td>17:42:17</td>     <th>  Log-Likelihood:    </th> <td> -107.12</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>converged:</th>           <td>True</td>       <th>  LL-Null:           </th> <td> -210.02</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th> </th>                      <td> </td>        <th>  LLR p-value:       </th> <td>1.073e-27</td>\n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "                  <td></td>                    <th>coef</th>     <th>std err</th>      <th>z</th>      <th>P>|z|</th> <th>[95.0% Conf. Int.]</th> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Intercept</th>                        <td>   -5.1450</td> <td>    1.021</td> <td>   -5.037</td> <td> 0.000</td> <td>   -7.147    -3.143</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>search_city[T.Austin, TX]</th>        <td>   -2.1942</td> <td>    1.430</td> <td>   -1.535</td> <td> 0.125</td> <td>   -4.996     0.608</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>search_city[T.Boston, MA]</th>        <td>    1.5711</td> <td>    0.901</td> <td>    1.744</td> <td> 0.081</td> <td>   -0.194     3.337</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>search_city[T.Detroit, MI]</th>       <td>    1.7999</td> <td>    1.261</td> <td>    1.427</td> <td> 0.154</td> <td>   -0.672     4.272</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>search_city[T.Minneapolis, MN]</th>   <td>    0.3245</td> <td>    1.360</td> <td>    0.239</td> <td> 0.811</td> <td>   -2.341     2.990</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>search_city[T.New Orleans, LA]</th>   <td>    0.2632</td> <td>    1.627</td> <td>    0.162</td> <td> 0.871</td> <td>   -2.925     3.451</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>search_city[T.New York, NY]</th>      <td>    1.0649</td> <td>    0.868</td> <td>    1.227</td> <td> 0.220</td> <td>   -0.636     2.766</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>search_city[T.San Francisco, CA]</th> <td>    2.9000</td> <td>    1.002</td> <td>    2.895</td> <td> 0.004</td> <td>    0.936     4.864</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>search_city[T.Seattle, WA]</th>       <td>    0.1219</td> <td>    0.962</td> <td>    0.127</td> <td> 0.899</td> <td>   -1.764     2.008</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>search_city[T.Washington, DC]</th>    <td>    0.9241</td> <td>    0.906</td> <td>    1.021</td> <td> 0.307</td> <td>   -0.851     2.699</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>rating_cat[T.low_rating]</th>         <td>    1.6955</td> <td>    0.656</td> <td>    2.586</td> <td> 0.010</td> <td>    0.410     2.981</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>rating_cat[T.no_rating]</th>          <td>    2.2258</td> <td>    0.509</td> <td>    4.369</td> <td> 0.000</td> <td>    1.227     3.224</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>is_high_level</th>                    <td>    1.4038</td> <td>    0.443</td> <td>    3.171</td> <td> 0.002</td> <td>    0.536     2.272</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>in_city</th>                          <td>    1.0962</td> <td>    0.428</td> <td>    2.560</td> <td> 0.010</td> <td>    0.257     1.935</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>analysis</th>                         <td>    1.2451</td> <td>    0.601</td> <td>    2.073</td> <td> 0.038</td> <td>    0.068     2.422</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>analytics</th>                        <td>    0.1444</td> <td>    0.467</td> <td>    0.309</td> <td> 0.757</td> <td>   -0.770     1.059</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>data</th>                             <td>    0.0331</td> <td>    0.220</td> <td>    0.150</td> <td> 0.881</td> <td>   -0.399     0.465</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>experience</th>                       <td>    1.7370</td> <td>    0.549</td> <td>    3.163</td> <td> 0.002</td> <td>    0.661     2.813</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>health</th>                           <td>    0.1197</td> <td>    0.755</td> <td>    0.159</td> <td> 0.874</td> <td>   -1.360     1.599</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>learning</th>                         <td>   -1.0626</td> <td>    1.461</td> <td>   -0.727</td> <td> 0.467</td> <td>   -3.927     1.802</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>looking</th>                          <td>    2.2079</td> <td>    0.863</td> <td>    2.560</td> <td> 0.010</td> <td>    0.517     3.898</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>machine</th>                          <td>    0.3002</td> <td>    1.527</td> <td>    0.197</td> <td> 0.844</td> <td>   -2.692     3.292</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>public</th>                           <td>    0.7227</td> <td>    0.835</td> <td>    0.866</td> <td> 0.387</td> <td>   -0.914     2.359</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>research</th>                         <td>   -0.7006</td> <td>    0.485</td> <td>   -1.446</td> <td> 0.148</td> <td>   -1.651     0.249</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>scientist</th>                        <td>    1.7704</td> <td>    0.713</td> <td>    2.484</td> <td> 0.013</td> <td>    0.373     3.168</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>scientists</th>                       <td>   -0.2900</td> <td>    0.457</td> <td>   -0.635</td> <td> 0.526</td> <td>   -1.186     0.606</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>team</th>                             <td>    0.7558</td> <td>    0.544</td> <td>    1.390</td> <td> 0.164</td> <td>   -0.310     1.821</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>work</th>                             <td>    0.7198</td> <td>    0.556</td> <td>    1.294</td> <td> 0.196</td> <td>   -0.370     1.810</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>company</th>                          <td>   -0.0182</td> <td>    0.642</td> <td>   -0.028</td> <td> 0.977</td> <td>   -1.277     1.241</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>ds_in_name</th>                       <td>    1.1294</td> <td>    0.579</td> <td>    1.952</td> <td> 0.051</td> <td>   -0.005     2.264</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>ml_in_name</th>                       <td>    3.7348</td> <td>    1.300</td> <td>    2.873</td> <td> 0.004</td> <td>    1.187     6.283</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>engineer_in_name</th>                 <td>    1.9061</td> <td>    0.649</td> <td>    2.937</td> <td> 0.003</td> <td>    0.634     3.178</td>\n",
       "</tr>\n",
       "</table>"
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.summary.Summary'>\n",
       "\"\"\"\n",
       "                           Logit Regression Results                           \n",
       "==============================================================================\n",
       "Dep. Variable:              high_paid   No. Observations:                  303\n",
       "Model:                          Logit   Df Residuals:                      271\n",
       "Method:                           MLE   Df Model:                           31\n",
       "Date:                Mon, 21 Nov 2016   Pseudo R-squ.:                  0.4900\n",
       "Time:                        17:42:17   Log-Likelihood:                -107.12\n",
       "converged:                       True   LL-Null:                       -210.02\n",
       "                                        LLR p-value:                 1.073e-27\n",
       "====================================================================================================\n",
       "                                       coef    std err          z      P>|z|      [95.0% Conf. Int.]\n",
       "----------------------------------------------------------------------------------------------------\n",
       "Intercept                           -5.1450      1.021     -5.037      0.000        -7.147    -3.143\n",
       "search_city[T.Austin, TX]           -2.1942      1.430     -1.535      0.125        -4.996     0.608\n",
       "search_city[T.Boston, MA]            1.5711      0.901      1.744      0.081        -0.194     3.337\n",
       "search_city[T.Detroit, MI]           1.7999      1.261      1.427      0.154        -0.672     4.272\n",
       "search_city[T.Minneapolis, MN]       0.3245      1.360      0.239      0.811        -2.341     2.990\n",
       "search_city[T.New Orleans, LA]       0.2632      1.627      0.162      0.871        -2.925     3.451\n",
       "search_city[T.New York, NY]          1.0649      0.868      1.227      0.220        -0.636     2.766\n",
       "search_city[T.San Francisco, CA]     2.9000      1.002      2.895      0.004         0.936     4.864\n",
       "search_city[T.Seattle, WA]           0.1219      0.962      0.127      0.899        -1.764     2.008\n",
       "search_city[T.Washington, DC]        0.9241      0.906      1.021      0.307        -0.851     2.699\n",
       "rating_cat[T.low_rating]             1.6955      0.656      2.586      0.010         0.410     2.981\n",
       "rating_cat[T.no_rating]              2.2258      0.509      4.369      0.000         1.227     3.224\n",
       "is_high_level                        1.4038      0.443      3.171      0.002         0.536     2.272\n",
       "in_city                              1.0962      0.428      2.560      0.010         0.257     1.935\n",
       "analysis                             1.2451      0.601      2.073      0.038         0.068     2.422\n",
       "analytics                            0.1444      0.467      0.309      0.757        -0.770     1.059\n",
       "data                                 0.0331      0.220      0.150      0.881        -0.399     0.465\n",
       "experience                           1.7370      0.549      3.163      0.002         0.661     2.813\n",
       "health                               0.1197      0.755      0.159      0.874        -1.360     1.599\n",
       "learning                            -1.0626      1.461     -0.727      0.467        -3.927     1.802\n",
       "looking                              2.2079      0.863      2.560      0.010         0.517     3.898\n",
       "machine                              0.3002      1.527      0.197      0.844        -2.692     3.292\n",
       "public                               0.7227      0.835      0.866      0.387        -0.914     2.359\n",
       "research                            -0.7006      0.485     -1.446      0.148        -1.651     0.249\n",
       "scientist                            1.7704      0.713      2.484      0.013         0.373     3.168\n",
       "scientists                          -0.2900      0.457     -0.635      0.526        -1.186     0.606\n",
       "team                                 0.7558      0.544      1.390      0.164        -0.310     1.821\n",
       "work                                 0.7198      0.556      1.294      0.196        -0.370     1.810\n",
       "company                             -0.0182      0.642     -0.028      0.977        -1.277     1.241\n",
       "ds_in_name                           1.1294      0.579      1.952      0.051        -0.005     2.264\n",
       "ml_in_name                           3.7348      1.300      2.873      0.004         1.187     6.283\n",
       "engineer_in_name                     1.9061      0.649      2.937      0.003         0.634     3.178\n",
       "====================================================================================================\n",
       "\"\"\""
      ]
     },
     "execution_count": 656,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# seeing if these word features improve the model\n",
    "y, X = patsy.dmatrices('''high_paid ~ search_city + rating_cat + is_high_level + in_city + \n",
    "analysis + analytics + data + experience + health + learning + looking + machine + public + \n",
    "research + scientist + scientists + team + work + company + ds_in_name + ml_in_name + engineer_in_name''', data=df_with_wordcounts)\n",
    "sm.Logit(y, X).fit().summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 645,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best C:  [ 0.5]\n",
      "Training model score on Test subset:  0.82\n"
     ]
    }
   ],
   "source": [
    "#fit \n",
    "\n",
    "X = patsy.dmatrix('''~ search_city + rating_cat + is_high_level + in_city + \n",
    "analysis + analytics + data + experience + health + learning + looking + machine + public + \n",
    "research + scientist + scientists + team + work + company + ds_in_name + ml_in_name + engineer_in_name''', data=df_with_wordcounts)\n",
    "y = df_with_wordcounts.high_paid.values\n",
    "\n",
    "X_train, X_test, y_train, y_test = sklearn.model_selection.train_test_split(X, y, test_size=0.33, random_state = 109)\n",
    "\n",
    "log_regCV = sklearn.linear_model.LogisticRegressionCV(Cs=[0.0001, 0.001, 0.01, 0.1, 0.5, 0.75, 1.0, 2.5, 5.0, 10.0, 100.0, 1000.0])\n",
    "log_regCV.fit(X_train, y_train)\n",
    "print 'best C: ', log_regCV.fit(X, y).C_\n",
    "print 'Training model score on Test subset: ', log_regCV.score(X_test, y_test)\n",
    "#note: I have no continuous features, so I have nothing to scale."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 646,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cross-val scores:  [ 0.7745098   0.73267327  0.8       ]\n",
      "mean cross-val:  0.769061023749\n",
      "accuracy: 0.76897689769\n",
      "precision: 0.834710743802\n",
      "recall: 0.668874172185\n",
      "AUC: 0.858833129335\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x26bd3a450>"
      ]
     },
     "execution_count": 646,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAiAAAAGJCAYAAACzcoinAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nOAUEABhOAQEAhlNAAIDhvgD1UXVW7kjH+AAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x2683bb210>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# looking at cross-validated scores\n",
    "print 'cross-val scores: ', sklearn.model_selection.cross_val_score(log_regCV, X, y, cv=3)\n",
    "print 'mean cross-val: ', sklearn.model_selection.cross_val_score(log_regCV, X, y, cv=3).mean()\n",
    "\n",
    "#creating confusion matrix from cross-validated predictions.\n",
    "y_pred = sklearn.model_selection.cross_val_predict(log_regCV, X, y, cv=3)\n",
    "\n",
    "actual_vs_cross_val_pred = pd.DataFrame([y_pred, y]).transpose()\n",
    "actual_vs_cross_val_pred.columns = ['cross_val_pred', 'actual']\n",
    "pd.crosstab(actual_vs_cross_val_pred.cross_val_pred, actual_vs_cross_val_pred.actual)\n",
    "\n",
    "\n",
    "print 'accuracy:', sklearn.metrics.accuracy_score(y, y_pred)\n",
    "print 'precision:', sklearn.metrics.precision_score(y, y_pred)\n",
    "print 'recall:', sklearn.metrics.recall_score(y, y_pred)\n",
    "\n",
    "\n",
    "y_score = log_regCV.decision_function(X_test)\n",
    "fpr, tpr, thresholds = sklearn.metrics.roc_curve(y_test, y_score)\n",
    "print 'AUC:', sklearn.metrics.auc(fpr, tpr)\n",
    "\n",
    "\n",
    "plt.plot(fpr, tpr, label='AUC: {:.2}'.format(sklearn.metrics.auc(fpr, tpr)))\n",
    "plt.xlabel('FPR')\n",
    "plt.ylabel('TPR')\n",
    "plt.title('ROC Curve for Cross-Validated Model')\n",
    "plt.plot([0, 1], [0, 1], 'k--')\n",
    "plt.legend(loc='lower right')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 735,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: Maximum number of iterations has been exceeded.\n",
      "         Current function value: 0.229154\n",
      "         Iterations: 35\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "//anaconda/envs/py27/lib/python2.7/site-packages/statsmodels/base/model.py:466: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n",
      "  \"Check mle_retvals\", ConvergenceWarning)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<caption>Logit Regression Results</caption>\n",
       "<tr>\n",
       "  <th>Dep. Variable:</th>     <td>high_paid</td>    <th>  No. Observations:  </th>  <td>   303</td>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Model:</th>               <td>Logit</td>      <th>  Df Residuals:      </th>  <td>   245</td>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Method:</th>               <td>MLE</td>       <th>  Df Model:          </th>  <td>    57</td>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Date:</th>          <td>Tue, 22 Nov 2016</td> <th>  Pseudo R-squ.:     </th>  <td>0.6694</td>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Time:</th>              <td>07:08:00</td>     <th>  Log-Likelihood:    </th> <td> -69.434</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>converged:</th>           <td>False</td>      <th>  LL-Null:           </th> <td> -210.02</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th> </th>                      <td> </td>        <th>  LLR p-value:       </th> <td>2.223e-31</td>\n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "                       <td></td>                         <th>coef</th>     <th>std err</th>      <th>z</th>      <th>P>|z|</th> <th>[95.0% Conf. Int.]</th> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Intercept</th>                                  <td>   -7.7978</td> <td>    1.902</td> <td>   -4.100</td> <td> 0.000</td> <td>  -11.526    -4.070</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>search_city[T.Austin, TX]</th>                  <td>   -1.6698</td> <td>    2.534</td> <td>   -0.659</td> <td> 0.510</td> <td>   -6.636     3.296</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>search_city[T.Boston, MA]</th>                  <td>    3.1105</td> <td>    1.453</td> <td>    2.140</td> <td> 0.032</td> <td>    0.262     5.959</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>search_city[T.Detroit, MI]</th>                 <td>    1.2428</td> <td>    1.900</td> <td>    0.654</td> <td> 0.513</td> <td>   -2.482     4.968</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>search_city[T.Minneapolis, MN]</th>             <td>    1.2382</td> <td>    1.994</td> <td>    0.621</td> <td> 0.535</td> <td>   -2.671     5.147</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>search_city[T.New Orleans, LA]</th>             <td>    3.4917</td> <td>    2.431</td> <td>    1.436</td> <td> 0.151</td> <td>   -1.273     8.257</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>search_city[T.New York, NY]</th>                <td>    2.2379</td> <td>    1.413</td> <td>    1.584</td> <td> 0.113</td> <td>   -0.532     5.008</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>search_city[T.San Francisco, CA]</th>           <td>    5.2868</td> <td>    1.637</td> <td>    3.231</td> <td> 0.001</td> <td>    2.079     8.494</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>search_city[T.Seattle, WA]</th>                 <td>    3.0271</td> <td>    1.717</td> <td>    1.763</td> <td> 0.078</td> <td>   -0.339     6.393</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>search_city[T.Washington, DC]</th>              <td>    2.4200</td> <td>    1.369</td> <td>    1.767</td> <td> 0.077</td> <td>   -0.264     5.104</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>rating_cat[T.low_rating]</th>                   <td>    0.7927</td> <td>    1.005</td> <td>    0.788</td> <td> 0.430</td> <td>   -1.178     2.763</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>rating_cat[T.no_rating]</th>                    <td>    1.4671</td> <td>    0.743</td> <td>    1.974</td> <td> 0.048</td> <td>    0.010     2.924</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>time_since_posted[T.13-18 days ago]</th>        <td>    1.9658</td> <td>    1.070</td> <td>    1.837</td> <td> 0.066</td> <td>   -0.131     4.063</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>time_since_posted[T.19-24 days ago]</th>        <td>    1.3224</td> <td>    1.097</td> <td>    1.205</td> <td> 0.228</td> <td>   -0.828     3.473</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>time_since_posted[T.25-30 days ago]</th>        <td>   -0.6715</td> <td>    1.328</td> <td>   -0.505</td> <td> 0.613</td> <td>   -3.275     1.932</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>time_since_posted[T.7-12 days ago]</th>         <td>    0.1404</td> <td>    0.918</td> <td>    0.153</td> <td> 0.878</td> <td>   -1.658     1.939</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>time_since_posted[T.in the last day]</th>       <td>   -1.2302</td> <td>    1.540</td> <td>   -0.799</td> <td> 0.424</td> <td>   -4.248     1.787</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>time_since_posted[T.more than 30 days ago]</th> <td>    0.9160</td> <td>    0.903</td> <td>    1.014</td> <td> 0.310</td> <td>   -0.854     2.686</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>how_paid[T.monthly]</th>                        <td>  -25.5388</td> <td> 5.03e+04</td> <td>   -0.001</td> <td> 1.000</td> <td>-9.85e+04  9.85e+04</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>how_paid[T.weekly]</th>                         <td>  -21.1273</td> <td> 4758.487</td> <td>   -0.004</td> <td> 0.996</td> <td>-9347.590  9305.335</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>how_paid[T.yearly]</th>                         <td>    0.2070</td> <td>    0.761</td> <td>    0.272</td> <td> 0.786</td> <td>   -1.285     1.699</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>is_high_level</th>                              <td>    3.1040</td> <td>    1.184</td> <td>    2.621</td> <td> 0.009</td> <td>    0.783     5.425</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>in_city</th>                                    <td>    1.3736</td> <td>    0.635</td> <td>    2.164</td> <td> 0.030</td> <td>    0.129     2.618</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>analysis</th>                                   <td>    1.4113</td> <td>    1.059</td> <td>    1.333</td> <td> 0.183</td> <td>   -0.664     3.487</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>analytics</th>                                  <td>   -1.0233</td> <td>    0.564</td> <td>   -1.814</td> <td> 0.070</td> <td>   -2.129     0.082</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>data</th>                                       <td>    0.5226</td> <td>    0.361</td> <td>    1.449</td> <td> 0.147</td> <td>   -0.184     1.229</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>experience</th>                                 <td>    2.8904</td> <td>    1.014</td> <td>    2.852</td> <td> 0.004</td> <td>    0.904     4.877</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>health</th>                                     <td>   -0.3324</td> <td>    1.523</td> <td>   -0.218</td> <td> 0.827</td> <td>   -3.318     2.654</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>learning</th>                                   <td>   -7.2477</td> <td>    4.917</td> <td>   -1.474</td> <td> 0.140</td> <td>  -16.885     2.390</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>looking</th>                                    <td>    1.4613</td> <td>    1.005</td> <td>    1.453</td> <td> 0.146</td> <td>   -0.509     3.432</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>machine</th>                                    <td>    6.3039</td> <td>    4.947</td> <td>    1.274</td> <td> 0.203</td> <td>   -3.392    16.000</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>public</th>                                     <td>    2.0195</td> <td>    1.561</td> <td>    1.293</td> <td> 0.196</td> <td>   -1.041     5.080</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>research</th>                                   <td>    1.2739</td> <td>    0.681</td> <td>    1.871</td> <td> 0.061</td> <td>   -0.061     2.608</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>scientist</th>                                  <td>    2.1181</td> <td>    0.917</td> <td>    2.311</td> <td> 0.021</td> <td>    0.322     3.915</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>scientists</th>                                 <td>   -0.8583</td> <td>    0.674</td> <td>   -1.274</td> <td> 0.203</td> <td>   -2.179     0.462</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>team</th>                                       <td>    0.9065</td> <td>    0.724</td> <td>    1.252</td> <td> 0.210</td> <td>   -0.512     2.325</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>work</th>                                       <td>    2.2512</td> <td>    0.998</td> <td>    2.256</td> <td> 0.024</td> <td>    0.295     4.207</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>company</th>                                    <td>    1.1184</td> <td>    0.858</td> <td>    1.303</td> <td> 0.193</td> <td>   -0.564     2.800</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>ds_in_name</th>                                 <td>    1.2526</td> <td>    1.202</td> <td>    1.042</td> <td> 0.297</td> <td>   -1.103     3.609</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>ml_in_name</th>                                 <td>  -45.1304</td> <td> 8.58e+05</td> <td>-5.26e-05</td> <td> 1.000</td> <td>-1.68e+06  1.68e+06</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>engineer_in_name</th>                           <td>   -1.5884</td> <td>    2.762</td> <td>   -0.575</td> <td> 0.565</td> <td>   -7.002     3.826</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>analyst_tit</th>                                <td>   -3.0195</td> <td>    1.320</td> <td>   -2.287</td> <td> 0.022</td> <td>   -5.607    -0.432</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>data_tit</th>                                   <td>    0.8791</td> <td>    0.820</td> <td>    1.072</td> <td> 0.284</td> <td>   -0.728     2.487</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>developer_tit</th>                              <td>    0.6582</td> <td>    1.424</td> <td>    0.462</td> <td> 0.644</td> <td>   -2.133     3.449</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>engineer_tit</th>                               <td>    2.8837</td> <td>    2.026</td> <td>    1.423</td> <td> 0.155</td> <td>   -1.087     6.854</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>engineering_tit</th>                            <td>    2.2251</td> <td>    3.327</td> <td>    0.669</td> <td> 0.504</td> <td>   -4.295     8.745</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>lead_tit</th>                                   <td>   -2.0468</td> <td>    1.480</td> <td>   -1.383</td> <td> 0.167</td> <td>   -4.947     0.854</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>learning_tit</th>                               <td>   32.5939</td> <td> 8.58e+05</td> <td>  3.8e-05</td> <td> 1.000</td> <td>-1.68e+06  1.68e+06</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>machine_tit</th>                                <td>   16.8838</td> <td> 1.53e+04</td> <td>    0.001</td> <td> 0.999</td> <td>-2.99e+04     3e+04</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>manager_tit</th>                                <td>   -2.0671</td> <td>    1.507</td> <td>   -1.372</td> <td> 0.170</td> <td>   -5.020     0.886</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>quantitative_tit</th>                           <td>    7.1335</td> <td>    1.669</td> <td>    4.274</td> <td> 0.000</td> <td>    3.862    10.405</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>research_tit</th>                               <td>   -1.2144</td> <td>    1.468</td> <td>   -0.827</td> <td> 0.408</td> <td>   -4.093     1.664</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>science_tit</th>                                <td>    0.2419</td> <td>    1.811</td> <td>    0.134</td> <td> 0.894</td> <td>   -3.307     3.791</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>scientist_tit</th>                              <td>   -0.1180</td> <td>    0.940</td> <td>   -0.125</td> <td> 0.900</td> <td>   -1.961     1.725</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>senior_tit</th>                                 <td>   -2.7074</td> <td>    1.479</td> <td>   -1.831</td> <td> 0.067</td> <td>   -5.606     0.191</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>software_tit</th>                               <td>    5.4891</td> <td>    2.818</td> <td>    1.948</td> <td> 0.051</td> <td>   -0.035    11.013</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>page</th>                                       <td>-2.747e-05</td> <td>    0.012</td> <td>   -0.002</td> <td> 0.998</td> <td>   -0.025     0.024</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>number_reviews</th>                             <td>   -0.0005</td> <td>    0.001</td> <td>   -0.357</td> <td> 0.721</td> <td>   -0.003     0.002</td>\n",
       "</tr>\n",
       "</table>"
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.summary.Summary'>\n",
       "\"\"\"\n",
       "                           Logit Regression Results                           \n",
       "==============================================================================\n",
       "Dep. Variable:              high_paid   No. Observations:                  303\n",
       "Model:                          Logit   Df Residuals:                      245\n",
       "Method:                           MLE   Df Model:                           57\n",
       "Date:                Tue, 22 Nov 2016   Pseudo R-squ.:                  0.6694\n",
       "Time:                        07:08:00   Log-Likelihood:                -69.434\n",
       "converged:                      False   LL-Null:                       -210.02\n",
       "                                        LLR p-value:                 2.223e-31\n",
       "==============================================================================================================\n",
       "                                                 coef    std err          z      P>|z|      [95.0% Conf. Int.]\n",
       "--------------------------------------------------------------------------------------------------------------\n",
       "Intercept                                     -7.7978      1.902     -4.100      0.000       -11.526    -4.070\n",
       "search_city[T.Austin, TX]                     -1.6698      2.534     -0.659      0.510        -6.636     3.296\n",
       "search_city[T.Boston, MA]                      3.1105      1.453      2.140      0.032         0.262     5.959\n",
       "search_city[T.Detroit, MI]                     1.2428      1.900      0.654      0.513        -2.482     4.968\n",
       "search_city[T.Minneapolis, MN]                 1.2382      1.994      0.621      0.535        -2.671     5.147\n",
       "search_city[T.New Orleans, LA]                 3.4917      2.431      1.436      0.151        -1.273     8.257\n",
       "search_city[T.New York, NY]                    2.2379      1.413      1.584      0.113        -0.532     5.008\n",
       "search_city[T.San Francisco, CA]               5.2868      1.637      3.231      0.001         2.079     8.494\n",
       "search_city[T.Seattle, WA]                     3.0271      1.717      1.763      0.078        -0.339     6.393\n",
       "search_city[T.Washington, DC]                  2.4200      1.369      1.767      0.077        -0.264     5.104\n",
       "rating_cat[T.low_rating]                       0.7927      1.005      0.788      0.430        -1.178     2.763\n",
       "rating_cat[T.no_rating]                        1.4671      0.743      1.974      0.048         0.010     2.924\n",
       "time_since_posted[T.13-18 days ago]            1.9658      1.070      1.837      0.066        -0.131     4.063\n",
       "time_since_posted[T.19-24 days ago]            1.3224      1.097      1.205      0.228        -0.828     3.473\n",
       "time_since_posted[T.25-30 days ago]           -0.6715      1.328     -0.505      0.613        -3.275     1.932\n",
       "time_since_posted[T.7-12 days ago]             0.1404      0.918      0.153      0.878        -1.658     1.939\n",
       "time_since_posted[T.in the last day]          -1.2302      1.540     -0.799      0.424        -4.248     1.787\n",
       "time_since_posted[T.more than 30 days ago]     0.9160      0.903      1.014      0.310        -0.854     2.686\n",
       "how_paid[T.monthly]                          -25.5388   5.03e+04     -0.001      1.000     -9.85e+04  9.85e+04\n",
       "how_paid[T.weekly]                           -21.1273   4758.487     -0.004      0.996     -9347.590  9305.335\n",
       "how_paid[T.yearly]                             0.2070      0.761      0.272      0.786        -1.285     1.699\n",
       "is_high_level                                  3.1040      1.184      2.621      0.009         0.783     5.425\n",
       "in_city                                        1.3736      0.635      2.164      0.030         0.129     2.618\n",
       "analysis                                       1.4113      1.059      1.333      0.183        -0.664     3.487\n",
       "analytics                                     -1.0233      0.564     -1.814      0.070        -2.129     0.082\n",
       "data                                           0.5226      0.361      1.449      0.147        -0.184     1.229\n",
       "experience                                     2.8904      1.014      2.852      0.004         0.904     4.877\n",
       "health                                        -0.3324      1.523     -0.218      0.827        -3.318     2.654\n",
       "learning                                      -7.2477      4.917     -1.474      0.140       -16.885     2.390\n",
       "looking                                        1.4613      1.005      1.453      0.146        -0.509     3.432\n",
       "machine                                        6.3039      4.947      1.274      0.203        -3.392    16.000\n",
       "public                                         2.0195      1.561      1.293      0.196        -1.041     5.080\n",
       "research                                       1.2739      0.681      1.871      0.061        -0.061     2.608\n",
       "scientist                                      2.1181      0.917      2.311      0.021         0.322     3.915\n",
       "scientists                                    -0.8583      0.674     -1.274      0.203        -2.179     0.462\n",
       "team                                           0.9065      0.724      1.252      0.210        -0.512     2.325\n",
       "work                                           2.2512      0.998      2.256      0.024         0.295     4.207\n",
       "company                                        1.1184      0.858      1.303      0.193        -0.564     2.800\n",
       "ds_in_name                                     1.2526      1.202      1.042      0.297        -1.103     3.609\n",
       "ml_in_name                                   -45.1304   8.58e+05  -5.26e-05      1.000     -1.68e+06  1.68e+06\n",
       "engineer_in_name                              -1.5884      2.762     -0.575      0.565        -7.002     3.826\n",
       "analyst_tit                                   -3.0195      1.320     -2.287      0.022        -5.607    -0.432\n",
       "data_tit                                       0.8791      0.820      1.072      0.284        -0.728     2.487\n",
       "developer_tit                                  0.6582      1.424      0.462      0.644        -2.133     3.449\n",
       "engineer_tit                                   2.8837      2.026      1.423      0.155        -1.087     6.854\n",
       "engineering_tit                                2.2251      3.327      0.669      0.504        -4.295     8.745\n",
       "lead_tit                                      -2.0468      1.480     -1.383      0.167        -4.947     0.854\n",
       "learning_tit                                  32.5939   8.58e+05    3.8e-05      1.000     -1.68e+06  1.68e+06\n",
       "machine_tit                                   16.8838   1.53e+04      0.001      0.999     -2.99e+04     3e+04\n",
       "manager_tit                                   -2.0671      1.507     -1.372      0.170        -5.020     0.886\n",
       "quantitative_tit                               7.1335      1.669      4.274      0.000         3.862    10.405\n",
       "research_tit                                  -1.2144      1.468     -0.827      0.408        -4.093     1.664\n",
       "science_tit                                    0.2419      1.811      0.134      0.894        -3.307     3.791\n",
       "scientist_tit                                 -0.1180      0.940     -0.125      0.900        -1.961     1.725\n",
       "senior_tit                                    -2.7074      1.479     -1.831      0.067        -5.606     0.191\n",
       "software_tit                                   5.4891      2.818      1.948      0.051        -0.035    11.013\n",
       "page                                       -2.747e-05      0.012     -0.002      0.998        -0.025     0.024\n",
       "number_reviews                                -0.0005      0.001     -0.357      0.721        -0.003     0.002\n",
       "==============================================================================================================\n",
       "\"\"\""
      ]
     },
     "execution_count": 735,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# seeing if these word features improve the model\n",
    "y, X = patsy.dmatrices('''high_paid ~ search_city + rating_cat + is_high_level + in_city + \n",
    "analysis + analytics + data + experience + health + learning + looking + machine + public + \n",
    "research + scientist + scientists + team + work + company + ds_in_name + ml_in_name + engineer_in_name\n",
    "+ analyst_tit + data_tit + developer_tit + engineer_tit + engineering_tit + lead_tit + learning_tit + engineering_tit\n",
    "+ lead_tit + learning_tit + machine_tit + manager_tit + quantitative_tit + research_tit + science_tit + scientist_tit + \n",
    "senior_tit + software_tit + page + time_since_posted + how_paid + number_reviews''', data=df_with_wordcounts)\n",
    "sm.Logit(y, X).fit().summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 658,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best C:  [ 0.1]\n",
      "Training model score on Test subset:  0.8\n"
     ]
    }
   ],
   "source": [
    "#fit \n",
    "\n",
    "X = patsy.dmatrix('''~ search_city + rating_cat + is_high_level + in_city + \n",
    "analysis + analytics + data + experience + health + learning + looking + machine + public + \n",
    "research + scientist + scientists + team + work + company + ds_in_name + ml_in_name + engineer_in_name\n",
    "+ analyst_tit + data_tit + developer_tit + engineer_tit + engineering_tit + lead_tit + learning_tit + engineering_tit\n",
    "+ lead_tit + learning_tit + machine_tit + manager_tit + quantitative_tit + research_tit + science_tit + scientist_tit + \n",
    "senior_tit + software_tit''', data=df_with_wordcounts)\n",
    "y = df_with_wordcounts.high_paid.values\n",
    "\n",
    "X_train, X_test, y_train, y_test = sklearn.model_selection.train_test_split(X, y, test_size=0.33, random_state = 109)\n",
    "\n",
    "log_regCV = sklearn.linear_model.LogisticRegressionCV(Cs=[0.0001, 0.001, 0.01, 0.1, 0.5, 0.75, 1.0, 2.5, 5.0, 10.0, 100.0, 1000.0])\n",
    "log_regCV.fit(X_train, y_train)\n",
    "print 'best C: ', log_regCV.fit(X, y).C_\n",
    "print 'Training model score on Test subset: ', log_regCV.score(X_test, y_test)\n",
    "#note: I have no continuous features, so I have nothing to scale."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 659,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cross-val scores:  [ 0.78431373  0.76237624  0.79      ]\n",
      "mean cross-val:  0.778896654371\n",
      "accuracy: 0.778877887789\n",
      "precision: 0.823076923077\n",
      "recall: 0.708609271523\n",
      "AUC: 0.87474500204\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x26bd87610>"
      ]
     },
     "execution_count": 659,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAiAAAAGJCAYAAACzcoinAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x26bc1a910>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# looking at cross-validated scores\n",
    "print 'cross-val scores: ', sklearn.model_selection.cross_val_score(log_regCV, X, y, cv=3)\n",
    "print 'mean cross-val: ', sklearn.model_selection.cross_val_score(log_regCV, X, y, cv=3).mean()\n",
    "\n",
    "#creating confusion matrix from cross-validated predictions.\n",
    "y_pred = sklearn.model_selection.cross_val_predict(log_regCV, X, y, cv=3)\n",
    "\n",
    "actual_vs_cross_val_pred = pd.DataFrame([y_pred, y]).transpose()\n",
    "actual_vs_cross_val_pred.columns = ['cross_val_pred', 'actual']\n",
    "pd.crosstab(actual_vs_cross_val_pred.cross_val_pred, actual_vs_cross_val_pred.actual)\n",
    "\n",
    "\n",
    "print 'accuracy:', sklearn.metrics.accuracy_score(y, y_pred)\n",
    "print 'precision:', sklearn.metrics.precision_score(y, y_pred)\n",
    "print 'recall:', sklearn.metrics.recall_score(y, y_pred)\n",
    "\n",
    "\n",
    "y_score = log_regCV.decision_function(X_test)\n",
    "fpr, tpr, thresholds = sklearn.metrics.roc_curve(y_test, y_score)\n",
    "print 'AUC:', sklearn.metrics.auc(fpr, tpr)\n",
    "\n",
    "\n",
    "plt.plot(fpr, tpr, label='AUC: {:.2}'.format(sklearn.metrics.auc(fpr, tpr)))\n",
    "plt.xlabel('FPR')\n",
    "plt.ylabel('TPR')\n",
    "plt.title('ROC Curve for Cross-Validated Model')\n",
    "plt.plot([0, 1], [0, 1], 'k--')\n",
    "plt.legend(loc='lower right')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 741,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best C:  [ 1.]\n",
      "Training model score on Test subset:  0.85\n"
     ]
    }
   ],
   "source": [
    "#fit \n",
    "\n",
    "X = patsy.dmatrix('''~ search_city + rating_cat + is_high_level + in_city + \n",
    "analysis + analytics + data + experience + health + learning + looking + machine + public + \n",
    "research + scientist + scientists + team + work + company + ds_in_name + ml_in_name + engineer_in_name\n",
    "+ analyst_tit + data_tit + developer_tit + engineer_tit + engineering_tit + lead_tit + learning_tit + engineering_tit\n",
    "+ lead_tit + learning_tit + machine_tit + manager_tit + quantitative_tit + research_tit + science_tit + scientist_tit + \n",
    "senior_tit + software_tit + how_paid + page + number_reviews + time_since_posted''', data=df_with_wordcounts)\n",
    "y = df_with_wordcounts.high_paid.values\n",
    "\n",
    "X_train, X_test, y_train, y_test = sklearn.model_selection.train_test_split(X, y, test_size=0.33, random_state = 109)\n",
    "\n",
    "log_regCV = sklearn.linear_model.LogisticRegressionCV(penalty='l1', solver='liblinear', Cs=[0.0001, 0.001, 0.01, 0.1, 0.5, 0.75, 1.0, 2.5, 5.0, 10.0, 100.0, 1000.0])\n",
    "log_regCV.fit(X_train, y_train)\n",
    "print 'best C: ', log_regCV.fit(X, y).C_\n",
    "print 'Training model score on Test subset: ', log_regCV.score(X_test, y_test)\n",
    "#note: I have no continuous features, so I have nothing to scale."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 740,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cross-val scores:  [ 0.7745098   0.74257426  0.78      ]\n",
      "mean cross-val:  0.765694687116\n",
      "accuracy: 0.765676567657\n",
      "precision: 0.8125\n",
      "recall: 0.688741721854\n",
      "AUC: 0.935897435897\n",
      "coefficients [[-1.16577857 -1.19339701  0.3522679   0.         -0.09562688  0.\n",
      "   0.02016674  1.39515508 -0.15494791  0.          0.70422365  1.17380158\n",
      "   0.23551947  0.19224737 -0.2675068   0.          0.          0.\n",
      "   0.9619743   0.34181173  0.53868152 -0.02449591  0.20785079  0.95316999\n",
      "   0.          1.18036901  0.          0.3988024   0.          1.16263531\n",
      "  -0.25423693  0.59015136  0.64665646  0.13192402  0.67108476  0.\n",
      "   0.38870244 -1.16788046  0.24028152  0.          0.71038797  0.\n",
      "  -0.36585644  1.60105125  0.21471597  0.          3.36968038 -0.77166874\n",
      "   0.          0.          0.          0.89725266]]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x26f107590>"
      ]
     },
     "execution_count": 740,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAiAAAAGJCAYAAACzcoinAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x26df94710>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# looking at cross-validated scores\n",
    "print 'cross-val scores: ', sklearn.model_selection.cross_val_score(log_regCV, X, y, cv=3)\n",
    "print 'mean cross-val: ', sklearn.model_selection.cross_val_score(log_regCV, X, y, cv=3).mean()\n",
    "\n",
    "#creating confusion matrix from cross-validated predictions.\n",
    "y_pred = sklearn.model_selection.cross_val_predict(log_regCV, X, y, cv=3)\n",
    "\n",
    "actual_vs_cross_val_pred = pd.DataFrame([y_pred, y]).transpose()\n",
    "actual_vs_cross_val_pred.columns = ['cross_val_pred', 'actual']\n",
    "pd.crosstab(actual_vs_cross_val_pred.cross_val_pred, actual_vs_cross_val_pred.actual)\n",
    "\n",
    "\n",
    "print 'accuracy:', sklearn.metrics.accuracy_score(y, y_pred)\n",
    "print 'precision:', sklearn.metrics.precision_score(y, y_pred)\n",
    "print 'recall:', sklearn.metrics.recall_score(y, y_pred)\n",
    "\n",
    "\n",
    "y_score = log_regCV.decision_function(X_test)\n",
    "fpr, tpr, thresholds = sklearn.metrics.roc_curve(y_test, y_score)\n",
    "print 'AUC:', sklearn.metrics.auc(fpr, tpr)\n",
    "print 'coefficients', log_regCV.coef_\n",
    "\n",
    "\n",
    "plt.plot(fpr, tpr, label='AUC: {:.2}'.format(sklearn.metrics.auc(fpr, tpr)))\n",
    "plt.xlabel('FPR')\n",
    "plt.ylabel('TPR')\n",
    "plt.title('ROC Curve for Cross-Validated Model')\n",
    "plt.plot([0, 1], [0, 1], 'k--')\n",
    "plt.legend(loc='lower right')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 742,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "closest to 1 0.170113519355\n",
      "best threshold -0.271823372504\n",
      "best fpr, tpr: 0.115384615385 0.875\n"
     ]
    }
   ],
   "source": [
    "closest_to_1 = 1\n",
    "best_threshold = None\n",
    "best_tpr = None\n",
    "best_fpr = None\n",
    "for fpr_, tpr_, threshold in zip(fpr, tpr, thresholds):\n",
    "    dist = (fpr_**2 + (1-tpr_)**2)**.5\n",
    "    if dist < closest_to_1:\n",
    "        closest_to_1 = dist\n",
    "        best_threshold = threshold\n",
    "        best_tpr = tpr_\n",
    "        best_fpr = fpr_\n",
    "print 'closest to 1', closest_to_1\n",
    "print 'best threshold', best_threshold\n",
    "print 'best fpr, tpr:', best_fpr, best_tpr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 743,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7619888373847028"
      ]
     },
     "execution_count": 743,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "math.e**best_threshold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 678,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 713,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>*features</th>\n",
       "      <th>coefficients</th>\n",
       "      <th>odds_ratio</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Intercept</td>\n",
       "      <td>-1.387</td>\n",
       "      <td>0.250</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>search_city[T.Austin, TX]</td>\n",
       "      <td>-0.071</td>\n",
       "      <td>0.931</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>search_city[T.Boston, MA]</td>\n",
       "      <td>0.300</td>\n",
       "      <td>1.350</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>search_city[T.Detroit, MI]</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>search_city[T.Minneapolis, MN]</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>search_city[T.New Orleans, LA]</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>search_city[T.New York, NY]</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>search_city[T.San Francisco, CA]</td>\n",
       "      <td>1.362</td>\n",
       "      <td>3.904</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>search_city[T.Seattle, WA]</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>search_city[T.Washington, DC]</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>rating_cat[T.low_rating]</td>\n",
       "      <td>0.431</td>\n",
       "      <td>1.539</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>rating_cat[T.no_rating]</td>\n",
       "      <td>0.797</td>\n",
       "      <td>2.219</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>how_paid[T.monthly]</td>\n",
       "      <td>-1.962</td>\n",
       "      <td>0.141</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>how_paid[T.weekly]</td>\n",
       "      <td>-0.248</td>\n",
       "      <td>0.780</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>how_paid[T.yearly]</td>\n",
       "      <td>0.269</td>\n",
       "      <td>1.309</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>time_since_posted[T.13-18 days ago]</td>\n",
       "      <td>0.290</td>\n",
       "      <td>1.336</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>time_since_posted[T.19-24 days ago]</td>\n",
       "      <td>0.184</td>\n",
       "      <td>1.202</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>time_since_posted[T.25-30 days ago]</td>\n",
       "      <td>-0.260</td>\n",
       "      <td>0.771</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>time_since_posted[T.7-12 days ago]</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>time_since_posted[T.in the last day]</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>time_since_posted[T.more than 30 days ago]</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>is_high_level</td>\n",
       "      <td>0.903</td>\n",
       "      <td>2.467</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>in_city</td>\n",
       "      <td>0.456</td>\n",
       "      <td>1.578</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>analysis</td>\n",
       "      <td>0.372</td>\n",
       "      <td>1.451</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>analytics</td>\n",
       "      <td>-0.096</td>\n",
       "      <td>0.908</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>data</td>\n",
       "      <td>0.226</td>\n",
       "      <td>1.254</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>experience</td>\n",
       "      <td>0.929</td>\n",
       "      <td>2.532</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>health</td>\n",
       "      <td>0.061</td>\n",
       "      <td>1.063</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>learning</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>looking</td>\n",
       "      <td>1.242</td>\n",
       "      <td>3.463</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>machine</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>public</td>\n",
       "      <td>0.318</td>\n",
       "      <td>1.374</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>research</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>scientist</td>\n",
       "      <td>1.153</td>\n",
       "      <td>3.168</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>scientists</td>\n",
       "      <td>-0.249</td>\n",
       "      <td>0.780</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>team</td>\n",
       "      <td>0.490</td>\n",
       "      <td>1.632</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>work</td>\n",
       "      <td>0.686</td>\n",
       "      <td>1.986</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>company</td>\n",
       "      <td>0.039</td>\n",
       "      <td>1.040</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>ds_in_name</td>\n",
       "      <td>0.767</td>\n",
       "      <td>2.153</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>ml_in_name</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>engineer_in_name</td>\n",
       "      <td>0.330</td>\n",
       "      <td>1.391</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>analyst_tit</td>\n",
       "      <td>-1.376</td>\n",
       "      <td>0.253</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>data_tit</td>\n",
       "      <td>0.140</td>\n",
       "      <td>1.150</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>developer_tit</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>engineer_tit</td>\n",
       "      <td>0.660</td>\n",
       "      <td>1.935</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>engineering_tit</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>lead_tit</td>\n",
       "      <td>-0.219</td>\n",
       "      <td>0.803</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>learning_tit</td>\n",
       "      <td>1.509</td>\n",
       "      <td>4.522</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>machine_tit</td>\n",
       "      <td>0.037</td>\n",
       "      <td>1.038</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>manager_tit</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50</th>\n",
       "      <td>quantitative_tit</td>\n",
       "      <td>3.404</td>\n",
       "      <td>30.084</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51</th>\n",
       "      <td>research_tit</td>\n",
       "      <td>-0.657</td>\n",
       "      <td>0.518</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52</th>\n",
       "      <td>science_tit</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53</th>\n",
       "      <td>scientist_tit</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54</th>\n",
       "      <td>senior_tit</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55</th>\n",
       "      <td>software_tit</td>\n",
       "      <td>0.767</td>\n",
       "      <td>2.153</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56</th>\n",
       "      <td>page</td>\n",
       "      <td>0.005</td>\n",
       "      <td>1.005</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57</th>\n",
       "      <td>number_reviews</td>\n",
       "      <td>-0.000</td>\n",
       "      <td>1.000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                     *features  coefficients  odds_ratio\n",
       "0                                    Intercept        -1.387       0.250\n",
       "1                    search_city[T.Austin, TX]        -0.071       0.931\n",
       "2                    search_city[T.Boston, MA]         0.300       1.350\n",
       "3                   search_city[T.Detroit, MI]         0.000       1.000\n",
       "4               search_city[T.Minneapolis, MN]         0.000       1.000\n",
       "5               search_city[T.New Orleans, LA]         0.000       1.000\n",
       "6                  search_city[T.New York, NY]         0.000       1.000\n",
       "7             search_city[T.San Francisco, CA]         1.362       3.904\n",
       "8                   search_city[T.Seattle, WA]         0.000       1.000\n",
       "9                search_city[T.Washington, DC]         0.000       1.000\n",
       "10                    rating_cat[T.low_rating]         0.431       1.539\n",
       "11                     rating_cat[T.no_rating]         0.797       2.219\n",
       "12                         how_paid[T.monthly]        -1.962       0.141\n",
       "13                          how_paid[T.weekly]        -0.248       0.780\n",
       "14                          how_paid[T.yearly]         0.269       1.309\n",
       "15         time_since_posted[T.13-18 days ago]         0.290       1.336\n",
       "16         time_since_posted[T.19-24 days ago]         0.184       1.202\n",
       "17         time_since_posted[T.25-30 days ago]        -0.260       0.771\n",
       "18          time_since_posted[T.7-12 days ago]         0.000       1.000\n",
       "19        time_since_posted[T.in the last day]         0.000       1.000\n",
       "20  time_since_posted[T.more than 30 days ago]         0.000       1.000\n",
       "21                               is_high_level         0.903       2.467\n",
       "22                                     in_city         0.456       1.578\n",
       "23                                    analysis         0.372       1.451\n",
       "24                                   analytics        -0.096       0.908\n",
       "25                                        data         0.226       1.254\n",
       "26                                  experience         0.929       2.532\n",
       "27                                      health         0.061       1.063\n",
       "28                                    learning         0.000       1.000\n",
       "29                                     looking         1.242       3.463\n",
       "30                                     machine         0.000       1.000\n",
       "31                                      public         0.318       1.374\n",
       "32                                    research         0.000       1.000\n",
       "33                                   scientist         1.153       3.168\n",
       "34                                  scientists        -0.249       0.780\n",
       "35                                        team         0.490       1.632\n",
       "36                                        work         0.686       1.986\n",
       "37                                     company         0.039       1.040\n",
       "38                                  ds_in_name         0.767       2.153\n",
       "39                                  ml_in_name         0.000       1.000\n",
       "40                            engineer_in_name         0.330       1.391\n",
       "41                                 analyst_tit        -1.376       0.253\n",
       "42                                    data_tit         0.140       1.150\n",
       "43                               developer_tit         0.000       1.000\n",
       "44                                engineer_tit         0.660       1.935\n",
       "45                             engineering_tit         0.000       1.000\n",
       "46                                    lead_tit        -0.219       0.803\n",
       "47                                learning_tit         1.509       4.522\n",
       "48                                 machine_tit         0.037       1.038\n",
       "49                                 manager_tit         0.000       1.000\n",
       "50                            quantitative_tit         3.404      30.084\n",
       "51                                research_tit        -0.657       0.518\n",
       "52                                 science_tit         0.000       1.000\n",
       "53                               scientist_tit         0.000       1.000\n",
       "54                                  senior_tit         0.000       1.000\n",
       "55                                software_tit         0.767       2.153\n",
       "56                                        page         0.005       1.005\n",
       "57                              number_reviews        -0.000       1.000"
      ]
     },
     "execution_count": 713,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.DataFrame({'*features' : X.design_info.column_names, \n",
    "                   'coefficients': log_regCV.coef_[0,:].round(3)})\n",
    "df['odds_ratio'] = (math.e**df.coefficients).round(3)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 714,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>*features</th>\n",
       "      <th>coefficients</th>\n",
       "      <th>odds_ratio</th>\n",
       "      <th>interpretation</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Intercept</td>\n",
       "      <td>-1.387</td>\n",
       "      <td>0.250</td>\n",
       "      <td>base odds: 1:4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>search_city[T.Austin, TX]</td>\n",
       "      <td>-0.071</td>\n",
       "      <td>0.931</td>\n",
       "      <td>7.41% lower odds</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>search_city[T.Boston, MA]</td>\n",
       "      <td>0.300</td>\n",
       "      <td>1.350</td>\n",
       "      <td>35.0% greater odds</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>search_city[T.Detroit, MI]</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>no change</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>search_city[T.Minneapolis, MN]</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>no change</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>search_city[T.New Orleans, LA]</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>no change</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>search_city[T.New York, NY]</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>no change</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>search_city[T.San Francisco, CA]</td>\n",
       "      <td>1.362</td>\n",
       "      <td>3.904</td>\n",
       "      <td>290.4% greater odds</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>search_city[T.Seattle, WA]</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>no change</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>search_city[T.Washington, DC]</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>no change</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>rating_cat[T.low_rating]</td>\n",
       "      <td>0.431</td>\n",
       "      <td>1.539</td>\n",
       "      <td>53.9% greater odds</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>rating_cat[T.no_rating]</td>\n",
       "      <td>0.797</td>\n",
       "      <td>2.219</td>\n",
       "      <td>121.9% greater odds</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>how_paid[T.monthly]</td>\n",
       "      <td>-1.962</td>\n",
       "      <td>0.141</td>\n",
       "      <td>609.22% lower odds</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>how_paid[T.weekly]</td>\n",
       "      <td>-0.248</td>\n",
       "      <td>0.780</td>\n",
       "      <td>28.21% lower odds</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>how_paid[T.yearly]</td>\n",
       "      <td>0.269</td>\n",
       "      <td>1.309</td>\n",
       "      <td>30.9% greater odds</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>time_since_posted[T.13-18 days ago]</td>\n",
       "      <td>0.290</td>\n",
       "      <td>1.336</td>\n",
       "      <td>33.6% greater odds</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>time_since_posted[T.19-24 days ago]</td>\n",
       "      <td>0.184</td>\n",
       "      <td>1.202</td>\n",
       "      <td>20.2% greater odds</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>time_since_posted[T.25-30 days ago]</td>\n",
       "      <td>-0.260</td>\n",
       "      <td>0.771</td>\n",
       "      <td>29.7% lower odds</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>time_since_posted[T.7-12 days ago]</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>no change</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>time_since_posted[T.in the last day]</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>no change</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>time_since_posted[T.more than 30 days ago]</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>no change</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>is_high_level</td>\n",
       "      <td>0.903</td>\n",
       "      <td>2.467</td>\n",
       "      <td>146.7% greater odds</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>in_city</td>\n",
       "      <td>0.456</td>\n",
       "      <td>1.578</td>\n",
       "      <td>57.8% greater odds</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>analysis</td>\n",
       "      <td>0.372</td>\n",
       "      <td>1.451</td>\n",
       "      <td>45.1% greater odds</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>analytics</td>\n",
       "      <td>-0.096</td>\n",
       "      <td>0.908</td>\n",
       "      <td>10.13% lower odds</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>data</td>\n",
       "      <td>0.226</td>\n",
       "      <td>1.254</td>\n",
       "      <td>25.4% greater odds</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>experience</td>\n",
       "      <td>0.929</td>\n",
       "      <td>2.532</td>\n",
       "      <td>153.2% greater odds</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>health</td>\n",
       "      <td>0.061</td>\n",
       "      <td>1.063</td>\n",
       "      <td>6.3% greater odds</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>learning</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>no change</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>looking</td>\n",
       "      <td>1.242</td>\n",
       "      <td>3.463</td>\n",
       "      <td>246.3% greater odds</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>machine</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>no change</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>public</td>\n",
       "      <td>0.318</td>\n",
       "      <td>1.374</td>\n",
       "      <td>37.4% greater odds</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>research</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>no change</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>scientist</td>\n",
       "      <td>1.153</td>\n",
       "      <td>3.168</td>\n",
       "      <td>216.8% greater odds</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>scientists</td>\n",
       "      <td>-0.249</td>\n",
       "      <td>0.780</td>\n",
       "      <td>28.21% lower odds</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>team</td>\n",
       "      <td>0.490</td>\n",
       "      <td>1.632</td>\n",
       "      <td>63.2% greater odds</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>work</td>\n",
       "      <td>0.686</td>\n",
       "      <td>1.986</td>\n",
       "      <td>98.6% greater odds</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>company</td>\n",
       "      <td>0.039</td>\n",
       "      <td>1.040</td>\n",
       "      <td>4.0% greater odds</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>ds_in_name</td>\n",
       "      <td>0.767</td>\n",
       "      <td>2.153</td>\n",
       "      <td>115.3% greater odds</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>ml_in_name</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>no change</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>engineer_in_name</td>\n",
       "      <td>0.330</td>\n",
       "      <td>1.391</td>\n",
       "      <td>39.1% greater odds</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>analyst_tit</td>\n",
       "      <td>-1.376</td>\n",
       "      <td>0.253</td>\n",
       "      <td>295.26% lower odds</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>data_tit</td>\n",
       "      <td>0.140</td>\n",
       "      <td>1.150</td>\n",
       "      <td>15.0% greater odds</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>developer_tit</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>no change</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>engineer_tit</td>\n",
       "      <td>0.660</td>\n",
       "      <td>1.935</td>\n",
       "      <td>93.5% greater odds</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>engineering_tit</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>no change</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>lead_tit</td>\n",
       "      <td>-0.219</td>\n",
       "      <td>0.803</td>\n",
       "      <td>24.53% lower odds</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>learning_tit</td>\n",
       "      <td>1.509</td>\n",
       "      <td>4.522</td>\n",
       "      <td>352.2% greater odds</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>machine_tit</td>\n",
       "      <td>0.037</td>\n",
       "      <td>1.038</td>\n",
       "      <td>3.8% greater odds</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>manager_tit</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>no change</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50</th>\n",
       "      <td>quantitative_tit</td>\n",
       "      <td>3.404</td>\n",
       "      <td>30.084</td>\n",
       "      <td>2908.4% greater odds</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51</th>\n",
       "      <td>research_tit</td>\n",
       "      <td>-0.657</td>\n",
       "      <td>0.518</td>\n",
       "      <td>93.05% lower odds</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52</th>\n",
       "      <td>science_tit</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>no change</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53</th>\n",
       "      <td>scientist_tit</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>no change</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54</th>\n",
       "      <td>senior_tit</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>no change</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55</th>\n",
       "      <td>software_tit</td>\n",
       "      <td>0.767</td>\n",
       "      <td>2.153</td>\n",
       "      <td>115.3% greater odds</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56</th>\n",
       "      <td>page</td>\n",
       "      <td>0.005</td>\n",
       "      <td>1.005</td>\n",
       "      <td>0.5% greater odds</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57</th>\n",
       "      <td>number_reviews</td>\n",
       "      <td>-0.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>no change</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                     *features  coefficients  odds_ratio  \\\n",
       "0                                    Intercept        -1.387       0.250   \n",
       "1                    search_city[T.Austin, TX]        -0.071       0.931   \n",
       "2                    search_city[T.Boston, MA]         0.300       1.350   \n",
       "3                   search_city[T.Detroit, MI]         0.000       1.000   \n",
       "4               search_city[T.Minneapolis, MN]         0.000       1.000   \n",
       "5               search_city[T.New Orleans, LA]         0.000       1.000   \n",
       "6                  search_city[T.New York, NY]         0.000       1.000   \n",
       "7             search_city[T.San Francisco, CA]         1.362       3.904   \n",
       "8                   search_city[T.Seattle, WA]         0.000       1.000   \n",
       "9                search_city[T.Washington, DC]         0.000       1.000   \n",
       "10                    rating_cat[T.low_rating]         0.431       1.539   \n",
       "11                     rating_cat[T.no_rating]         0.797       2.219   \n",
       "12                         how_paid[T.monthly]        -1.962       0.141   \n",
       "13                          how_paid[T.weekly]        -0.248       0.780   \n",
       "14                          how_paid[T.yearly]         0.269       1.309   \n",
       "15         time_since_posted[T.13-18 days ago]         0.290       1.336   \n",
       "16         time_since_posted[T.19-24 days ago]         0.184       1.202   \n",
       "17         time_since_posted[T.25-30 days ago]        -0.260       0.771   \n",
       "18          time_since_posted[T.7-12 days ago]         0.000       1.000   \n",
       "19        time_since_posted[T.in the last day]         0.000       1.000   \n",
       "20  time_since_posted[T.more than 30 days ago]         0.000       1.000   \n",
       "21                               is_high_level         0.903       2.467   \n",
       "22                                     in_city         0.456       1.578   \n",
       "23                                    analysis         0.372       1.451   \n",
       "24                                   analytics        -0.096       0.908   \n",
       "25                                        data         0.226       1.254   \n",
       "26                                  experience         0.929       2.532   \n",
       "27                                      health         0.061       1.063   \n",
       "28                                    learning         0.000       1.000   \n",
       "29                                     looking         1.242       3.463   \n",
       "30                                     machine         0.000       1.000   \n",
       "31                                      public         0.318       1.374   \n",
       "32                                    research         0.000       1.000   \n",
       "33                                   scientist         1.153       3.168   \n",
       "34                                  scientists        -0.249       0.780   \n",
       "35                                        team         0.490       1.632   \n",
       "36                                        work         0.686       1.986   \n",
       "37                                     company         0.039       1.040   \n",
       "38                                  ds_in_name         0.767       2.153   \n",
       "39                                  ml_in_name         0.000       1.000   \n",
       "40                            engineer_in_name         0.330       1.391   \n",
       "41                                 analyst_tit        -1.376       0.253   \n",
       "42                                    data_tit         0.140       1.150   \n",
       "43                               developer_tit         0.000       1.000   \n",
       "44                                engineer_tit         0.660       1.935   \n",
       "45                             engineering_tit         0.000       1.000   \n",
       "46                                    lead_tit        -0.219       0.803   \n",
       "47                                learning_tit         1.509       4.522   \n",
       "48                                 machine_tit         0.037       1.038   \n",
       "49                                 manager_tit         0.000       1.000   \n",
       "50                            quantitative_tit         3.404      30.084   \n",
       "51                                research_tit        -0.657       0.518   \n",
       "52                                 science_tit         0.000       1.000   \n",
       "53                               scientist_tit         0.000       1.000   \n",
       "54                                  senior_tit         0.000       1.000   \n",
       "55                                software_tit         0.767       2.153   \n",
       "56                                        page         0.005       1.005   \n",
       "57                              number_reviews        -0.000       1.000   \n",
       "\n",
       "          interpretation  \n",
       "0         base odds: 1:4  \n",
       "1       7.41% lower odds  \n",
       "2     35.0% greater odds  \n",
       "3              no change  \n",
       "4              no change  \n",
       "5              no change  \n",
       "6              no change  \n",
       "7    290.4% greater odds  \n",
       "8              no change  \n",
       "9              no change  \n",
       "10    53.9% greater odds  \n",
       "11   121.9% greater odds  \n",
       "12    609.22% lower odds  \n",
       "13     28.21% lower odds  \n",
       "14    30.9% greater odds  \n",
       "15    33.6% greater odds  \n",
       "16    20.2% greater odds  \n",
       "17      29.7% lower odds  \n",
       "18             no change  \n",
       "19             no change  \n",
       "20             no change  \n",
       "21   146.7% greater odds  \n",
       "22    57.8% greater odds  \n",
       "23    45.1% greater odds  \n",
       "24     10.13% lower odds  \n",
       "25    25.4% greater odds  \n",
       "26   153.2% greater odds  \n",
       "27     6.3% greater odds  \n",
       "28             no change  \n",
       "29   246.3% greater odds  \n",
       "30             no change  \n",
       "31    37.4% greater odds  \n",
       "32             no change  \n",
       "33   216.8% greater odds  \n",
       "34     28.21% lower odds  \n",
       "35    63.2% greater odds  \n",
       "36    98.6% greater odds  \n",
       "37     4.0% greater odds  \n",
       "38   115.3% greater odds  \n",
       "39             no change  \n",
       "40    39.1% greater odds  \n",
       "41    295.26% lower odds  \n",
       "42    15.0% greater odds  \n",
       "43             no change  \n",
       "44    93.5% greater odds  \n",
       "45             no change  \n",
       "46     24.53% lower odds  \n",
       "47   352.2% greater odds  \n",
       "48     3.8% greater odds  \n",
       "49             no change  \n",
       "50  2908.4% greater odds  \n",
       "51     93.05% lower odds  \n",
       "52             no change  \n",
       "53             no change  \n",
       "54             no change  \n",
       "55   115.3% greater odds  \n",
       "56     0.5% greater odds  \n",
       "57             no change  "
      ]
     },
     "execution_count": 714,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def interpretation(odds_ratio):\n",
    "    if odds_ratio == 1.0:\n",
    "        return \"no change\"\n",
    "    elif odds_ratio < 1:\n",
    "        inv = odds_ratio**-1\n",
    "        pct = round((100*(inv-1)), 2)\n",
    "        return str(pct)+'% lower odds'\n",
    "    else:\n",
    "        pct = round((100*(odds_ratio-1)), 2)\n",
    "        return str(pct)+'% greater odds'\n",
    "df['interpretation'] = df.odds_ratio.apply(interpretation)\n",
    "df.ix[0,'interpretation'] = 'base odds: 1:4'\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for metric in ['accuracy', 'precision', 'recall', 'roc_auc']:\n",
    "    scores = cross_val_score(model, X_scaled, y, cv=3, scoring=metric)\n",
    "    print(metric, scores.mean(), scores.std())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "focus": false,
    "id": "f44df3c1-cf82-4271-8660-fdd0052097b6"
   },
   "outputs": [],
   "source": [
    "model.fit(X_scaled, y)\n",
    "\n",
    "df = pd.DataFrame({'features' : vectorizer.get_feature_names(), 'coef': model.coef_[0,:]})\n",
    "df.sort_values('coef', ascending=False, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "focus": false,
    "id": "e182bbe4-2a72-4e75-a3e8-c117688cb8a6"
   },
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "focus": false,
    "id": "a15ef8ea-3130-4c08-a165-ac34d2a8d829"
   },
   "outputs": [],
   "source": [
    "df.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "focus": false,
    "id": "b8a13337-0cde-4117-a928-ffae14661453"
   },
   "outputs": [],
   "source": [
    "# retest L1 and L2 regularization\n",
    "from sklearn.linear_model import LogisticRegressionCV\n",
    "\n",
    "model = LogisticRegressionCV()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "focus": false,
    "id": "936cd752-6b3f-450f-bfb6-1659c6e71539"
   },
   "source": [
    "Score: | /24\n",
    "------|-------\n",
    "Identify: Problem Statement and Hypothesis | \n",
    "Acquire: Import Data using BeautifulSoup| \n",
    "Parse: Clean and Organize Data| \n",
    "Model: Perform Logistic Regression| \n",
    "Evaluate: Logistic Regression Results\t|\n",
    "Present: Blog Report with Findings and Recommendations\t\t| \n",
    "Interactive Tableau visualizations | \n",
    "Regularization |\n",
    "Bonus: Countvectorizer  | "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 273,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "                <audio controls=\"controls\" autoplay=\"autoplay\">\n",
       "                    <source src=\"http://www.soundjay.com/button/beep-01a.mp3\" type=\"audio/mpeg\" />\n",
       "                    Your browser does not support the audio element.\n",
       "                </audio>\n",
       "              "
      ],
      "text/plain": [
       "<IPython.lib.display.Audio object>"
      ]
     },
     "execution_count": 273,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from IPython.display import Audio\n",
    "Audio(url=\"http://www.soundjay.com/button/beep-01a.mp3\",autoplay=True)"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
